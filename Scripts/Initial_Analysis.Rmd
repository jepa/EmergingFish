---
title: Matching the Time of Emergence of Transboundary Fish Stocks to Lead Time for
  Policy Response Under Climate Change
author: "Juliano Palacios Abrantes"
date: "09/03/2020"
output:
  word_document: 
    keep_md: yes
  html_document: default
subtitle: Initital analysis
editor_options: 
  chunk_output_type: console
---


```{r setup, eval = T, echo = F, warning = F, message = F, results = 'hide'}

library(MyFunctions)

#### Project's Library
packages <- c(
  "dbemImport",
  "tidyverse",
  "here", # for dbem_import `here()`da
  "data.table", #dbem_import `fread()`
  "readxl", # for reading excell files
  "janitor", # for clearing names
  "geosphere", # estimate distances between points `distm()`
  "ggrepel",
  "zoo", # for average mean
  "parallel", # for mclapply,
  "sf", # for mapping
  "st", # for mapping
  "rgdal", #Spatial analysis
  "tools", #Spatial analysis 
  "zeallot", # for Juanito's map
  "gmt", # for estimating distances between points
  "viridis",
  "cowplot",
  "rfishbase",
  "stargazer", # For nice lm tables
  "tidytext", # for boxplot order
  "moments", # for skewness and kurto
  "pgirmess" # for non parametric post hoc test
)

my_lib(packages)

```


# Methods

See methods section of the paper (e.g. Manusript.Rmd)

## Creating Data

Here we re-arrange existing data for the analysis. We have three steps:

1- Set the SAU relations between index and EEZs and include lat long data for each index

2.- Deteremine the centroid of each EEZ and asigned an id to each neighbouring interaction (e.g. Chile and Peru or Canada West Coast and US West Coast) 

3.- Set Neigbouring IDs based on the interactions between neighbouring EEZs for all of those sharing transboundary species

```{r pre_data_creation, eval = F, echo = F}

## ---------------##
#### 1. SAU relations between INDEX and Country's EEZs
# Re-ran with new names data
## ---------------##

# EEZIDs_List <- my_path("G", extra_path = "Spatial/V_Lam", name="Updated_EEZList_17June2016.xlsx", read = TRUE) %>%
  # clean_names()

EEZ_CellID <- my_path("G", extra_path = "Spatial/DBEM", name="EEZ_CellID.xlsx", read = TRUE) %>%
  clean_names()
colnames(EEZ_CellID) <- c("eezid","index")

# SAU name relatioal table (Fish For Visa)
sau_clean_names <- my_path("G", extra_path = "Spatial/SAU/", name="matching_names.csv", read = TRUE)

Lon_Lat_DBEM <- my_path("G", extra_path = "Spatial", name="Lon_Lat_DBEM.txt", read = TRUE, header = FALSE)
colnames(Lon_Lat_DBEM) <- c("index","lon","lat")


# Index_Code <- EEZIDs_List %>% 
#   left_join(EEZ_CellID) %>% 
#   rename(eez_name = name) %>% 
#   left_join(Lon_Lat_DBEM,
#             by = "index")


Index_Code <-  sau_clean_names %>% 
  select(eezid = sf_eezid) %>% 
  left_join(EEZ_CellID,
            by = "eezid") %>% 
  left_join(Lon_Lat_DBEM,
            by =  "index")

# Save Index data for future 
# write_csv(index_code,
          # paste(my_path("G",extra_path = "Spatial/DBEM"),"sau_index_code.csv",sep="")
          # )

## ---------------##
#### 2. entroids 
## ---------------##

# Load SAU shapefile name and paths

# The path
Path_SAU <- my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile")

# The File
File_Name <- "SAUEEZ_July2015.shp"

# Load it!
SAU_eez_sf <- st_read(dsn = Path_SAU,
                        layer =file_path_sans_ext(File_Name)
                      ) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1)

# Get the center poligon of each EEZ for map source/target with st_centroid
coords <- as.data.frame(st_centroid(SAU_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,
                             ifelse( eez_name == "Brazil",-36.937,longitude
                             )
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

# Double check coords
# Note that Australia and Ggreenland have points in the middle of the country because of the EEZ shape

coords_map <- ggplot() +
  geom_sf(data = SAU_eez_sf, aes(), fill = NA) +
  geom_point(data = eez_centroid,
             aes(
               x = longitude,
               y = latitude
             )
  )

ggsave("coords_map.png",
       plot = coords_map,
       width = 10,
       height = 8,
       units = "in"
       )
  

# Save dataframe so we don't need to run this ewvery time
# write_csv(coords,
#           "eez_centroids.csv")


## ---------------##
#### 3. Set Neigbouring IDs
## ---------------##

# Read transboundary species database from Palacios-Abrantes et al 2020 (FishForVisa)
Transboundary_spp <- my_path("D", extra_path = "Species/", name="Transboundary_spp.csv", read = TRUE)

# Get id of neighbouring pairs
Neighbours_spp <- Transboundary_spp %>% 
  group_by(eez_name,eez_neighbour) %>% 
  summarise(n=n()) %>% 
  ungroup() %>% 
  select(-n) %>% 
  rownames_to_column("neighbour_id")

# Split dataframes to merge neighbouring ids
df1 <- Neighbours_spp
df2 <- Neighbours_spp
colnames(df2) <- c("neighbour_id", "eez_neighbour", "eez_name")

# Merge neighbouring ids
df_full <- bind_rows(df1, df2) %>% 
  group_by(eez_neighbour,eez_name) %>% 
  summarise(neighbour_id = min(neighbour_id))

# Save dataframe so we don't need to run this every time
# write_csv(df_full, 
#           "Neighbours_eez_id.csv")
    
```

## Estimating Proportion Change

This part of the analysis estimates the Stock Share Ratio and its change under cliamte change under two time frames; early (2030) and mid (2050). Note that 2020 is the average of 2021 to 2040 and mid is the average of 2041 to 2060.


### Fun `EstPropChange`

```{r EstPropChange, eval = F, echo = F}

EstPropChange <- function(taxon_key,
                          year,
                          hist_y = 2005,
                          data_type = "Catch",
                          ensemble_list, # expects a list of ensembles to averrage by
                          path,
                          neighbours){
  
  
  # Loads species data for all ensembles
  Spp_Dist <- bind_rows(
    lapply(
      ensemble_list,
      read_dbem_ens,
      taxon_key = taxon_key,
      year = year,
      data_type = data_type,
      model = "GFDL",
      rcp = "85",
      # path = "/Volumes/DATA/DATA",
      my_path = F
    )
  )
  

  # Filter Species distribution to that of the neighbouring EEZs
  # ------------ #
  # Warning message:
  # Column `eez_name` joining factor and character vector, coercing into character vector 
# ------------ #
  
  suppressWarnings(
    Trans_EEZ <- Transboundary_spp %>% 
      filter(taxon_key %in% Spp_Dist$taxon_key) %>% 
      left_join(index_code,
                by = c("eez_name")
      )
    )
  
  # Get neighbouring id
  Neighbours_List <- Neighbours %>% 
    semi_join(Trans_EEZ,
              by = c("eez_name","eez_neighbour")
    )
  
  # Selecting only the transboundary nature of the species
  Trans_Spp <- Spp_Dist %>%
    filter(index %in% Trans_EEZ$index) %>% 
    left_join(index_code,
              by = "index") %>% 
    filter(eez_name %in% Neighbours_List$eez_name)
  
  # -------------------- #
  # Estimate area index
  # The number of species' cells present within each country's EEZ
  # -------------------- #
  
  #Determines the amount of catch present in each country
  Spp_Grid <- Trans_Spp %>% 
    group_by(taxon_key,
             eez_name,
             year,
             ensemble) %>% 
    summarise(n_spp_eez = length(unique(index)),
              total_mcp = sum(value)
              ) %>% 
    left_join(Neighbours_List,
              by = "eez_name")
  
  # Split dataframes to merge latter
  Territory_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      taxon_key,
      Name=eez_name,
      n_spp_eez,
      total_mcp,
      year,
      ensemble
    )
  
  Neighbour_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      taxon_key,
      n_spp_eez,
      total_mcp,
      Name=eez_neighbour,
      eez_name,
      year,
      ensemble
    )
  
  # Estimate Area index and % change
  Per_Ghange_D <- full_join(Territory_T,
                            Neighbour_T, 
                            by = c("Name","taxon_key","year","ensemble")
  ) %>%
    rowwise() %>%
    mutate(Spp_Total = sum(n_spp_eez.x,n_spp_eez.y,na.rm=T),
           MCP_Total = sum(total_mcp.x,total_mcp.y,na.rm=T)) %>% # Total gridcelles per Neighbours
    distinct() %>% # Removes false duplicates from `full_join()`
    rename(eez_name = Name,
           eez_neighbour =eez_name,
           n_spp_Country = n_spp_eez.x,
           n_spp_Neighbour = n_spp_eez.y,
           mcp_Country = total_mcp.x,
           mcp_Neighbour = total_mcp.y) %>% 
    mutate(area_index = n_spp_Country/Spp_Total,
           catch_proportion = mcp_Country/MCP_Total) %>% 
    # Determine the three time frames for comparrison
    mutate(
      time_step = ifelse(year < hist_y,"historical",
                         ifelse(year >= 2021 & year <= 2040, "early",
                                ifelse(year >= 2041 & year <= 2060, "mid","NA")
                         )
      )
    ) %>%
    filter(time_step != "NA") %>% 
    # Time mean and sd
    ungroup() %>% 
    group_by(taxon_key,ensemble,eez_name,eez_neighbour,time_step) %>% 
    summarise_at(vars("area_index","catch_proportion"),
                 c(temp_mean=mean,
                   tempo_sd=sd)
    ) %>% 
    # ensemble mean and sd
    group_by(taxon_key,eez_name,eez_neighbour,time_step) %>%
    summarise_at(vars("area_index_temp_mean","catch_proportion_temp_mean"),
                 c(ensemble_mean = mean,
                   ensemble_sd = sd
                   )
    )
  
  # --------------- #
  # End function
  # --------------- #
  
  if(nrow(Per_Ghange_D) > 0){
  
  # Save Result
  name <- paste("proportion_",taxon_key,".csv",sep="")
  path_name <- paste(my_path("R",extra_path = "Proportion_2005"),name,sep= "")
  
  write_csv(Per_Ghange_D,
            path_name)
  
  return(print(paste("analysis done",taxon_key)))
  # return(Per_Ghange_D)
  
  }else{
    print(paste("no result for",taxon_key))
  }
  
  # Or return a df
  # return(Per_Ghange_D)
}

EstPropChange(taxon_key = 600004,
              year = year_df$year,
              hist_y = 2000,
              data_type = "Catch",
              ensemble_list = c(102,103,104),
              # path = path,
              neighbours = neighbours)



```

### Proportion Control Panel

```{r Proportion_control_panel, eval = F, echo = F}

## ----------------- ##
# Data needed for estimating year of emergence
## ----------------- ##

# SAU relations between INDEX and Country's EEZs (see chunk 3)
index_code <- my_path("G", extra_path = "Spatial/SAU/", name="sau_index_code.csv", read = TRUE)

# Neighbour list and their respective id (see chunk 3)
Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE)

# Transboundary species and their sharing EEZs (see Palacios-Abrantes et al; FishForVisa)
Transboundary_spp <- my_path("D", extra_path = "Species/", name="Transboundary_spp.csv", read = TRUE) %>% 
  clean_names() %>% 
  select(-v1) 

## ----------------- ##
# Global variables
## ----------------- ##

# Year timeframe
year_df <- tibble(year =  c(seq(1951,2005,1), seq(2006,2099,1)),
                  time_period = c(rep("historic", 55), rep("future", 94))
                  )

# List of ensemble members
# ensemble_list <- seq(102,103,1) # for testing
ensemble_list <- seq(102,111,1)

#  List os species
spp_list <- unique(Transboundary_spp$taxon_key)

modeled_spp <- list.files(my_path("R", extra_path = "Proportion_n"))

modeled_spp <- gsub("proportion_","",modeled_spp)
modeled_spp <- gsub(".csv","",modeled_spp)

spp_list <- spp_list[!spp_list %in% modeled_spp]


```

### Proportion routine

```{r Proportion_routine, eval = F, echo = F}

####_______________________ ####
# Estimating proportion change
####_______________________ ####
gc()
t_start <- Sys.time()

mclapply(
  spp_list,
  EstPropChange,
  year = year_df$year,
  data_type = "Catch",
  ensemble_list = ensemble_list,
  path = DBEM_path,
  neighbours = Neighbours
)

t_end <- Sys.time()-t_start;t_end

# Hall 1000 ran it in 5.33 hours past
# Hall 1000 ran it in  hours (July 2020)

```

## Estimating emerging year

This rutine estimates the time (e.g. year) in which the changes in stock share ratio is more likely to happen based on historical variations (e.g. model noise) and future trends (e.g signal). This result uses teh average of the 10 ensemble members

### Fun `GetCentroids` 

This function estimates the distance between the centroid of each neighbouring EEZ and the distribution of the species along both EEZs. We define species centroid as the tile with the highest value of maimum catch potential from all of the species distribution in each year.

```{r GetCentroids, eval = T, echo = F}

GetCentroids <- function(taxon_key,
                         year, 
                         data_type = "Catch",
                         ensemble, 
                         path,
                         Neighbours,
                         eez_centroid,
                         p # percentile of data for central distribution
                         ){
  
  # ----------------- #
  # Get model data from spps for one ensemble
  #  ---------------- #
 if(ensemble == 102){
   print(taxon_key)
 }
    
  Spp_Dist <- read_dbem_ens(
    taxon_key = taxon_key,
    year = year,
    data_type = data_type,
    ensemble = ensemble, # change me to ensemble
    path = my_path("G","DBEM")
  )

  # ----------------- #
  # Extra step 
  # ----------------- #
  
  #### Creates a data to control computational time (lol!)
  #   if(file.exists(paste(my_path("R"),"spp_df.csv",sep="")) == FALSE){
  #   spp_df <- tibble() %>% 
  #     write_csv(.,
  #               paste(my_path("R"),"spp_df.csv",sep=""))
  # }
  # 
  # suppressMessages(
  #   spp_df <- my_path("R",name="spp_df.csv",read = TRUE)
  # )
  # spp_df <- tibble(taxon_key,
  #                  ensemble) %>% 
  #   bind_rows(spp_df) %>% 
  #   write_csv(.,
  #             paste(my_path("R"),"spp_df.csv",sep=""))

  # ----------------- #
  # Estimate distance between centroids
  # ----------------- #
  
  # Filter only the transboundary nature of the species 
  Trans_Spp <- Spp_Dist %>%
    left_join(index_code,
              by= "index") %>% 
    filter(!is.na(value)) %>% 
    semi_join(Transboundary_spp, # filter only transboundary cases
              by = c("taxon_key","eez_name")
    )
  
  # ----------------- #
  # Extra step 
  # ----------------- #
  # Controls for cases with no-data
  nr <- nrow(Trans_Spp)
  if(nr > 0){
    
    # Filter eez by those transboundary
    unique_eez <- unique(Trans_Spp$eez_name)
    
    Neighbours_combo <- Neighbours %>% 
      filter(eez_name %in% unique_eez,
             eez_neighbour %in% unique_eez)
    
    # Get the centroid of each country
    EEZ_centroid <- eez_centroid %>% 
      filter(eez_name %in% Trans_Spp$eez_name) %>% 
      mutate(taxon_key = taxon_key)
    
    # ----------------- #
    # Centroid function
    # ----------------- #
    
    # This function estimates the distance of each neighbouring EEZ
    # It uses Ids wich is a pre-determine identifier of neighbouring
    # EEZs. Fo example Peru and Chile have Id = 167, and viceversa
    
    CentroidsFx <- function(Ids){  
      
      # Filter data by Ids
      EEZ_ids <- Neighbours_combo %>% 
        filter(neighbour_id == Ids)
      
      Sub_Trans_Spp <- Trans_Spp %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      Sub_EEZ_centroid <- EEZ_centroid %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      # Function to get percentiles
      # https://www.tidyverse.org/blog/2020/03/dplyr-1-0-0-summarise/
      quibble <- function(x, q = p) {
        tibble(x = quantile(x, q), q = q)
      }

      # Get the percentile treshold per year, ensemble and neighbour id
      percentile <- Sub_Trans_Spp %>% 
        left_join(EEZ_ids, by = "eez_name") %>% 
        group_by(taxon_key,year,ensemble,neighbour_id) %>%  # for whole distribution
        do(quibble(.$value, p))
      
       Centroids <- Sub_Trans_Spp %>% 
         left_join(EEZ_ids, by = "eez_name") %>% 
         left_join(percentile,
                   by = c("taxon_key","year","ensemble","neighbour_id")
                   ) %>% 
         mutate(to_filter = ifelse(value < x,"out","keep")) %>% 
         filter(to_filter == "keep") %>% 
         group_by(taxon_key,year,ensemble,neighbour_id) %>%  # for whole distribution
         summarise_at(vars(lon,lat),mean) %>% 
         left_join(Sub_EEZ_centroid, by = "taxon_key") %>%
         # select(eez_name =eez_name.y, everything() ,-eez_name.x) %>% 
         # Estimate distances between spp centroid and EEZ centroid
         mutate(
           distance = geodist(longitude, # eez longitude
                              latitude,  # eez latitude
                              lon,  # species longitude
                              lat, # species latitude
                              units="km")
         ) %>% 
         select(taxon_key,eez_name,neighbour_id,ensemble,year,distance)
       
       ### Code to produce graphs for Brazil and ruguay
       
       # name <- paste(taxon_key, "distrbution p = 90%") 
       # Centroids %>% 
       #   # filter(year %in% c(1951,2000,2010)) %>% 
       #   ggplot() +
       #   geom_point(
       #     aes(
       #       x = lon,
       #       y = lat,
       #       size = distance,
       #       color = year,
       #       shape= eez_name
       #     )
       #   ) +
       #   geom_point(
       #     aes(
       #       x = longitude,
       #       y = latitude,
       #     ),
       #     fill = "red"
       #   ) +
       #   geom_sf(data = braur_sf,
       #           aes()
       #   )  +
       #   ggtitle(name)
       # 
       # ggsave(paste(taxon_key,"distribution.jpg",sep="_"),
       # plot = last_plot(),
       # width = 10,
       # height = 8,
       # units = "in",
       # path = my_path("D")
       # )
       
      return(Centroids)
      
    }
    
    # Determine the ids
    Ids <- unique(Neighbours_combo$neighbour_id)
    
    # Run sub-function
    Centroids_Data <- bind_rows(
      lapply(Ids,CentroidsFx)
    )
    
  }else{
    # In case there's no data
    Centroids_Data <- tibble()
    
  }
  
  return(Centroids_Data)
  
}

# Test function

# GetCentroids(taxon_key = 600076,
#              year = year_df$year[1:5],
#              data_type = "Catch",
#              ensemble = 102,
#              Neighbours = Neighbours,
#              eez_centroid = eez_centroid
#              )

# head(Test_centroids)
# unique(Test_centroids$ensemble)
# unique(Test_centroids$neigh)
# 




# braur_sf <- World_ %>% 
#   filter(name %in% c("Brazil","Uruguay"))

# ggplot(braur_sf) +
#   geom_sf() +
  # geom_point(data = subset(Centroids, year %in% seq(1951,2100,20)),
  # geom_point(data = subset(Centroids,eez_name =="Brazil"),
  # geom_point(data = Centroids,
  #            aes(
  #              x = lon,
  #              y = lat,
  #              color = year#,
  #              # size = value
  #            )
  # ) #+
  # facet_wrap(~to_filter+eez_name)


```

### Fun `TransIndex`

This functions takes on `GetCentroids` function and estimates the TransIndex (*TI*) for each pair of neighbouring countries. Presents a 10 years average of the results

$$TI =(\frac{D_{A,y}}{sd(D_{A,h})} - \frac{D_{B,y}}{sd(D_{B,h)}})^2$$

The year of emergece is defined as the first year where the trend is larger than the 95% CI of the historic variation.

Note: If no historic data available then emerging year is the first year of data in an EEZ

```{r TransIndex, eval = T, echo = T}

TransIndex <- function(Centroids, # Expecting the results from the GetCentroids function
                       Id, # A numeric value representing a neighbouring interaction (ONE!)
                       Hist_y = 2005,
                       Plot = F){ # The LAST year of Historical data
  
  
  # Filter data by neighbouring ID
  Centroids_id <- Centroids %>% 
    filter(neighbour_id %in% Id)
  
  EEZ_ids <- Neighbours %>% 
    filter(neighbour_id %in% Id)

  # Historical mean and sd of distance
  historical <- Centroids_id %>%
    filter(year <= Hist_y) %>% 
    ungroup() %>%
    group_by(taxon_key,ensemble,eez_name,neighbour_id) %>%
    summarise_at(vars("distance"),
                 c(hd_temp_mean=mean,
                   hd_temp_sd=sd,
                   n_yrs =~n())
                 )
  
    # Future results
  future <- Centroids_id %>% 
    filter(year > Hist_y)
  
   # Get unique eezs
  Unique_EEZs <- unique(EEZ_ids$eez_name)
  
  # Transboundary Index
  Trans_index <- Centroids_id %>% 
    left_join(historical,
              by = c("taxon_key","eez_name","ensemble","neighbour_id")
    ) %>%
    # Re arrenging table for mutate
    gather("variable","value",distance:hd_temp_sd) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.na(value),0,value)) %>% 
    mutate(
      names = ifelse(eez_name ==Unique_EEZs[1],paste("Country_A",variable,sep="_"),paste("Country_B",variable,sep="_")
    )
    ) %>%
    select(-eez_name,-variable) %>%
    spread(names,value) %>% 
    # mutate index
    mutate(
      trans_index = (Country_A_distance/Country_A_hd_temp_sd - Country_B_distance/Country_B_hd_temp_sd)^2
    # )
    ) %>% 
    # Ten years average of results
    group_by(taxon_key,ensemble,neighbour_id) %>% 
    mutate(RMean = rollmean(x = trans_index, 
                            10, 
                            align = "right", 
                            fill = trans_index,
                            na.rm=T)
    ) %>% 
    # filter(year > 1960) %>%
    select(taxon_key,neighbour_id,year,ensemble,trans_index,RMean)
  
  # Average of 10 years mean of ensemble members results
  mean_sd_index <- Trans_index %>% 
    group_by(taxon_key,year,neighbour_id) %>% 
    summarise_at(vars("RMean"),
                 c(trend=mean,
                   ensemble_sd=sd,
                   n_ens = ~n()
                   
    ),
    na.rm=T
    )
    
    # Valid ensembles
  # Only perform analysis on ensembles containing all years between 1951 and 2040
    n_years <- mean_sd_index %>% 
      group_by(n_ens) %>% 
      summarise(
        n_year = n()
      ) %>% 
      filter(
        n_year == 149
      )
    
    mean_sd_index <- mean_sd_index %>% 
      filter(n_ens %in% n_years$n_ens)
  
  # Estimate noice from ensemble members
  historic_sd <- Trans_index %>% 
    filter(year <= Hist_y) %>% 
    group_by(taxon_key,neighbour_id,ensemble) %>% #Average historic data per year first
    summarise_at(vars("trans_index"),
                 c(trend= mean),
                 na.rm=T
                 ) %>% 
    group_by(taxon_key,neighbour_id) %>% #Capture ensemble variation
    summarise_at(vars("trend"),
                 c(hist_mean=mean,
                   noise=sd,
                   n_ens = ~n())
                 )
  
  
  # For testing
  if(Plot == T & length(historic_sd$hist_mean) > 1){
  # Plot the result, bruh
  
  # Step to determine if data exists
  Plot_Test <- nrow(subset(mean_sd_index, trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise)))>0
  
  ggplot() +
    geom_line(data = mean_sd_index,
              aes(
                x = year,
                y = trend
              )
    ) +
    geom_ribbon(data = mean_sd_index,
                aes(x=year,
                    ymin=historic_sd$hist_mean-historic_sd$noise,
                    ymax=historic_sd$hist_mean+historic_sd$noise),
                alpha = 0.5,
                fill = "grey50"
    ) +
    geom_ribbon(data = mean_sd_index,
                aes(x=year,
                    ymin=historic_sd$hist_mean-(historic_sd$noise*2),
                    ymax=historic_sd$hist_mean+(historic_sd$noise)*2)
                ,
                alpha = 0.5,
                fill = "grey30"
    ) +
    geom_line(data = mean_sd_index,
              aes(
                x = year,
                y = historic_sd$hist_mean
              ),
              colour = "grey50"
    ) +
    # Conditional, will only plot circles if the data exists
    {if(Plot_Test)geom_point(data = subset(mean_sd_index, trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise)),
               aes(
                 x = year,
                 y = trend,
                 colour = "red",
               ),
               shape = 1,
               size = 3
    )
      } +
    geom_vline(xintercept = Hist_y,colour="blue",alpha = 0.5) +
    scale_x_continuous(breaks = seq(1950,2100,5)) +
    theme_classic()
  
    tk <- unique(mean_sd_index$taxon_key)
  
    ggsave(paste(tk,Id,"plot_example.jpg",sep="_"),
       plot = last_plot(),
       width = 10,
       height = 8,
       units = "in",
       path = my_path("R")
       )
  
  }
  
  # If no historic data then emergin year is the first year of data
  if(nrow(historic_sd) == 0){
    
    Final_Result <- mean_sd_index %>%
      group_by(taxon_key,neighbour_id,n_ens) %>%
      summarise(emerging_yr= min(year)) %>%
      left_join(EEZ_ids,
                by = "neighbour_id") %>%
      ungroup() %>%
      select(taxon_key,eez_name,eez_neighbour,n_ens,emerging_yr) %>% 
      mutate(tresh= NA)
  
  return(Final_Result)
    
  }else{
  
    Raw_Result <- mean_sd_index %>%
      filter(year > Hist_y) %>%
      mutate(
        tresh_one = ifelse(trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise),"One",NA),
        tresh_two = ifelse(trend > (historic_sd$hist_mean+(2*historic_sd$noise)) | trend < (historic_sd$hist_mean-(2*historic_sd$noise)),"Two",NA)
      ) %>%
      gather("tresh","emerged",tresh_one,tresh_two) 
    
    
    taxon <- unique(Raw_Result$taxon_key)
    name_raw <- paste(my_path("R",extra_path = "/Emergence_last_raw_p90/"),taxon,"_emergence_raw.csv",sep="")
    
    write_csv(Raw_Result,
              name_raw)
    
    ToE_Result <- Raw_Result %>% 
    # Method the last year when the index overshoots and never goes back
      filter(is.na(emerged)) %>% 
      group_by(taxon_key, neighbour_id,n_ens,tresh) %>% 
      summarize(emerging_yr = max(year)+1) %>% # last year of NA + 1 makes it the first year of overshooting
      left_join(EEZ_ids,
                by = "neighbour_id") %>%
      ungroup() %>%
      select(taxon_key,eez_name,eez_neighbour,n_ens,emerging_yr,tresh)
  
  return(ToE_Result)
  }
}
  



```

### Fun `GetTransIndex`

This is the last function of the emerging year evaluation. It was made so we could run the analysis per each species. The function function simply runs the functions `GetCentroids` by ensabmble member and then `TransIndex` by pairing EEZ. Thus, with this function we run the whole set by species * paired EEZ * ten ensemble members. 

```{r GetTransIndex, eval = T, echo = T}
  
GetTransIndex <- function(taxon_key,
                          year,
                          Hist_y,
                          data_type = "Catch",
                          path,
                          ensemble_list,
                          Neighbours,
                          eez_centroid,
                          p = NA,
                          Plot = F){
  t_start <- Sys.time()
  print("Starting Step One")
    # First step
    # Call Get centroids fucntion for centroids data per ensemble
  
  Step_one <- bind_rows(
      lapply(ensemble_list,
             GetCentroids,
             taxon_key = taxon_key, # for testing
             year = year_df$year,
             data_type = data_type,
             Neighbours = Neighbours,
             eez_centroid = eez_centroid,
             p = p
             )
    )
  
    
    # Set the different neighbouring pairs
    Ids <- unique(Step_one$neighbour_id)
    
    print("Starting Step Two")
    
    # Second Step
    # Get the transboudary index based on all centroids
    Step_two <- bind_rows(
      lapply(Ids,
             TransIndex,
             Hist_y = Hist_y,
             Centroid = Step_one)
    )
    
    name <- paste(my_path("R",extra_path = "/Emergence_last_p90/"),taxon_key,"_emergence.txt",sep="")
    
    write_csv(Step_two,
              name)
    
    time_dif <- Sys.time()-t_start
     
    message <- paste("Analysis done for", taxon_key, "in",time_dif, "minutes")
    return(message)
  }
  
  
  # GetTransIndex(
  #   taxon_key = 600076,
  #   ensemble_list = ensemble_list,
  #   year = year_df$year,
  #   Hist_y = 2000,
  #   data_type = "Catch",
  #   Neighbours = Neighbours,
  #   eez_centroid = eez_centroid
  # )


  # spp_list <- c(600004, 600245)
  # 
  #  test <- bind_rows(
  #   lapply(spp_list,
  #          GetTransIndex,
  #          year = year,
  #          data_type = "Catch",
  #          path = path,
  #          Neighbours = Neighbours,
  #          eez_centroid = eez_centroid,
  #          ensemble_list = ensemble_list
  #   )
  # )
  # 
    
```

### Emerging Control Panel

```{r Emerging_control_panel, eval = T, echo = T}

## ----------------- ##
# Data needed for estimating year of emergence
# Note: Use repo = F when running on the Beast or Hall1000
## ----------------- ##

# SAU relations between INDEX and Country's EEZs (see chunk 3)
index_code <- my_path("G", extra_path = "Spatial/SAU/", name="sau_index_code.csv", read = TRUE)

# EEZ list and their centroid of distribution (see chunk 3)
eez_centroid <- my_path("D", extra_path = "Spatial/", name="eez_centroids.csv", read = TRUE)

# Neighbour list and their respective id (see chunk 3)
Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE)

# Transboundary species and their sharing EEZs (see Palacios-Abrantes et al; FishForVisa)
Transboundary_spp <- my_path("D", extra_path = "Species/", name="Transboundary_spp.csv", read = TRUE) %>% 
  clean_names()

# ------------------------------------------- #
### Estimate number of transboundary stocks ###
# ------------------------------------------- #

Transboundary_spp %>% 
  left_join(Neighbours,
            by = c("eez_name", "eez_neighbour")) %>% 
  # filter(neighbour_id %in% c(1,105)) %>%
  # filter(neighbour_id == 470) %>%
  group_by(neighbour_id) %>% 
  summarise(n_stock = length(unique(taxon_key))) %>% 
  # View()
  group_by() %>% 
  summarise(t_trans_stocks = sum(n_stock)) # 9132


## ----------------- ##
# Global variables
## ----------------- ##

# Year timeframe
year_df <- tibble(year =  seq(1951,2099,1))

# Last year of "historic" data
Historic_year = 2005

# Data path
# path = DBEM_path

# List of ensemble members
# ensemble_list <- seq(102,103,1) # for testing
ensemble_list <- seq(102,111,1)

#  List os species
spp_list <- unique(Transboundary_spp$taxon_key)

# Already modeled species
spp_done <- list.files(my_path("R", extra_path = "Emergence"))

spp_done <- gsub("\\_.*","",spp_done)

spp_reman <- spp_list[!spp_list %in% spp_done]

rand_plot <- sample(spp_reman,5)


```

### Emerging Routine

```{r Emerging_routine, eval = F, echo = F}

####_______________________ ####
# Estimating year of eergence
####_______________________ ####
# n_cores <- 24
t_start <- Sys.time()

gc()

    Emerging_result <- bind_rows(
      mclapply(spp_list,
               GetTransIndex,
               year = year_df$year,
               Hist_y = Historic_year,
               data_type = "Abd",
               ensemble_list = ensemble_list,
               Neighbours = Neighbours,
               eez_centroid = eez_centroid,
               p = 0.90,
               Plot = F
      )
    )

``` 


```{r Emerging_routine_DoPar, eval = F, echo = F}

library(doParallel)
library(doSNOW)

cl <- makeCluster(12)
registerDoSNOW(cl)


# To show processing times
repetitions <- length(spp_reman)
pb <- txtProgressBar(max = repetitions, style = 3)

progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)


foreach(i=1:repetitions,
        .combine = rbind,
        .packages = c("MyFunctions",packages),
        .options.snow = opts,
        .verbose = T) %dopar% 
  GetTransIndex(
    taxon_key =spp_reman[i],
    ensemble_list = ensemble_list,
    year = year_df$year,
    Hist_y = 2000,
    data_type = "Catch",
    Neighbours = Neighbours,
    eez_centroid = eez_centroid
  )

close(pb)
stopCluster(cl)

```


## SST time of emergence


##### Fun `GetEnvData`

```{r get_env_data, eval = F, echo = T}

getEnvVar=function(yr,ensemble,variable){
  
  filepath <- paste("/Volumes/DATA/DATA/Environmental data/GFDL_CMIP5_Large_Ensemble/All var/ens",ensemble,"/",sep="")
  
    file = paste(variable,"_",yr,".txt",sep="")
    read_me <- paste(filepath,file,sep="")
    
    data <- bind_cols(lapply(read_me,FUN= data.table::fread, na.strings = "NA",header=F)
      ) %>% 
      mutate(index = seq(1,259200,1))
    
    colnames(data) <- c(as.character(ensemble),"index")
    
      
    data <- data %>% 
      gather("ensemble","variable",1:length(ensemble)) %>%  # fix it has to be untill 10
      mutate(variable = ifelse(variable == -9999.00000,NA,variable)) # Fixing NAs connotation
  
  
  # Retrun
  
  getTemp <- data %>% 
    mutate(ensemble = ensemble,
           year = yr)
  
  return(getTemp)
}

```

```{r temp_emergence, eval = F, echo = F}


TempEmer <- function(yrs, hist_y = 2005, variable, ensemble){ # The LAST year of Historical data
  
  # Load environmental data
  sst_data <- bind_rows(
    lapply(
      yrs,
      getEnvVar, 
      ensemble = ensemble, 
      variable = variable
    )
  ) %>% 
    left_join(index_code,
              by = "index") %>%  # join with EEZ indexes
    select(-lat,-lon,-eez_name) %>% 
    filter(!is.na(eezid)) %>% 
    # Get average temperature per eez
    group_by(ensemble,eezid,year) %>%
    summarise_at(vars("variable"),
                 c(hd_eez_mean=mean),
                 na.rm=T
    ) %>% 
    # estimate 10 years running mean
    group_by(ensemble,eezid) %>% 
    mutate(Rmean = rollmean(x = hd_eez_mean, 
                            10, 
                            align = "right", 
                            fill = hd_eez_mean)
    )
  
  # Average of 10 years mean of ensemble members results
  mean_sd_index <- sst_data %>% 
    group_by(eezid,year) %>% 
    summarise_at(vars("Rmean"),
                 c(trend=mean,
                   ensemble_sd=sd,
                   n_ens = ~n()
                   
    ),
    na.rm=T
    )
  
  # Historic data
  historical <- sst_data %>%
    filter(year <= hist_y) %>%
    ungroup() %>%
    # get EEZ time average
    group_by(ensemble,eezid) %>%
    summarise_at(vars("Rmean"),
                 c(hd_temp_mean=mean),
                 na.rm= T
    ) %>% 
    # get ensemble member mean and noice
    group_by(eezid) %>% 
    summarise_at(vars("hd_temp_mean"),
                 c(hist_mean=mean,
                   noise = sd),
                 na.rm = T
    )
  
  
  
  # ----------------------- #
  # Plot for data viz
  # ----------------------- #
  
  # samp <- sample(mean_sd_index$eezid,30,replace = F)
  
  # mean_sd_index <- mean_sd_index %>% 
    # filter(eezid %in% samp)
  
  

    # plot_data <- mean_sd_index %>% 
  # left_join(historical,
  #           by = "eezid")
    
  
  # ggplot() +
  #   geom_line(data = plot_data,
  #             aes(
  #               x = year,
  #               y = trend
  #             )
  #   ) +
  #   geom_ribbon(data = plot_data,
  #               aes(x=year,
  #                   ymin=hist_mean-noise,
  #                   ymax=hist_mean+noise
  #                   ),
  #               alpha = 0.5
  #   ) +
  #   geom_line(data = plot_data,
  #             aes(
  #               x = year,
  #               y = hist_mean
  #               ),
  #             linetype = "dashed"
  #   ) +
  #   facet_wrap(~eezid,
  #              scales = "free") +
  #   # Conditional, will only plot circles if the data exists
  #   geom_point(data = subset(plot_data, trend > (hist_mean+noise) | trend < (hist_mean-noise)),
  #              aes(
  #                x = year,
  #                y = trend,
  #                colour = "red",
  #              ),
  #              shape = 1,
  #              size = 3
  #   ) +
  #   geom_vline(xintercept = hist_y,colour="black",alpha = 0.5) +
  #   scale_x_continuous(breaks = seq(1950,2100,5)) +
  #   theme_classic()
  
  
  # Future results
  future <- sst_data %>% 
    filter(year > hist_y) %>% 
    # get ensemble member mean and noice
    group_by(eezid,year) %>% 
    summarise_at(vars("Rmean"),
                 c(trend=mean,
                   f_noise = sd)
    ) %>% 
    group_by(eezid) 
  
  
  Final_Result <- future %>%
    left_join(historical,
              by = "eezid") %>% 
    mutate(
      tresh_one = ifelse(trend > (hist_mean+noise) | trend < (hist_mean-noise),"One",NA),
      tresh_two = ifelse(trend > (hist_mean+(2*noise)) | trend < (hist_mean-(2*noise)),"Two",NA)
    ) %>%
    gather("tresh","YesNo",tresh_one,tresh_two) %>% 
    filter(!is.na(YesNo)) %>% 
    group_by(eezid,tresh) %>% 
    summarise(emerging_yr = min(year))
  
  return(Final_Result)
}
 
gc()


sst <- TempEmer(
  yrs = seq(1951,2070,1),
  hist_y = 2005,
  variable = "SST",
  ensemble = seq(102,111,1)
)

write_csv(sst,
          "ToE_sst.csv")

botTemp <- TempEmer(
  yrs = seq(1951,2070,1),
  hist_y = 2005,
  variable = "botTemp",
  ensemble = seq(102,111,1)
)

write_csv(botTemp,
          "ToE_bottemp.csv")

test <- sst %>% 
  filter(tresh == "tresh_one")

hist(test$emerging_yr)

gc()

test_map <- World_eez_sf %>% 
  left_join(test,
            by = "eezid") %>% 
  ggplot() +
  geom_sf(
    aes(
      fill = emerging_yr
    )
  )+ scale_fill_viridis(
    limits = c(2000,2070),
    breaks = seq(2000,2070,10)#,
    # direction = -1
  ) +
  my_ggtheme_m() +
  ggsave("botTemp_ToE.png",
         width = 12,
         height = 10,
         units = "in"
  )

```


```{r william_code, eval = F, echo = F}

datascale<-subset(testdata,!is.na(MHW) & !is.na(MeanChange))
MHWBreaks<-c(0.2,0.4,0.5,0.6,0.8,2.1)
MeanChangeBreaks<-c(-0.4,0.6,0.7,0.8,1.0,2.0)
#testdata$MHW <- with(testdata, cut(MHW,
#                                   breaks=quantile(MHW, probs=seq(0,1, by=0.2), na.rm=TRUE),
#                                   include.lowest=TRUE))
testdata$MHW <- with(testdata, cut(MHW,
                                   breaks=MHWBreaks, na.rm=TRUE),
                                   include.lowest=TRUE)
testdata$MHW <- as.numeric(testdata$MHW)
#testdata$MeanChange <- with(testdata, cut(MeanChange,
#                                          breaks=quantile(MeanChange, probs=seq(0,1, by=0.2), na.rm=TRUE),
#                                          include.lowest=TRUE))
testdata$MeanChange <- with(testdata, cut(MeanChange,
                                          breaks=MeanChangeBreaks, na.rm=TRUE),
                                          include.lowest=TRUE)

testdata$MeanChange <- as.numeric(testdata$MeanChange)  

library(ggplot2)
d <- data.frame(testdata,fill_val = rgb(blue=0.5,red = testdata$MHW/5, green = testdata$MeanChange/5))

world <- map_data("world")
map<- ggplot(d, aes(x=lon, y=lat)) +
  geom_tile(aes(fill = fill_val)) +
  scale_fill_identity()+
  geom_cartogram(data=world, map=world,
                 aes(x=long, y=lat, map_id=region),fill="white",color="black")+
  coord_quickmap(xlim=c(-180,180), ylim=c(-89, 90))+
  ylab("")+
  xlab("")+
  scale_y_continuous(expand = c(0, -5))+
  scale_x_continuous(expand = c(0, 0))+
  labs(title=paste("(A) Sea Surface Temperature",sep=""))+
  theme(axis.line = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        legend.position="bottom",
        #panel.border = element_blank(),
        panel.border = element_rect(colour = "black", fill=NA, size=1),
        panel.background = element_blank(),
        #axis.text.y=element_blank(),
        axis.text=element_text(size=9,colour="black"),
        plot.title=element_text(hjust=0,vjust=-0.4,face="bold",size=24)
  )
dlegend <- expand.grid(x = seq(0, 1, 0.25), y = seq(0, 1, 0.25)) %>%
  mutate(mix2 = rgb(red = x, green = y, blue = 0.5))
library(cowplot)
xyLegend <- ggplot(dlegend, aes(x, y)) +
  geom_tile(aes(fill = mix2)) +
  scale_fill_identity() +
  labs(x = "Higher MHW change->",
       y = "Higher mean change->") +
  theme_void() +
  theme(axis.title = element_text(size = 8),
        axis.title.y = element_text(angle = 90)) +
  coord_fixed()
p=ggdraw() +
  draw_plot(map, 0, 0, 1, 1) +
  draw_plot(xyLegend, 0.05, 0.1, 0.2, 0.2)
#ggsave(p,filename="/Users/william/Google Drive/Projects/MHWs Global/MHW_SST_plot.png",height=9,width=8,dpi=300)
ggsave(map,filename="/Users/william/Google Drive/Projects/MHWs Global/MHW_SST_plot_map.png",height=8,width=11,dpi=300) (edited) 


```

# Results

## Percentage Change

This results only shows the average percentage change in proportion of all speecies within an EEZ without relationship with neighbours

### Functions and Data needed

#### Fun `SummaryProp`

This function estimates the total change in MCP proportion of each species for each EEZ. It looses the connection with neighbours as you only know for x species houw much is the proportion changing.

```{r fun_SummaryProp, eval = F, echo =F}

SummaryProp <- function(taxon_key,links="NA"){
  
  # Reads taxon data
  proportion_data <- fread(paste(my_path("R",extra_path = "Proportion_2005c/"),"proportion_",taxon_key,".csv", sep="")) %>% 
    filter(!is.na(eez_neighbour)) %>% 
    select(
      1:4,
      ensemble_mean = catch_proportion_temp_mean_ensemble_mean,
      ensemble_sd = catch_proportion_temp_mean_ensemble_sd)
  
  # Identify SSR treshold for natural spatial variability of the stock
  proportion_tresh <- proportion_data %>% 
    filter(time_step == "historical") %>% 
    mutate(
      top_tresh = ensemble_mean+(2*ensemble_sd), # two s.d.
      low_tresh = ensemble_mean-(2*ensemble_sd) # two.s.d
    ) %>% 
    select(taxon_key:eez_neighbour,top_tresh:low_tresh) %>% 
    left_join(proportion_data) %>% 
    # Only keeps change if surpasses treshold
    mutate(
      over_tresh = ifelse(ensemble_mean > top_tresh | ensemble_mean < low_tresh,"keep",
                          ifelse(time_step == "historical","keep","drop")
      )
    ) %>% 
    filter(over_tresh == "keep") %>% 
    select(-top_tresh,-low_tresh)
  
  if(links == "y"){
    # summarizes by country and neighbour
    country_summary <- proportion_tresh %>% 
      group_by(taxon_key,eez_name,eez_neighbour,time_step) %>% 
      summarise(
        mean_spp = mean(ensemble_mean, na.rm = T) # average spp change from all countries sharing
      ) %>% 
      filter(!is.na(mean_spp))
    
  }else{
    # summarizes by country
    country_summary <- proportion_tresh %>% 
      group_by(taxon_key,eez_name,eez_neighbour,time_step) %>% 
      summarise(
        mean_spp = mean(ensemble_mean,na.rm=T) # average spp change from all countries sharing that speceies
      ) %>% 
      filter(!is.na(mean_spp))
    }
  
  return(country_summary)
}

```


#### Fun `EEZProp`

The next step is to summarize all species per eez so our results shows average change of all species within an EEZ towards a neighbour. 

**Note: Contains step to filter out changes less than +-2 s.d.**

```{r fun_EEZProp, eval = F, echo = F}

EEZProp <- function(taxon_list,links="NA"){
  
  spp <- bind_rows(
    lapply(taxon_list,SummaryProp,links)
  )
  
  
  if(links == "y"){
    
    # Percentage of SSR stocks changing
    n_ssr <- spp %>% 
      group_by(eez_name,time_step) %>% 
      summarise(
        # n_spp = length(unique(taxon_key)),
        n_stock = n(),
      ) %>% 
      spread(time_step,n_stock) %>% 
      mutate_at(vars(early,mid),
                .funs = ~(./historical)*100
      ) %>% 
      select(-historical) %>%
      gather("time_step","n_per",early:mid)
    
    # Min, max and median change per eez_name and neighbor
    eez_summary <- spp %>% 
      group_by(eez_name,eez_neighbour,time_step) %>% 
      summarise(
        n_spp = length(unique(taxon_key)),
        n_stock = n(),
        min_eez = min(mean_spp, na.rm=T),
        max_eez = max(mean_spp, na.rm=T),
        sd_eez = sd(mean_spp, na.rm=T), # for some weird reason it wont work if the order is fliped
        mean_eez = median(mean_spp,na.rm=T)
        ) %>% 
      select(eez_name:max_eez,mean_eez,sd_eez,n_spp,n_stock) %>% 
      left_join(n_ssr)
        
  }else{
    
    eez_summary <- spp %>% 
      group_by(eez_name,time_step) %>% 
      summarise(
        n_spp = length(unique(taxon_key)),
        n_stock = n(),
        min_eez = min(mean_spp, na.rm=T),
        max_eez = max(mean_spp, na.rm=T),
        sd_eez = sd(mean_spp, na.rm=T), # for some weird reason it wont work if the order is fliped
        mean_eez = mean(mean_spp,na.rm=T)
        ) %>% 
      select(eez_name:max_eez,mean_eez,sd_eez,n_spp,n_stock)
        
        
  }
  
  return(eez_summary)
  
}

```

#### Fun `PropChange`

Finally, we estimate the average proportion change of all species within each eez

```{r fun_PropChange, eval = F, echo =F}

PropChange <- function(taxon_list,links="NA"){
  
  eez <- EEZProp(taxon_list,links)
  
  proportion_change <- eez %>% 
    gather("variable","value",n_spp:n_per) %>% 
    spread(time_step,value) %>% 
    mutate_at(vars(
      "per_early" = early,
      "per_mid" = mid
    ),
    # funs(round(((.-historical)/(abs(historical)))*100,2)
    funs(ifelse(variable == "n_per",.,round(((.-historical)/(abs(historical)))*100,2)
                )
         )
    )
  
  return(proportion_change)
  
}


```

### Run Results Analysis

#### Read Data for Analysis

```{r General_Data, eval = F, echo =F}

# --------------- #
# General Data needed
# --------------- #

# Read transboundary species database from Palacios-Abrantes et al 2020 (FishForVisa)
Transboundary_spp <- my_path("D", extra_path = "Species/", name="Transboundary_spp.csv", read = TRUE)


# Get taxon list
Taxon_list_emer <- list.files(my_path("R",extra_path = "Emergence_2005"))

# clean names for function
Taxon_list_emer <- gsub("_.*","",Taxon_list_emer) 

# SAU exploited species list
Exploited_spp_list <- my_path("G","SAU","exploited_species_list.csv",read = T) %>%
  clean_names() %>% 
  pull(taxon_name)

# Get habitat preference from fishbase
Spp_env_pref <- rbind(species(Exploited_spp_list, #species from rfishbase package
                              fields = species_fields$habitat[4])
                      ) %>% 
  mutate(taxon_name = Exploited_spp_list) %>% 
  left_join(my_path("G","SAU","exploited_species_list.csv", read = T) %>%
              clean_names(),
            by = "taxon_name")

# Neighbour list and their respective id (see chunk 3)
Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE)

Neighbours_n <- Neighbours %>% 
  group_by(eez_name) %>% 
  summarise(
    n = length(unique(eez_neighbour))
  )

# Clean names to match data
Matching_names <- my_path("G","Spatial/SAU", "sau_matching_names.csv", read = T) %>% 
  rename(eezid = eez_id)

Fishing_names <- Matching_names %>% 
  group_by(sau_fishing_entity,fishing_entity_id) %>% 
  summarise(n=n()) %>% 
  select(-n)

# eez_centroids
Eez_centroids <- my_path("D", extra_path = "Spatial/", name="eez_centroids.csv", read = TRUE) %>% 
  rename(sf_eez_name = eez_name) %>% 
  left_join(Matching_names) %>% 
  select(eezid,latitude,longitude)

# Species depth clasification (SAU-fishbase)
Spp_depth <-fread(paste(my_path("D"),"SAU/SppTaxonName.csv", sep ="")) %>% 
  clean_names()

# Temperature Time of Emergence
Toe_temp <- left_join(my_path("D","Climate", "ToE_sst.csv", read = T),
                      my_path("D","Climate", "ToE_bottemp.csv", read = T)
                      ) %>% 
  clean_names()

# Biogeographic regions (from Rey 2020)
Biogeo_reg <-fread(paste(my_path("D"),"Climate/SPATIAL_PARTITION_OCEAN.csv", sep ="")) %>% 
  clean_names()
  
# Fix coordinate system and re-name biomes
Biogeo_reg <- suppressWarnings(Biogeo_reg[order(Biogeo_reg$lat, rev(Biogeo_reg$lon),decreasing=TRUE), ]) %>% 
  mutate(index = seq(1,259200,1)) %>% 
  mutate(
    biome = ifelse(biome2 %in% c(1,4), "tropical",
                   ifelse(biome2  %in% c(2,5),"temperate",
                          ifelse(biome2  %in% c(3,6), "polar",
                                 biome2)
                   )
    )
    ) %>% 
  filter(biome2 != "NaN")



# biome2 1 = Coastal tropical 
# biome2 2 = Coastal sub-tropical
# biome2 3 = Coastal polar
# biome2 4 = Oceanic tropical
# biome2 5 = Oceanic sub-tropical
# biome2 6 = Oceanic polar

# Biogeo_reg %>%
  # gather("biome_type","value",biome:biome2) %>%
# ggplot() +
# geom_tile(
#   aes(
#     x = lon,
#     y = lat,
#     fill = biome
#   )
# )
#   facet_wrap(~biome_type,
#              ncol=1)


# Get eez to index relational data
EEZ_CellID <- my_path("G", extra_path = "Spatial/DBEM", name="EEZ_CellID.xlsx", read = TRUE) %>%
  clean_names()
colnames(EEZ_CellID) <- c("eezid","index")

Eez_biogeo <- EEZ_CellID %>% 
  # filter(eezid == 8) %>%
  left_join(Biogeo_reg,
       by = "index") %>% 
  # Deal with NaNs in data
  mutate(biome = ifelse(biome == "NaN",0,biome)) %>% 
  filter(biome > 0) %>% 
  # Get frequency of biome per index
  group_by(eezid,biome) %>% 
  summarise(nbiom=n()) %>% 
  # Select the more frequent biome per eez
  group_by(eezid) %>% 
  top_n(1,nbiom) %>% 
  ungroup() %>% 
  select(-nbiom) %>% 
  distinct(eezid, .keep_all = T) # Croatia is 1/2. We arbitrary allocated the first one

# Species catch trend (from FishForVisa)

# Catch_trend <- my_path("D","Species","Catch_trend.csv", read = T) %>% 
#   clean_names() %>% 
#   filter(taxon_key %in% Taxon_list_emer) %>% 
#   rename(sau_fishing_entity = territory) %>% 
#   left_join(Fishing_names,
#             by = "sau_fishing_entity") %>% 
#   filter(status != "No Trend") %>% 
#   mutate(category = ifelse(status %in% c("Developing","Rebuilding"),"Category A",
#                          ifelse(status == "Max Exploited","Category B",
#                                 ifelse(status %in% c("Over Exploited","Collapsed","Category C"),"Category C", "No Category")
#                          )
#          )
#   )


# --------------- #
# Load Proportion results
# --------------- #
# Get taxon list
Taxon_list <- list.files(my_path("R",extra_path = "Proportion_2005c"))

# clean names for function
Taxon_list <- gsub(".*_","",Taxon_list) 

# clean names for function
Taxon_list <- gsub(".csv","",Taxon_list) 


# Read proportion results
Prop_results <- PropChange(Taxon_list, links="y") %>%
  filter(!is.na(eez_neighbour)) %>%
  mutate(per_mid_plot =ifelse(per_mid >= 100, 100,
                              ifelse(per_mid <= -100,-100,per_mid)
  ),
  per_early_plot =ifelse(per_early >= 100, 100,
                         ifelse(per_early <= -100,-100,per_early)
  )
  )

# For dat availability
 # write_csv(prop_results,
          # "proportion_change_2005.csv")

# --------------- #
# Load year of emergence results
# --------------- #

Paths <- paste(my_path("R",extra_path = "Emergence_2005"),Taxon_list_emer,"_emergence.txt",sep="")

# Load all sp in one table
Eme_Res <- bind_rows(lapply(Paths, fread)) %>% 
  filter(
    n_ens == 10
  ) %>% 
  left_join(Neighbours,
            by = c("eez_name","eez_neighbour")
  ) %>% 
  rename(sf_eez_name=eez_name) %>% 
  left_join(Matching_names,
            by=  "sf_eez_name") %>% 
  clean_names() %>% 
  mutate(tresh = str_to_lower(tresh))

# warnings() for empty data species # New version of package being a pain in the arse

# View(Eme_Res)

# --------------- #
# Load SAU catch and revenue data
# --------------- #

Sau_data <-fread(paste(my_path("D"),"SAU/sau_catch_value_country_taxon_JEPA.csv", sep ="")) %>%
  clean_names() %>% 
  # Remove high seas and 207 and 208 that are unknown
  filter(!fishing_entity_id %in% c(213,223)) %>%  # 207,208
  # Allocate catch of islands to UK
  mutate(fishing_entity_id = ifelse(fishing_entity_id %in% c(219,220), 183,fishing_entity_id)) %>% 
  # Convert to 2019 real USD
  mutate(values = 1.16 * value) %>%
  # Average 10 years of data
  group_by(fishing_entity_id,taxon_key) %>% 
  summarise_at(c("catch","value"),
               mean,na.rm=T) %>% 
  gather("variable","value",catch:value)


# --------------- #
# Load shapefiles for figures
# --------------- #

# Load SAU shapefile name and paths

# The path
path_world <- my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile")
path_world <- "~/Downloads/SAU_Shapefile"

# The File
fnam_world <- "SAUEEZ_July2015.shp"

# Load it!
World_eez_sf <- st_read(dsn = path_world,
                        layer =file_path_sans_ext(fnam_world)) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  # st_transform(crs = "+proj=eck4") %>% # for tbular plot
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1) %>% 
  clean_names()


# World_eez_sf %>% 
#   filter(str_detect(eez_name,"Russia")) %>% 
#   ggplot() +
#   geom_sf() +
#   aes(fill = eez_name)


# Call world map from natural earth

World_map_dat <- Matching_names %>% 
  group_by(sau_fishing_entity,fishing_entity_id,iso_a3) %>% 
  summarise(n=n()) %>% 
  select(-n) 

World_map <- rnaturalearth::ne_countries(scale = 'small', returnclass = c("sf")) %>%
  clean_names() %>% 
  select(iso_a3,sovereignt,sov_a3,name,name_long,region_wb,continent,geometry) %>% 
  # st_transform(crs = "+proj=eck4") %>%
  st_transform(crs = 4326) %>% # 4326
  mutate(iso_a3 = ifelse(sovereignt == "Norway","NOR",
                         ifelse(name == "France","FRA",
                                iso_a3)
                         )
         ) %>% 
    left_join(World_map_dat,
            by = "iso_a3")


# Load eez_centroid data
Eez_centroid <- my_path("D", "Spatial","eez_centroids.csv",read = T)

# Tranform to tubular
Eez_centroid_sf <-st_as_sf(Eez_centroid,
            coords = c("longitude", "latitude")
            ) %>% 
  st_set_crs(4326) #%>% # to match shapefiles
  # st_transform(crs = "+proj=eck4")

# Transform sf to df
# Eez_centroid_eck <- as.data.frame(Eez_centroid_sf)

# Eez_centroid_eck <- do.call(rbind, st_geometry(Eez_centroid_sf)) %>% 
#   as_tibble() %>% 
#   setNames(c("lon","lat")) %>% 
#   bind_cols(Eez_centroid) %>% 
  # select(eez_name,longitude = lon,latitude = lat)


# Join all data for analysis

Main_data <- Eme_Res %>% # 19728
  filter(tresh == "Tresh_one") %>% # 11490
  left_join(Spp_depth) %>% 
  select(taxon_key,tresh,sf_eez_name,sau_fishing_entity,fishing_entity_id,emerging_yr,eezid,dem_pel,un_region= un_geo_region) %>% 
  left_join(Toe_temp,
            by = c("eezid","tresh")
            ) %>% 
  left_join(Catch_trend,
            by = c("taxon_key","sau_fishing_entity","fishing_entity_id")
            ) %>% # 11492
  left_join(Eez_biogeo,
            by = "eezid") %>% 
  left_join(Spp_env_pref,
            by = "taxon_key") %>% 
  left_join(Eez_centroids,
            by = "eezid") %>% 
  mutate(latitude = abs(latitude))


```

###  Year of Eergence Analysis


```{r ToE_generals,  eval = F, echo = T}

### ------------ ##
# Select a trshold
selected_tresh <- "tresh_two"
### ------------ ##

# Total number of emerging stocks

# Global estimates
Eme_Res %>% 
  group_by(tresh,neighbour_id) %>% 
  summarise(
    emerging_stocks = length(unique(taxon_key))
    ) %>% 
  group_by(tresh) %>% 
  summarise(
    emerging_stocks = sum(emerging_stocks),
    prop_total = (emerging_stocks/9132)*100,
    )

# Global average ToE
Eme_Res %>% 
  group_by(tresh) %>% 
  summarise(
    # emerging_stocks = length(unique(taxon_key)),
    # prop_total = (emerging_stocks/9132)*100,
    mean= mean(emerging_yr),
    sd = sd(emerging_yr),
    min = min(emerging_yr),
    max = max(emerging_yr)
           )



```

##### Fig. 1. Accumulative plots

```{r Time_lapse_data,  eval = F, echo = T}

# Per Stock
stock_d <-  
  Eme_Res %>% 
  left_join(Neighbours) %>% 
  # distinct(taxon_key,neighbour_id, .keep_all = TRUE) %>% 
  group_by(taxon_key,neighbour_id,tresh) %>% 
  summarise(
    taxon_emer = min(emerging_yr)
  ) %>% 
  group_by(taxon_emer,tresh) %>% 
  summarise(
    n_tax = n()
  ) %>% 
  group_by(tresh) %>% 
  mutate(
    com_sum = cumsum(n_tax),
    level = "stock"
  )

max(stock_d$com_sum)

#  EEZ data
eez_d <-  Eme_Res %>% 
  left_join(Neighbours) %>% 
  filter(n_ens == 10) %>% 
  # distinct(eez_name,neighbour_id, .keep_all = TRUE) %>% 
  group_by(sf_eez_name,tresh) %>% 
  summarise(
    taxon_emer = min(emerging_yr)
  ) %>% 
  group_by(taxon_emer,tresh) %>% 
  summarise(
    n_tax = n()
  ) %>% 
  group_by(tresh) %>% 
  mutate(
    com_sum = cumsum(n_tax),
    level = "eez"
  )

max(eez_d$com_sum)

# Plot Data
plot_data <- stock_d %>% 
  bind_rows(eez_d) %>% 
  filter(tresh != "NA") %>% 
  mutate(
    # total = ifelse(level == "stock",length(unique(Eme_Res$taxon_key)),length(unique(Eme_Res$sf_eez_name))),
    total = ifelse(level == "stock",max(stock_d$com_sum),max(eez_d$com_sum)),
    per = com_sum/total*100
  ) %>% 
  gather("metric","value",com_sum,per) %>% 
  filter(tresh == selected_tresh)


# Manually include rest of data untill 2100
cont_eez <- plot_data %>% 
  filter(level == "eez") %>% 
  arrange(taxon_emer) %>% 
  slice(1:24) %>%
  select(-1) %>% 
  arrange(metric) %>% 
  mutate(
    value = ifelse(metric == "per",100,228),
    taxon_emer = c(seq(2088,2099,1),seq(2088,2099,1))
  )

plot_data <- plot_data %>% 
  bind_rows(cont_eez) %>% 
  mutate(
    my_facet = ifelse(metric == "per","Percentage (%)","Cumulative sum (n stocks)"),
    label = ifelse(total == max(stock_d$com_sum),"Total number of emerging stocks","Total number of EEZs")
  )


dashed_lines <- tibble(
  x = c(2030,2050,2080),
  label = c("UN 2030 Agenda","Early range shift  ","Late range shift   ")
)


# How many between 2006 and 2020?
plot_data %>% 
  filter(taxon_emer <= 2020,
         tresh == selected_tresh) %>%  # Presenting results for the second treshold
  group_by(level,metric) %>% 
  summarise(
    max(taxon_emer),
    min(taxon_emer),
    mean(taxon_emer),
    sd(taxon_emer)
  )

```


```{r Time_lapse_plot, eval = F, echo = F}

### Three plots

count_eez_plot <- ggplot() +
  geom_area(data = subset(plot_data, metric == "com_sum" & level == "eez"),
            aes(
              x = as.numeric(taxon_emer),
              y = value,
              fill = level
            ),
            size=0.5,
            colour="black"
  )  +
  # Add dashed lines and labels
  geom_vline(
    data = dashed_lines,
    aes(
      xintercept = x
    ),
     linetype="dashed",
    color = "grey"
  ) +
  geom_text(data = dashed_lines,
            aes(
              x = x-4,
              y = 40,
              label = label
            ),
            size = 4,
            color = "white",
            angle = 90
  ) +
  scale_y_continuous("Cumulative number of EEZs",
                     expand = c(0,0)
                     ) +
  scale_x_continuous("Year of range shift",
                     breaks = seq(2000,2100,25),
                     limits = c(2005,2100),
                     # label = c(seq(2000,2075,25),">2100"),
                     expand = c(0, 0)
  ) +
  my_ggtheme_p() +
  theme(legend.position = "") +
  guides(fill=guide_legend(title= "Level", reverse=FALSE)) +
  scale_fill_viridis(discrete = T,
                     begin = 0.1, 
                     end = 0.1
  )



#### Count stock plot 
count_stock_plot <- ggplot() +
  geom_area(data = subset(plot_data, metric == "com_sum" & level == "stock"),
            aes(
              x = as.numeric(taxon_emer),
              y = value,
              fill = level
            ),
            size=0.5,
            colour="black"
  )  +
  # Add dashed lines and labels
  geom_vline(
    data = dashed_lines,
    aes(
      xintercept = x
    ),
     linetype="dashed",
    color = "grey"
  ) +
  geom_text(data = dashed_lines,
            aes(
              x = x-4,
              y = 750,
              label = label
            ),
            size = 4,
            color = "white",
            angle = 90
  ) +
  scale_y_continuous("Cumulative number of stocks",
                     expand = c(0,0)
                     ) +
  scale_x_continuous("",
                     breaks = seq(2000,2100,25),
                     limits = c(2005,2100),
                     # label = c(seq(2000,2075,25),">2100"),
                     expand = c(0, 0)
  ) +
  my_ggtheme_p(leg_pos = "") +
  guides(fill=guide_legend(title= "Level", reverse=FALSE)) +
  scale_fill_viridis(discrete = T,
                     begin = 0.7, 
                     end = 0.7
  )


# Percentage plot
percentage_plot <- ggplot() +
  geom_area(data = subset(plot_data, level == "eez" & my_facet == "Percentage (%)"),
            aes(
              x = as.numeric(taxon_emer),
              y = value,
              fill = level
            ),
            size=0.5,
            colour="black"
  ) + 
  geom_area(data = subset(plot_data, level == "stock" & my_facet == "Percentage (%)"),
            aes(
              x = as.numeric(taxon_emer),
              y = value,
              fill = level
            ),
            size=0.5,
            colour="black"
  ) + 
  # Add dashed lines and labels
  geom_vline(
    data = dashed_lines,
    aes(
      xintercept = x
    ),
     linetype="dashed",
    color = "grey"
  ) +
  geom_text(data = dashed_lines,
            aes(
              x = x-4,
              y = 18,
              label = label
            ),
            size = 4,
            color = "white",
            angle = 90
  ) +
  scale_y_continuous("Cumulative proportion of the total (%)",
                     expand = c(0,0)
  ) +
  scale_x_continuous("",
                     breaks = seq(2000,2100,25),
                     limits = c(2005,2100),
                     # label = c(seq(2000,2075,25),">2100"),
                     expand = c(0, 0)
  ) +
  my_ggtheme_p(leg_pos = "right") +
  theme(
    strip.text.x = element_blank()
  ) +
  guides(fill=guide_legend(title= "", reverse=FALSE)) +
  scale_fill_viridis(discrete = T,
                     begin = 0.1, 
                     end = 0.7,
                     labels = c("EEZs","Stocks")
  )


# Legend
  legend <- get_legend(percentage_plot)
  
  percentage_plot <- percentage_plot + 
    theme(legend.position = "")
  

# Draw figure
  plot_all <- ggdraw() +
    # Latin America and the Car.
    draw_plot(count_stock_plot, x = 0.01, y = 0, width = 0.28, height = 0.90) +
    # Europe
    draw_plot(count_eez_plot, x = 0.28, y = 0, width = 0.28, height = 0.90) +
    # Percentage plot
    draw_plot(percentage_plot, x = 0.56, y = 0 , width = 0.28, height = 0.90) +
    # legend
    draw_plot(legend, x = 0.77, y = 0 , width = 0.28, height = 1) +
    # Labels
    draw_plot_label(label = c("A", "B","C"), 
                    size = 20,
                    x = c(0.01, 0.285,0.56), 
                    y = c(1,1,1)
    )
  
  
  # Save plot
  save_plot(
    "./Figures/cumu_per_freq.png",
    plot_all,
    base_height = 5,
    base_width = 12
  )


```


##### Fig. 2 Mapping the time of emergence

###### Mean ToE and vulnerabillity Index

```{r emergence_map, eval = F}

# Per EEZs
Eez_d_hist <- Eme_Res %>% 
  group_by(eezid,sau_fishing_entity,tresh) %>% 
  # summarise(n_tax = length(unique(taxon_key))) %>% 
  summarise(
    mean_yr = mean(emerging_yr,na.rm=T),
    sd_yr = sd(emerging_yr,na.rm=T),
    n_taxa = length(unique(taxon_key))
    ) %>% 
  gather("metric","value",mean_yr:n_taxa) %>% 
  # filter(metric != "n_taxa") %>% 
  mutate(
    reverse = abs(value-2100)  + 2000
  )

# Estimate the value (catch and USD) of emerging species
Eme_value_data <- Eme_Res %>% 
  group_by(sau_fishing_entity,fishing_entity_id,tresh,taxon_key) %>% 
  summarise(n()) %>% 
  left_join(Sau_data,
            by = c("fishing_entity_id","taxon_key")) %>% 
  filter(!is.na(variable)) %>% 
  group_by(sau_fishing_entity,fishing_entity_id,tresh,variable) %>% 
  summarise(
   sum_value = sum(value,na.rm=T),
    n_taxa = length(unique(taxon_key)) 
  )
  
# Total value of each fishing nation

Total_value <- Sau_data %>% 
  group_by(fishing_entity_id,variable) %>% 
  summarise(tot_value= sum(value,na.rm=T))


Value_map_data <- Eme_value_data %>% 
  left_join(Total_value,
            by = c("fishing_entity_id","variable")) %>% 
  mutate(participation = (sum_value/tot_value)*100+2000)


# Per fishing entity

fish_d_hist <- Eme_Res %>% 
  group_by(sau_fishing_entity,tresh) %>% 
  # summarise(n_tax = length(unique(taxon_key))) %>% 
  summarise(
    value = length(unique(taxon_key))
    ) %>% 
  filter(!is.na(sau_fishing_entity))

World_map_nemer <- World_map %>%
  full_join(Value_map_data,
            by = c("sau_fishing_entity","fishing_entity_id")
  ) %>% 
  filter(!is.na(participation))

# These are regions without transboundary species
grey_land <- World_map %>% 
  filter(!fishing_entity_id %in% Value_map_data$fishing_entity_id) %>% 
  filter(!sovereignt %in% c("Antarctica"))

# grey_eez <- World_eez_sf %>% 
#   filter(!eezid %in% Eez_d_hist$eezid,
#          !eez_name %in% Neighbours$eez_name)

# -------------------------- #
# Call plot for both tresholds
# -------------------------- #
for(i in 1:2){
  
  tresh_list <- c("tresh_one","tresh_two")
  name_save <- paste("./Figures/emer_map_lat_",tresh_list[i],".png",sep = "")
  
  # Value Map
  World_map_part <- World_map_nemer %>% 
  filter(
    tresh ==  tresh_list[i],
    variable == "value"
  )
  
  # ToE Map 
  toe_map_data <- World_eez_sf %>% 
    left_join(Eez_d_hist,
              by = "eezid") %>% 
    filter(tresh == tresh_list[i],
           metric == "mean_yr")
  
  # Map with countries without ToE
  
  russia_churchil <- World_eez_sf %>% 
    filter(eez_name %in% c("Russia (Kara Sea)","Russia (Laptev to Chukchi Sea)"))
  
  no_toe_eez <- World_eez_sf %>% 
    filter(eez_name %in% Neighbours$eez_name, # Filter EEZs without Transboundary spp
           !eez_name %in% toe_map_data$eez_name) %>%  # Filter EEZs with ToE stocks
    rbind(russia_churchil)
  
  no_toe_land <- World_map %>% 
    filter(name %in% Neighbours$eez_name, # Filter EEZs without Transboundary spp
           !name %in% World_map_part$name) # Filter EEZs with ToE stocks
    
    
  map <- ggplot(toe_map_data) +
    geom_sf(
      aes(
        fill = reverse #original map
        # fill = value
      ),
      color =  "white",
      size = 0.1
    ) +
    # Inlcude the participation of species
    geom_sf(data = World_map_part,
            # aes(fill = participation+2000), #original map
            aes(fill = participation),
            color =  "white",
            size = 0.1
    ) +
    # grey maps
    # ggplot() +
    geom_sf(data = grey_land, aes(), fill = "grey50", color =  "white",size = 0.1) +
    # geom_sf(data = grey_eez, aes(), fill = "white", color =  "grey50",size = 0.1) +
    geom_sf(data = no_toe_eez, aes(), fill = "lightblue", color =  "white",size = 0.1) +
    geom_sf(data = no_toe_land, aes(), fill = "lightblue", color =  "white",size = 0.1) +
    # Set Participation labels
    annotate("text",
             x =-150,
             y = -69,
             label = "% Of fishing revenue",
             color="black",
             size=5,
             angle=0,
             fontface="bold",
             hjust=0) +
    annotate("text", 
             x = c(-72,-35,5,46,82),
             y = -69,
             # x =(c(-8500000,-3000000,2500000,7500000,12800000)),
             # y = -9050000,
             label = c(0,25,50,75,100), 
             color="black", 
             size=4, 
             angle=0, 
             # fontface="bold",
             hjust=0) +
    # Set ToE labels
    annotate("text", 
             x =-150,
             y = -85,
             label = "Year of range shift",
             color="black", 
             size=5, 
             angle=0, 
             fontface="bold",
             hjust=0) +
    annotate("text", 
             x = c(-79,-39,2,42,81),
             y = -85,
             # label = seq(2100,2000,-25), # original
             label = c(">2100",seq(2075,2000,-25)), # not inluding the > because we dont know
             color="black", 
             size=4, 
             angle=0, 
             # fontface="bold",
             hjust=0) +
    # Set No emergence label
    annotate("text",
             x =110,
             y = -77,
             label = "No shift",
             color="black",
             size=5,
             angle=0,
             fontface="bold",
             hjust=0) +
    scale_fill_viridis("",
                       limits = c(2000,2100),
                       breaks = seq(2000,2100,25),
                       labels = c("","","","","")#,
                       # direction = -1
    ) +
    # scale_fill_gradientn("",
    #                      limits = c(2000,2100),
    #                      breaks = seq(2000,2100,25),
    #                       labels = c("","","","",""),
    #                      colours = pal
    # ) +
    # geom_hline(yintercept = c(-50,0,50,80)) +
    my_ggtheme_m() +
    theme(
      legend.box.margin = margin(t = -62, l = 252),
      legend.text = element_blank(),
      legend.key.width = unit(5, "line")
    )
  
  
  
  ## --------------- ##
  # Regional Boxplot
  ## --------------- ##
  
  boxplot_data <- Eme_Res %>% 
    filter(tresh == tresh_list[i],
           !is.na(un_sub_region)) %>%
    group_by(un_sub_region) %>% 
    summarise(order = median(emerging_yr)) %>% 
    left_join(Eme_Res) %>% 
    filter(tresh == tresh_list[i],
           !is.na(un_sub_region)) %>% 
    mutate(un_sub_region = ifelse(str_detect(un_sub_region,"Latin"),"Ltn. Ame. and\nthe Car.",
                                  ifelse(str_detect(un_sub_region,"Australia"),"Aus. and New Z.",
                                         ifelse(str_detect(un_sub_region,"Sub-Saharan"),"Sub-Saharan\nAfrica",
                                                paste(un_sub_region)))
    )
    )
  
  
  boxplot_data$un_sub_region <- boxplot_data$un_sub_region %>% 
    gsub("Northern","N.",.) %>% 
    gsub("Southern","S.",.) %>% 
    gsub("Western","W.",.) %>% 
    gsub("Eastern","E.",.) %>% 
    gsub("South-eastern","S.E.",.)
  
  # ---------- #
  # Summary data
  # ---------- #
  
  medians_data <- boxplot_data %>% 
    group_by(un_sub_region,un_geo_region) %>% 
    summarise(mean = mean(emerging_yr,na.rm = T),
              sd = sd(emerging_yr,na.rm = T),
              min = min(emerging_yr,na.rm = T),
              max = max(emerging_yr,na.rm = T),
              med = median(emerging_yr,na.rm = T),
              n_stocks = n()
    )
  
  boxplot_data <- boxplot_data %>% 
    left_join(medians_data,
              by = c("un_sub_region","un_geo_region")
              )


  boxplot <- ggplot(boxplot_data) +
    geom_violin(
      aes(
        x = reorder(un_sub_region,order),
        y = emerging_yr
      ),
      fill = "grey"
    ) + 
    facet_wrap(~un_geo_region,
               scales = "free_x",
               nrow = 1) +
    # Median points
    geom_point(
      aes(
        x = reorder(un_sub_region,order),
        y = med,
        colour = med
      ),
      size = 5
    ) + 
    # h line
    geom_hline(yintercept = 2030, color = "grey", size = 0.5, linetype="dashed") +
    scale_colour_viridis("",
                       limits = c(2000,2100),
                       breaks = seq(2000,2100,25),
                       labels = c("","","","",""),
                       direction = -1
    ) +
    xlab("") +
    ylab("Year of range shift") +
    scale_y_continuous(
                   labels = c(2000,2025, 2050, 2075, ">2100"), # not inluding the > because we dont know
    ) +
    my_ggtheme_p() +
    theme(
      axis.text.x = element_text(size = 16, angle = 45, face = "plain", hjust = 1), 
      strip.text.x = element_text(size = 18, colour = "black"), 
      axis.title.y = element_text(size = 18),
      axis.text.y = element_text(size = 16), 
      # axis.ticks.x = element_blank(),
      legend.position = ""
    )
  
  ## --------------- ##
  # Combine plots and save them
  ## --------------- ##
  
  p <- ggdraw() +
    # ToE Latitudinal plot
    # draw_plot(Eez_hist, x = 0.873, y = 0.53, width = 0.124, height = 0.37) +
    # Time of Emergence Map
    draw_plot(map, x = 0, y = 0.4, width = 1, height = 0.6) +
    # Regional boxplot
    draw_plot(boxplot, x = 0, y = -0.03, width = 1, height = 0.44) +
    # Labels
    draw_plot_label(label = c("A", "B"), 
                    size = 20,
                    x = c(0, 0), 
                    y = c(0.95, 0.46)
    )
  
  
  save_plot(
    name_save,
    p,
    base_height = 11,
    base_width = 12
  )
  
}


```

##### Fig. 4. Bubble plot

```{r, buble_plot, eval = F, echo = F}

dashed_lines <- tibble(
  x = c(2030,2050,2080),
  label = c("UN 2030 Agenda","Early range shift  ","Late range shift   ")
)
# Needs previous chunk

Buble_data <- Eez_d_hist %>% 
  filter(metric == "mean_yr") %>% 
  group_by(sau_fishing_entity,tresh) %>% 
  summarise(mean_yr = mean(value)) %>% 
  left_join(Eme_value_data,
            by = c("sau_fishing_entity","tresh")) %>% 
  filter(tresh == selected_tresh, # tresh hold selection
         variable == "value") %>% 
  mutate(
    weight_toe = sum_value/mean_yr,
    sum_value_bi = sum_value/1000000000,
    log_value = log10(sum_value_bi)
    ) %>%   # Billion usd
  left_join(Matching_names,
            by = c("sau_fishing_entity","fishing_entity_id")) %>% 
  distinct(sau_fishing_entity,.keep_all = TRUE) %>% 
  filter(!is.na(un_geo_region)) %>% 
  ungroup()# %>%  # no more asterisk
  # mutate(
  #   sau_fishing_entity = ifelse(sum_value_bi >= 1 & !sau_fishing_entity %in% c("Spain"), paste(sau_fishing_entity,"*",sep = ""),sau_fishing_entity))

### Fucntion for estimating percentile

quibble <- function(x, q = p) {
        tibble(x = quantile(x, q), q = q)
}

Percentile_value <- Buble_data %>% 
  group_by() %>%  # for whole distribution
        do(quibble(.$log_value, 0.75))


## Top fishing nations close to SDGs
Buble_data %>% 
  filter(log_value > Percentile_value$x & mean_yr < 2036) %>% 
  # View()
  group_by() %>% 
  summarise(sum(sum_value_bi),
            sum(n_taxa))

## All fishing nations close to SDGs
Buble_data %>% 
  filter(mean_yr < 2036) %>% 
  # nrow() # 76  coutries
  # View()
  group_by() %>% 
  summarise(sum(sum_value_bi),
            sum(n_taxa))

76/length(unique(Buble_data$sau_fishing_entity))

# Labels Data

Labels_data <- tibble(
  x = c(2030,2045,2055,2007),
  y = c(-5.8,-5.8,-5.8,Percentile_value$x+.1),
  label = c("UN 2030 Agenda", "Early shift","Late shift","Fisheries > 75th percentile")
)


# Plot the bubbles!
ggplot(Buble_data) +
  geom_point(
    aes(
      x = mean_yr,
      y = log_value,
      size = n_taxa,
      colour = un_geo_region,
      shape = un_geo_region
    ),
    alpha = 0.7
  ) +
  # Right side labels
  geom_label_repel(data = subset(Buble_data, log_value > Percentile_value$x & mean_yr < 2036 & mean_yr > 2034),
                  aes(
                    x = mean_yr,
                    y = log_value,
                    label = sau_fishing_entity
                  ),
                  arrow = arrow(length = unit(0.009, "npc"),
                                type = "closed",
                                ends = "first"),
                  force = 1,
                  box.padding = 0.2,
                  fill = "NA",
                  nudge_x = 2066 - subset(Buble_data,log_value > Percentile_value$x & mean_yr < 2036 & mean_yr > 2034)$mean_yr, # set distance from point
                  nudge_y = subset(Buble_data, log_value > Percentile_value$x & mean_yr < 2034)$log_value  +1.1 , # set vertical position
                  segment.size  = 0.1,
                  segment.color = "grey50",
                  direction     = "y",
                  hjust         = 1
  ) +
  # LEFT side labels
  geom_label_repel(data = subset(Buble_data, log_value > Percentile_value$x & mean_yr < 2034),
                  aes(
                    x = mean_yr,
                    y = log_value,
                    label = sau_fishing_entity
                  ),
                  arrow = arrow(length = unit(0.009, "npc"),
                                type = "closed",
                                ends = "first"),
                  force = 1,
                  box.padding = 0.2,
                  fill = "NA",
                  nudge_x = 2025 - subset(Buble_data, log_value > Percentile_value$x & mean_yr < 2034)$mean_yr, # set horizontal position
                  nudge_y = subset(Buble_data, log_value > Percentile_value$x & mean_yr < 2034)$log_value  +1.1 , # set vertical position
                  segment.size  = 0.1,
                  segment.color = "grey50",
                  direction     = "y",
                  hjust         = 1
  ) +
  # Divisory lines and labels
  geom_vline(xintercept = c(2030,2050), color = "grey50", size = 0.5, linetype = "dashed") +
  geom_hline(data = Percentile_value,
             aes(yintercept = x),
             color = "grey50"
  )  +
  geom_text(data = Labels_data,
            aes(
              x = x,
              y = y,
              label = label
            ),
            size = 5,
            color = "grey30"
  ) + 
  scale_shape("Region") +
  scale_color_viridis(name="Region",
                      discrete = T) +
  scale_x_continuous("Average year of range shift",
                     limits = c(2000,2080),
                     breaks = seq(2000,2080,10)
  ) +
  scale_y_continuous("Fishing revenue (log10)",
                     limits = c(-6,2),
                     breaks = seq(-6,2,2),
                     expand = c(0,0)
  ) +
  scale_size("Number of\nshifting stocks") +
  my_ggtheme_p(legend.position = "right") +
  ggsave("./Figures/bubble_plot.png",
         width = 12,
         height = 8,
         units = "in"
  )

```


```{r participation_text, eval = T, echo=F}

Value_map_data %>% 
  group_by(tresh,variable) %>% 
  summarise(m = mean(participation)-2000,
            sd = sd(participation-2000)
            )

```



### Species level analysis

#### Fig. 5 Species Boxplot

```{r deme_pela, eval = F, echo =F}

Dem_pel <- Eme_Res %>% 
  filter(tresh == selected_tresh,
         !is.na(un_sub_region)) %>% 
  left_join(Spp_env_pref) %>% 
  mutate(DemersPelag = ifelse(is.na(DemersPelag),"other",paste(DemersPelag)
  #                             ifelse(DemersPelag %in% c("bathypelagic","benthopelagic"), "bathy-bentho-pelagic",paste(DemersPelag)
  #                             )
   ),
    un_sub_region = ifelse(str_detect(un_sub_region,"Latin"),"Ltn. Ame. and the Car.",paste(un_sub_region)))


# Dem Pelagic boxplot
Eme_Res %>% 
  left_join(Spp_env_pref) %>% 
  mutate(DemersPelag = ifelse(is.na(DemersPelag),"other",DemersPelag)) %>% 
  group_by(DemersPelag,tresh) %>%
  summarise(mean_toe = median(emerging_yr,na.rm=T),
            n_spp = length(unique(taxon_key)),
            n_stock = n()
  ) %>%
  left_join(Dem_pel) %>%
  mutate(
    label = paste0(DemersPelag, "\n(n=",n_stock,")")
  ) %>%
  filter(tresh == selected_tresh,
         DemersPelag != "pelagic") %>% # just one spp.
  ggplot() +
  # geom_violin(
  geom_boxplot(
    aes(x = reorder(label,mean_toe),
        # aes(x = DemersPelag,
        y = emerging_yr,
        fill = mean_toe
    ),
    alpha = 0.8,
    # fill = "grey",
    coef = 0, # to have dotted error bars
    outlier.shape = NA # to have dotted error bars
  ) +
  # to have dotted error bars
  stat_boxplot(
    aes(x = reorder(label,mean_toe),
        # aes(x = DemersPelag,
        y = emerging_yr,
        # fill = DemersPelag
    ),
    geom ='errorbar',
    width = 0.3,
    linetype = "dashed") + 
  geom_hline(yintercept = 2030, color = "grey", size = 0.5, linetype="dashed") +
  xlab("") +
  ylab("Year of range shift") +
  my_ggtheme_p(leg_pos = "right", leg_tl_s =11, leg_tx_s = 10, axx_tx_ang = 45, ax_tx_s = 10, hjust = 1) +
  scale_fill_viridis("Average year of\nrange shift",
                       limits = c(2000,2100),
                       breaks = seq(2000,2100,25),
                       # labels = c("","","","",""),
                       direction = -1
    ) +
  scale_x_reordered() +
  ggsave("./Figures/regional_hab_boxplot.png",
         width = 10,
         height = 5,
         units = "in"
  )

```

### Statistics

#### Test for normallity

```{r, normality_test, eval = F, echo = F}
# Test for normality

Stats_data <- Eme_Res %>% 
  filter(tresh == selected_tresh,
         n_ens == 10)
  

# ------------------- #
# Test normal asumptions 
# ------------------- #

hist(Stats_data$emerging_yr) # Positevely skewed
qqnorm(Stats_data$emerging_yr) # not normally distributed
skewness(Stats_data$emerging_yr) #1.02
kurtosis(Stats_data$emerging_yr) #2.82

# ------------------- #

# (NOT NORMAL DISTRIRBUTION)

```

## Regional differences

```{r multiple_reg, eval = F, echo = F}

Reg_diff_data <- Eme_Res %>% 
  filter(tresh == selected_tresh,
         !is.na(un_sub_region)
         )

# ------------------- #
# Run non-parametric Krustal
# ------------------- #

Reg_kw <- kruskal.test(un_sub_region~emerging_yr, data = Reg_diff_data)

Reg_kw
# Kruskal-Wallis rank sum test
# 
# data:  un_sub_region by emerging_yr
# Kruskal-Wallis chi-squared = 287.23, df = 93, p-value < 2.2e-16

kruskalmc(emerging_yr~un_sub_region, data = Reg_diff_data) %>% 
  as.data.frame() %>% 
  rownames_to_column("comparrison") %>% 
  # head()
  View()
  write_csv("kw_regional.csv")

# Multiple differences but Eastern Asia, Lat. Ame. Car. and Polinesia are the nes who differe the most (e.g. differe with more revions).

# ------------------- #
# Just to double check ANOVA results (give the same)
# ------------------- #
Reg_aov <- aov(emerging_yr~un_sub_region, data = Reg_diff_data)
Reg_aov

summary(Reg_aov)

TukeyHSD(Reg_aov) %>% 
  tidy() %>% 
   filter(adj.p.value < 0.05) %>%
  View()


```

## Habitat preference differences

```{r multiple_reg, eval = F, echo = F}

Hab_diff_data <- Eme_Res %>% 
  filter(tresh == selected_tresh,
         !is.na(un_sub_region)
         ) %>% 
  left_join(Spp_env_pref,
            by = "taxon_key") 

# ------------------- #
# Run non-parametric Krustal
# ------------------- #

Hab_kw <- kruskal.test(DemersPelag~emerging_yr, data = Hab_diff_data)

Hab_kw
# Kruskal-Wallis rank sum test

# data:  DemersPelag by emerging_yr
# Kruskal-Wallis chi-squared = 286.48, df = 93, p-value < 2.2e-16

kruskalmc(emerging_yr~DemersPelag, data = Hab_diff_data) %>% 
  as.data.frame() %>% 
  rownames_to_column("comparrison") %>% 
  # head()
  View()
  write_csv("kw_habitat.csv")

# Multiple differences but main differences for pelagic-ocenaic and reefs

# ------------------- #
# Just to double check ANOVA results (give the same)
# ------------------- #

Hab_aov <- aov(emerging_yr~DemersPelag, data = hab_diff_data)
Hab_aov

summary(Hab_aov)

TukeyHSD(Hab_aov) %>% 
  tidy() %>% 
   filter(adj.p.value < 0.05) %>%
  View()


```


####  Prooportion Analysis

##### Fig. 5 and S5. (Proportion + Netowrk)

```{r fig_map_Juan, eval = F, echo =F}
# Figure made thanks to Juanito!
# http://jsmayorga.com/post/mapping-the-global-network-of-transnational-fisheries/

### Median number of stocks changing in each time step

Prop_results %>% 
  filter(variable == "n_per") %>% 
  group_by() %>% 
  summarise_at(vars(early,mid),funs(
    median(.,na.rm=T),
    sd(.,na.rm=T),
    length(unique(eez_name)),
    length(unique(eez_name))/280*100
    )
    )

# Prepare data from results
Data <- Prop_results %>% 
  # get coords for sources
  left_join(Eez_centroid,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(Eez_centroid,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  mutate(
    per_early = ifelse(is.na(per_early),0,per_early),
    per_mid = ifelse(is.na(per_mid),0,per_mid)
  ) %>% 
  drop_na() %>%
  # gather("variable","value",per_early:per_early_plot) %>% 
  filter(
    variable %in% c("mean_eez","n_spp")#,
    # source %in% c("Brazil","Argentina","Chile","Peru","Uruguay")
  )

# Convert to data to spatial
network_data_sf <- Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  # st_sfc(crs = "+proj=eck4") %>% # for tbular plot
  st_sf(geometry = .)%>%
  bind_cols(Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>%
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>%
  sf::st_sf(crs = 4326)
  # sf::st_sf(crs = "+proj=eck4") # for tbular plot


#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest(cols = c(coords)) %>%
  mutate_at(vars(X,Y), round,2) %>% 
  gather("time_step","per_chng",per_early:per_mid) %>% 
  mutate(per_plot = ifelse(per_chng > 50,50,per_chng),
         direction = ifelse(per_chng > 0,"positive","negative")
         )
  
# Plot it!

# Proportion map data 
Map_data <- Data %>% 
  gather("time_step","per_chng",per_early:per_mid) %>% 
  mutate(per_plot = ifelse(per_chng > 50,50,per_chng))

# Average number of taxa to change per eez

# Total number of transboundary stocks per EEZ
n_trans_eez <- Transboundary_spp %>% 
  group_by(eez_name) %>% 
  summarise(
    # n_trans = unique(length(taxon_key))
    n_trans = n()
  )

# Estimate the percentage changing
n_taxa_data <- Prop_results %>% 
  filter(variable == "n_spp") %>%
  select(eez_name,early,mid) %>% 
  left_join(n_trans_eez) %>% 
  # mutate(per = (early/n_trans)*100) %>% 
  mutate_at(vars(early,mid),
            .funs = ~(./n_trans)*100) %>% 
  rename(sf_eez_name = eez_name) %>% 
  left_join(Matching_names) %>% 
  select(sau_fishing_entity,fishing_entity_id,early,mid) %>% 
  gather("time_step","avrg_spp_per",early:mid) %>% 
  group_by(sau_fishing_entity,fishing_entity_id,time_step) %>%
  summarise(avrg_spp_per = mean(avrg_spp_per,na.rm=T)) %>% 
  mutate(time_step = ifelse(time_step == "early","per_early","per_mid")) %>% 
  mutate(avrg_spp_per = ifelse(avrg_spp_per > 50,50,avrg_spp_per))

# Included in map
n_taxa_map <- World_map %>% 
  full_join(n_taxa_data,
            by = c("sau_fishing_entity","fishing_entity_id")
            )

# Grey land
grey_land <- World_map %>% 
  filter(is.na(fishing_entity_id)) %>% 
  filter(!sovereignt %in% c("Antarctica"))


# Rectangles dataset
# coord_sf(xlim = c(-3, 35),ylim = c(30, 45)) +
Rectangles <- tibble(
    x1=c(-100,-14), #LatAm, Med, NE
    x2=c(-55,23),
    y1=c(9,50), 
    y2=c(30,67)
  )


time_sets <- c("per_early","per_mid")
# i = 1
for(i in 1:2){
  gc()# clean ram
  
  time <- time_sets[i]
  
  ## ------------------- ##
  # Global Plot
  ## ------------------- ##
  
  
  
  Prop_map <- ggplot() +
    geom_sf(data = subset(n_taxa_map, sovereignt != "Antarctica" & time_step == time),
            aes(fill = avrg_spp_per),
            size = 0.1,
            col = "white") +
    geom_sf(data = World_eez_sf, size = 0.1, fill = "white", col = "gray30") +
    geom_sf(data = grey_land, size = 0.1, fill = "grey50", col = "gray30") + # created for figure 2
    geom_point(data = subset(Map_data, time_step == time & per_plot < 0),
               aes(start_lon,
                   start_lat
               ),
               size = 0.05,
               col = "gray80",
               shape = 20,
               stroke = 1.5) +
    geom_path(data = subset(paths, time_step == time & per_plot > 0),
              aes(X,
                  Y,
                  group = interaction(line_id,subline_id),
                  col = per_plot
              ),
              size = 0.3,
              lineend = "round",
              arrow = arrow(length = unit(0.008, "npc"),
                            ends = "first"),
              show.legend = NA) +
    # Closeup Rectangles 
    geom_rect(data=Rectangles,
              aes(xmin=x1, 
                  xmax=x2,
                  ymin=y1,
                  ymax=y2),
              color="grey50", 
              fill = NA,
              linetype = "dashed"
    ) +
    my_ggtheme_m() +
    scale_colour_viridis(
      name="Stock share ratio gain \nand changing stocks (%)",
      limits = c(0,max(Map_data$per_plot)),
      breaks = seq(0,max(Map_data$per_plot),10),
      labels = c(seq(0,max(Map_data$per_plot-10),10),">50")
      # option="magma",
      # direction = -1
    ) +
    scale_fill_viridis(
      name="Stock share ratio gain \nand changing stocks (%)",
      limits = c(0,max(Map_data$per_plot)),
      breaks = seq(0,max(Map_data$per_plot),10),
      labels = c(seq(0,max(Map_data$per_plot-10),10),">50")
      # alpha = 0.8
      # option="magma",
      # direction = -1
    ) #+
  # ggsave("./Figures/fig_sup_1.png",
  # width = 12,
  # height = 8,
  # units = "in"
  # )
  
  ## ------------------- ##
  # Regional Plots
  ## ------------------- ##
  
  Lat_am_land <- World_map %>% 
    filter(region_wb %in% c("Latin America & Caribbean") |
             sau_fishing_entity %in% c("USA","Mexico")
    )
  
  Lat_am_eez <- World_eez_sf %>% 
    select(sf_eez_name = eez_name,everything()) %>% 
    left_join(Matching_names) %>% 
    filter(
      !str_detect(sf_eez_name,"Pacific"),
      !sf_eez_name %in% c("USA (East Coast)","Suriname","Guyana","French Guiana","Bermuda (UK)","Brazil","El Salvador")
    )
  
  Lat_am_data <- Map_data %>% 
    filter(source %in% Lat_am_eez$sf_eez_name)
  
  Lat_am_paths <- paths %>% 
    filter(source %in% Lat_am_eez$sf_eez_name,
           target %in% Lat_am_eez$sf_eez_name)
  
  
  Lat_am_map <- ggplot() +
    geom_sf(data = Lat_am_eez, size = 0.1, fill = "white", col = "gray30") +
    geom_sf(data = grey_land, size = 0.1, fill = "grey50", col = "gray30") +
    geom_sf(data = subset(n_taxa_map, sovereignt != "Antarctica" & time_step == time),
            aes(fill = avrg_spp_per),
            size = 0.1,col = "white") +
    geom_point(data = subset(Lat_am_data, time_step == time & per_plot < 0 ),
               aes(start_lon,
                   start_lat,
                   col = per_plot),
               size = 1,
               col = "gray30",
               shape = 20,
               stroke = 1.5) +
    geom_path(data = subset(Lat_am_paths, time_step == time & per_plot > 0),
              aes(X, Y,
                  group = interaction(line_id,subline_id),
                  col = per_plot
              ),
              size = 1,
              arrow = arrow(length = unit(0.05, "npc"),
                            ends = "first"),
              show.legend = NA) +
    coord_sf(xlim = c(-100, -55),ylim = c(9, 30)) + 
    labs(x = "", y = "") +
    scale_x_continuous(breaks = seq(-100,60,10)) +
    scale_y_continuous(breaks = seq(10,30,10)) +
    my_ggtheme_m() +
    theme(legend.position = "",
          panel.background = element_rect(fill = "white", color = "white"),
          panel.grid.major =  element_line(color = "white")
    ) +
    scale_colour_viridis(
      name="Average Gain of\nStock-Share Ratio (%)",
      limits = c(0,max(Lat_am_data$per_plot)),
      breaks = seq(0,max(Lat_am_data$per_plot),10),
      # option="magma",
      # direction = -1
    )+
    scale_fill_viridis(
      name="Average Gain of\nStock-Share Ratio (%)",
      limits = c(0,max(Lat_am_data$per_plot)),
      breaks = seq(0,max(Lat_am_data$per_plot),10),
      # option="magma",
      # direction = -1
    )
  
  
  ## ------------------- ##
  # The Med (Removed by Colette)
  ## ------------------- ##
  
  # # Land polygon
  # Med_land <- World_map %>% 
  #   filter(region_wb %in% c("Europe & Central Asia","Middle East & North Africa") |
  #            sau_fishing_entity %in% c("Spain","France")
  #   )
  # 
  # # EEZ polygon
  # Med_eez <- World_eez_sf %>% 
  #   select(sf_eez_name = eez_name,everything()) %>% 
  #   left_join(Matching_names) %>% 
  #   filter(sau_fishing_entity %in% Med_land$sau_fishing_entity,
  #          sf_eez_name != "Spain (Northwest)")
  # 
  # # Med data
  # Med_data <- Map_data %>% 
  #   filter(source %in% Med_eez$sf_eez_name)
  # 
  # # Med paths
  # Med_paths <- paths %>% 
  #   filter(source %in% Med_eez$sf_eez_name,
  #          target %in% Med_eez$sf_eez_name)
  # 
  # # Med plot
  # Med_map <- ggplot() +
  #   geom_sf(data = Med_eez, size = 0.5, fill = "white", col = "gray30") +
  #   geom_sf(data = grey_land, size = 0.1, fill = "grey50", col = "gray30") + # created for figure 2
  #   geom_sf(data = subset(n_taxa_map, sovereignt != "Antarctica" & time_step == time),
  #           aes(fill = avrg_spp_per),
  #           size = 0.1,col = "white") +
  #   geom_point(data = subset(Med_data, time_step == time & per_plot < 0 ),
  #              aes(start_lon,
  #                  start_lat,
  #                  col = per_plot),
  #              size = 1,
  #              col = "gray30",
  #              shape = 20,
  #              stroke = 1.5) +
  #   geom_path(data = subset(Med_paths, time_step == time & per_plot > 0),
  #             aes(X, Y,
  #                 group = interaction(line_id,subline_id),
  #                 col = per_plot
  #             ),
  #             size = 1,
  #             arrow = arrow(length = unit(0.05, "npc"),
  #                           ends = "first"),
  #             show.legend = NA) +
  #   coord_sf(xlim = c(-3, 35),ylim = c(30, 45)) +
  #   labs(x = "", y = "") +
  #   scale_x_continuous(breaks = seq(-5,35,10)) +
  #   scale_y_continuous(breaks = seq(30,50,5)) +
  #   my_ggtheme_m() +
  #   theme(legend.position = "",
  #         panel.background = element_rect(fill = "white", color = "white"),
  #         panel.grid.major =  element_line(color = "white")
  #   ) +
  #   scale_colour_viridis(
  #     name="Average Gain of\nStock-Share Ratio (%)",
  #     limits = c(0,max(Med_data$per_plot)),
  #     breaks = seq(0,max(Med_data$per_plot),5),
  #     # option="magma",
  #     # direction = -1
  #   )+
  #   scale_fill_viridis(
  #     name="Average Gain of\nStock-Share Ratio (%)",
  #     limits = c(0,max(Med_data$per_plot)),
  #     breaks = seq(0,max(Med_data$per_plot),5),
  #     # option="magma",
  #     # direction = -1
  #   )#;Med_map
  
  
  ## ------------------- ##
  # Northern Europe
  ## ------------------- ##
  
  Eu_land <- World_map %>% 
    filter(
      continent == "Europe",
      sau_fishing_entity != "Iceland"
    )
  
  # 
  # ggplot(N_Eu_land) +
  #   geom_sf() 
  
  
  Eu_eez <- World_eez_sf %>% 
    select(sf_eez_name = eez_name,everything()) %>% 
    left_join(Matching_names) %>% 
    filter(
      !sf_eez_name %in% c("Iceland", "Norway","Italy","Greece","Croatia","Bulgaria","Romania"),
      !str_detect(sf_eez_name,"Spain")
    )
  
  # Eu_eez %>% filter(str_detect(sf_eez_name,"Romania"))
  
  Eu_data <- Map_data %>% 
    filter(source %in% Eu_eez$sf_eez_name)
  
  Eu_paths <- paths %>% 
    filter(source %in% Eu_eez$sf_eez_name,
           target %in% Eu_eez$sf_eez_name)
  
  
  Eu_map <- ggplot() +
    geom_sf(data = Eu_eez, size = 0.5, fill = "white", col = "gray30") +
    geom_sf(data = grey_land, size = 0.1, fill = "grey50", col = "gray30") + # created for figure 2
    geom_sf(data = subset(n_taxa_map, sovereignt != "Antarctica" & time_step == time),
            aes(fill = avrg_spp_per),
            size = 0.1,col = "white") +
    geom_point(data = subset(Eu_data, time_step == time & per_plot < 0 ),
               aes(start_lon,
                   start_lat,
                   col = per_plot),
               size = 1,
               col = "gray30",
               shape = 20,
               stroke = 1.5) +
    geom_path(data = subset(Eu_paths, time_step == time & per_plot > 0),
              aes(X, Y,
                  group = interaction(line_id,subline_id),
                  col = per_plot
              ),
              size = 1,
              arrow = arrow(length = unit(0.05, "npc"),
                            ends = "first"),
              show.legend = NA) +
    coord_sf(xlim = c(-15, 30), ylim = c(45, 65)) +
    labs(x = "", y = "") +
    scale_y_continuous(breaks = seq(45,65,10)) +
    # scale_x_continuous(breaks = seq(45,65,5)) +
    my_ggtheme_m() +
    theme(legend.position = "",
          panel.background = element_rect(fill = "white", color = "white"),
          panel.grid.major =  element_line(color = "white")
    ) +
    scale_colour_viridis(
      name="Average Gain of\nStock-Share Ratio (%)",
      limits = c(0,max(Eu_data$per_plot)),
      breaks = seq(0,max(Eu_data$per_plot),5),
      # option="magma",
      # direction = -1
    )+
    scale_fill_viridis(
      name="Average Gain of\nStock-Share Ratio (%)",
      limits = c(0,max(Eu_data$per_plot)),
      breaks = seq(0,max(Eu_data$per_plot),5),
      # option="magma",
      # direction = -1
    )#;Eu_map
  
  # Legend
  map_plot <- get_legend(Prop_map)
  
  Prop_map <- Prop_map + 
    theme(legend.position = "")
  
  ## ------------------- ##
  # Render final plot
  ## ------------------- ##
  
  
  # Clean memory
  gc()
  
  # Draw figure
  plot_all <- ggdraw() +
    # Main map
    draw_plot(Prop_map, x = 0, y = 0.40, width = 1, height = 0.6) +
    # Latin America and the Car.
    draw_plot(Lat_am_map, x = 0.05, y = 0.00, width = 0.5, height = 0.50) +
    # Europe
    draw_plot(Eu_map, x = 0.52, y = 0.05, width = 0.35, height = 0.35) +
    # Legend
    draw_plot(legend, x = 0.25, y = 0, width = 0.59, height = 0.09) +
    # Labels
    draw_plot_label(label = c("A", "B", "The Caribbean","Northwestern Europe"),
                    size = c(20,20,15,15),
                    x = c(0.01,0.01,0.14,0.50),
                    y = c(1,0.45,0.44,0.44)
    )
  
  
  name <- paste0("./Figures/props_",time,".png")
  
  # Save plot
  save_plot(
    name,
    plot_all,
    base_height = 10,
    base_width = 12
  )
  
}
```

##### Fig S2 (Histogram of change)

```{r hist_change}

 Prop_results %>% 
  gather("time_step","change",per_early,per_mid) %>% 
  filter(variable == "mean_eez" & 
           !is.na(change)
         ) %>%
ggplot() +
  geom_density(
               aes(
                 x = ifelse(change >= 100,100,change),
                 # x = change,
                 fill = ifelse(time_step == "per_early","q",time_step)
                 # fill = time_step,
                 
               ),
               # stat = "count",
               # alpha= 0.8,
               size=0.1,
               # position = "stack"
  ) +
  scale_y_continuous("Density",
                     # breaks = seq(0,90,10),
                     # limits = c(0,100)
  ) +
  scale_x_continuous("Percentage Change",
                     breaks = seq(-75,500,25)
  ) +
  my_ggtheme_p() +
  theme(legend.position = "right") +
  scale_fill_viridis(discrete = T, 
                     option = "plasma",
                     alpha = 0.5,
                     name = "Time Step", labels = c("Middle", "Early")
                     ) +
  coord_flip() +
  ggsave("./Figures/hist_change.png",
         width = 6,
         height = 6,
         units = "in"
  )

```



## Sensitivity analysis

Testing different Per values for the centroids 

```{r data_loading, eval = F, echo = F}

# SAU exploited species list
Exploited_spp_list <- my_path("G","SAU","exploited_species_list.csv",read = T) %>%
  clean_names() %>% 
  pull(taxon_name)

# Load all sp in one table
sen_list <- c(20,50,90,95)

sen <- 95
read_sen <- function(sen){
  
  if(sen != 95){
  
  level <- paste0("Emergence_2005_p",sen)
  extra_path <- paste0("Toe_Sens_per/",level)
  
  # Get taxon list
  Taxon_list_sens <- list.files(my_path("R",extra_path = extra_path))
  
  Paths_sen <- paste(my_path("R",extra_path = extra_path),Taxon_list_sens,sep="")
  
  }else{
    
  Taxon_list <- gsub("_.*","",Taxon_list_sens) 
  
  Paths_sen <- paste(my_path("R",extra_path = "Emergence_2005"),Taxon_list_sens,"_emergence.txt",sep="")

  }
  
  Eme_sen <- bind_rows(lapply(Paths_sen, fread)) %>% 
    mutate(sen = sen) %>% 
    filter(
      n_ens == 10
    ) %>% 
    left_join(Neighbours,
              by = c("eez_name","eez_neighbour")
    ) %>% 
    rename(sf_eez_name=eez_name) %>% 
    left_join(Matching_names,
              by=  "sf_eez_name") %>% 
    clean_names()
  
  return(Eme_sen)
  
}

Sen_data <- bind_rows(
  lapply(sen_list,read_sen)
) %>% 
  filter(
    tresh== "tresh_two"
  )

unique(Sen_data$sen)

```

```{r data_analysis, eval = F, echo = F}

# Per Stock
sen_stock_d <-  
  Sen_data %>% 
  left_join(Neighbours) %>%
  group_by(taxon_key,neighbour_id,sen) %>% 
  summarise(
    taxon_emer = min(emerging_yr)
  ) %>% 
  group_by(taxon_emer,sen) %>% 
  summarise(
    n_tax = n()
  ) %>% 
  group_by(sen) %>% 
  mutate(
    com_sum = cumsum(n_tax),
    level = "stock"
  )


#  EEZ data
sen_eez_d <-  Sen_data %>% 
  left_join(Neighbours) %>% 
  filter(n_ens == 10) %>% 
  group_by(sf_eez_name,sen) %>% 
  summarise(
    taxon_emer = min(emerging_yr)
  ) %>% 
  group_by(taxon_emer,sen) %>% 
  summarise(
    n_tax = n()
  ) %>% 
  group_by(sen) %>% 
  mutate(
    com_sum = cumsum(n_tax),
    level = "eez"
  )


# Plot Data
sen_plot_data <- sen_stock_d %>% 
  bind_rows(sen_eez_d) %>% 
  mutate(
    # total = ifelse(level == "stock",length(unique(Eme_Res$taxon_key)),length(unique(Eme_Res$sf_eez_name))),
    total = ifelse(level == "stock",max(sen_stock_d$com_sum),max(sen_eez_d$com_sum)),
    per = com_sum/total*100
  ) %>% 
  gather("metric","value",com_sum,per) %>% 
  ungroup() %>% 
  mutate(
    my_facet = ifelse(metric == "per","Percentage (%)","Cumulative sum (n stocks)"),
    label = ifelse(total == max(sen_stock_d$com_sum),"Total number of emerging stocks","Total number of EEZs"),
  sen = paste("Percentile above",sen,"%") 
  )


# Lines data
dashed_lines <- tibble(
  x = c(2030,2050,2080),
  label = c("Agenda 2030","Early range shift  ","Late range shift   ")
)

# Plot me
ggplot() +
  geom_area(data = subset(sen_plot_data, level == "stock"),
            aes(
              x = as.numeric(taxon_emer),
              y = value,
              fill = level
            ),
            size=0.5,
            colour="black"
  )  +
  geom_area(data = subset(sen_plot_data, level == "eez"),
            aes(
              x = as.numeric(taxon_emer),
              y = value,
              fill = level
            ),
            size=0.5,
            colour="black"
  )  +
  # Shameslly plot it again to fix colors
  geom_area(data = subset(sen_plot_data, level == "stock" & my_facet == "Percentage (%)"),
            aes(
              x = as.numeric(taxon_emer),
              y = value,
              fill = level
            ),
            size=0.5,
            colour="black"
  ) +
  facet_wrap(~my_facet + sen,
             scales = "free",
             nrow=2) + 
  scale_y_continuous("",
                     expand = c(0,0)
  ) +
  scale_x_continuous("Year of range shift",
                     breaks = seq(2000,2100,25),
                     limits = c(2005,2100),
                     label = c(seq(2000,2075,25),">2100"),
                     expand = c(0,0)
  ) +
  # Add dashed lines and labels
  geom_vline(
    data = dashed_lines,
    aes(
      xintercept = x,
      linetype = label,
    ),
    color = "grey"
  ) + 
  my_ggtheme_p() +
  theme(
    legend.position = "right",
    panel.spacing = unit(3, "lines") # space between plots
  ) +
  guides(fill=guide_legend(title= "", reverse=FALSE),
         linetype = guide_legend(title = "Time step")) +
  scale_fill_viridis(discrete = T,
                     begin = 0.1, 
                     end = 0.7,
                     labels = c("EEZs","Stocks")
  ) +
  ggsave("./Figures/Supp3.png",
         width = 14,
         height = 10,
         units = "in"
  )

```




# END PAPER











# Troubleshooting

### Weird connections from Australia

```{r fig_map_Juan, eval = F, echo =F}

##_----------------------- #
# Checking on China and Indonesia
# Probably due to dispute territories

Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE) %>% 
  clean_names()

# 
# Neighbours %>% 
#   filter(eez_name == "China") %>% 
#   pull(eez_neighbour) %>% 
#   unique()

##_----------------------- #


# Get the center poligon of each EEZ for map source/target
coords <- as.data.frame(st_centroid(World_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,longitude
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

# Prepare data from results
Test_Data <- results %>% 
  # get coords for sources
  left_join(coords,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(coords,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  mutate(
    per_mid = ifelse(is.na(per_mid),0,per_mid)
  ) %>% 
  drop_na() %>% 
  filter(
    # per_mid >= 20,
    variable == "mean_spp",
  )


# Convert to data to spatial
network_data_sf <- Test_Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  st_sf(geometry = .)%>%
  bind_cols(Test_Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  sf::st_sf(crs = 4326)

#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest() %>% 
  mutate_at(vars(X,Y), round,2)

# Plot it!

country <- c("Fiji","Solomon Isl.","Tuvalu")

ggplot() +
  geom_sf(
    # data = subset(world_map,name %in% country),
    data = world_map,
    size = 0.1, fill = "gray90", col = "gray90") +
  geom_sf(
    # data = subset(World_eez_sf, eez_name %in% country),
    data = World_eez_sf,
    size = 0.1, fill = "white", col = "gray70") +
  geom_point(data = Test_Data,
             # data = subset(Test_Data, source %in% country & target %in% source),
             aes(start_lon,
                 start_lat,
                 col = per_mid),
             size = 0.1,
             col = "black",
             # shape = 21,
             stroke = 1.5) +
  geom_path(data = paths,
            # data = subset(paths, source %in% country),
            aes(X, Y,
                group = interaction(line_id,subline_id),
                col = per_mid
            ),
            size = 0.3,
            arrow = arrow(length = unit(0.009, "npc")),
            show.legend = NA) +
  # geom_sf_text(data = subset(World_eez_sf, eez_name %in% country),
  #              aes(label =eez_name),
  #              size = 2) +
  # geom_text(data = subset(Test_Data, source %in% country),
  #              aes(start_lon,
  #                start_lat,
  #                label = paste(source,"to",target)
  #              ),
  #              size = 2) +
  # geom_text_repel(data = Test_Data,
  #   aes(start_lon,
# start_lat,
# label = paste(source,"to",target)
# )
# )+
ggtheme_map() +
  scale_colour_gradientn("Gain of Stock-Share Ratio (%)",
                         colours = wesanderson::wes_palette("Zissou1", 100, type = "continuous"),
                         limits = c(0,25),
                         breaks = seq(0,25,5)
  )

```

### Arctic and Brasil missing species

```{r arctic, eval = F, echo =F}


# Old Code

###### Table.1 Multy linear model

```{r multiple_reg, eval = F, echo = F}

Arctic <- c("Canada (Arctic)","USA (Alaska, Arctic)", "Russia (Laptev to Chukchi Sea)")


can_us_arctic <- Transboundary_spp %>% 
  filter(eez_name == "Canada (Arctic)",
         eez_neighbour == "USA (Alaska, Arctic)")

arctic_spp <- Transboundary_spp %>% 
  filter(eez_name %in% Arctic,
         eez_neighbour %in% Arctic)



arctic_spp <- Spp_depth %>% 
  filter(taxon_key %in% can_us_arctic$taxon_key)


# Transbounudary species that will see no change
# 600252 Mallotus villosus  (Capelin)
# 600315 Eleginus gracilis (Safforn cod)
# 601520 Clupea pallasii  (Pacific herring)

Eme_Res %>% 
  filter(taxon_key %in% can_us_arctic$taxon_key) %>% 
  # filter(sau_eez_name %in% arctic_spp$eez_name) %>% 
  View(.)


```


```{r Brasa, eval = F, echo =F}

brasil <- Transboundary_spp %>% 
  filter(eez_name == "Brazil")

brasil_spp <- Spp_depth %>% 
  filter(taxon_key %in% brasil$taxon_key)

# Transbounudary species that will see no change
# 601590  Brevoortia pectinata  
# 690022  Pleoticus muelleri 
# 690023  Illex argentinus  
# 690338  Penaeus paulensis 


Eme_Res %>% 
  filter(taxon_key %in% brasil_spp$taxon_key) %>% 
  View(.)


```



```{r TransIndex, eval = F, echo = F}

TransIndex <- function(Spp,year, data_type = "Catch",ensemble_list,path,Neighbours,eez_centroid){
  
  # ----------------- #
  # Get Species Centrodis
  #  ---------------- #
  
  # Get model data from spps
  Spp_Dist <- bind_rows(
    lapply(
      ensemble_list,
      dbem_import,
      taxon_key = Spp,
      year = year,
      data_type = data_type,
      path = path
    )
  )
  
  
  #### Control for Spp id so I can fix problems
  
if(file.exists("~/Desktop/spp_df.csv") == FALSE){
  spp_df <- tibble() %>% 
    write_csv(.,
            "~/Desktop/spp_df.csv")
}

  suppressMessages(
    spp_df <- read_csv("~/Desktop/spp_df.csv")
  )
  spp_df <- tibble(Spp) %>% 
    bind_rows(spp_df) %>% 
    write_csv(.,
              "~/Desktop/spp_df.csv")
  
  
  #____________ Selecting only the transboundary nature of the species _________ #
  Trans_Spp <- Spp_Dist %>%
    left_join(index_code,
              by= "index") %>% 
    filter(!is.na(value)) %>% 
    semi_join(Transboundary_spp, # filter only transboundary cases
              by = c("taxon_key","eez_name")
    )
  
  # Step
  nr <- nrow(Trans_Spp)
  if(nr > 0){
    

    # Filter eez by those transboundary
  unique_eez <- unique(Trans_Spp$eez_name)
  
  Neighbours_combo <- Neighbours %>% 
    filter(eez_name %in% unique_eez,
           eez_neighbour %in% unique_eez)
    
    
    # Get the centroid of each country
    EEZ_centroid <- eez_centroid %>% 
      filter(eez_name %in% Trans_Spp$eez_name) %>% 
      mutate(taxon_key = Spp)
    
    
    Ids <- unique(Neighbours_combo$neighbour_id)
    
  corefx <- function(Ids){  
    
      EEZ_ids <- Neighbours_combo %>% 
        filter(neighbour_id == Ids)
      
      Sub_Trans_Spp <- Trans_Spp %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      Sub_EEZ_centroid <- EEZ_centroid %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      # Centroid is defined as the tile with the higest species value
      Centroids <- Sub_Trans_Spp %>% 
        left_join(EEZ_ids, by = "eez_name") %>% 
        group_by(taxon_key,year,ensemble,neighbour_id) %>%  # for whole distribution
        top_n(1,value) %>% 
        distinct(value,year, .keep_all = TRUE) %>%  # removes duplicates when tile is in between EEZs
        left_join(Sub_EEZ_centroid, by = "taxon_key") %>%
        select(eez_name =eez_name.y, everything() ,-eez_name.x)
      
      # Estimate distances between spp centroid and EEZ centroid
      Distance_Data <- Centroids %>%
        rename(
          catch_lon = lon,
          catch_lat = lat,
          eez_lon = longitude,
          eez_lat= latitude
        ) %>% 
        # Estimate the distance between centriods
        mutate(
          distance = geodist(eez_lon, eez_lat, catch_lon, catch_lat, units="km")
        ) %>% 
        select(taxon_key,eez_name,neighbour_id,ensemble,year,distance)
      
      # Historical mean and sd of distance
      historical <- Distance_Data %>%
        filter(year <= 2000) %>%
        ungroup() %>%
        group_by(taxon_key,ensemble,eez_name,neighbour_id) %>%
        summarise_at(vars("distance"),
                     c(hd_temp_mean=mean,
                       hd_temp_sd=sd)
        )
      
      
      # Future results
      future <- Distance_Data %>% 
        filter(year > 2000)
      
      # Transboundary Index
      Trans_index <- Distance_Data %>% 
        left_join(historical,
                  by = c("taxon_key","eez_name","ensemble","neighbour_id")
        ) %>%
        # Re arrenging table for mutate
        gather("variable","value",distance:hd_temp_sd) %>%
        ungroup()
      
      
      Partial <- Trans_index %>% 
        mutate(
          names = ifelse(eez_name ==Sub_EEZ_centroid$eez_name[1],paste("Country_A",variable,sep="_"),paste("Country_B",variable,sep="_"))
        ) %>%
        select(-eez_name,-variable) %>%
        spread(names,value) %>% 
        # mutate index
        mutate(
          trans_index = (Country_A_distance/Country_A_hd_temp_sd - Country_B_distance/Country_B_hd_temp_sd)^2
        ) %>% 
        group_by(taxon_key,ensemble,neighbour_id) %>% 
        mutate(RMean = rollmean(x = trans_index, 
                                10, 
                                align = "right", 
                                fill = trans_index)
        ) %>% 
        filter(year > 1960) %>% 
        select(taxon_key,neighbour_id,year,ensemble,trans_index,RMean)
      
      # Average of 10 years mean of ensemble members results
      mean_sd_index <- Partial %>% 
        group_by(taxon_key,year,neighbour_id) %>% 
        summarise_at(vars("RMean"),
                     c(trend=mean,
                       ensemble_sd=sd)
        )
      
      # Estimate noice from ensemble members
      historic_sd <- mean_sd_index %>% 
        filter(year < 2000) %>% 
        group_by(taxon_key) %>% 
        summarise_at(vars("trend"),
                     c(hist_mean=mean,
                       noise=sd)
        )
      
      
      # Plot the result, bruh
      # ggplot() +
      #   geom_line(data = mean_sd_index,
      #             aes(
      #               x = year,
      #               y = trend
      #             )
      #   ) +
      #   geom_ribbon(data = mean_sd_index,
      #               aes(x=year,
      #                   ymin=historic_sd$hist_mean-historic_sd$noise,
      #                   ymax=historic_sd$hist_mean+historic_sd$noise),
      #               alpha = 0.5,
      #               fill = "grey50"
      #   ) +
      #   geom_line(data = mean_sd_index,
      #             aes(
      #               x = year,
      #               y = historic_sd$hist_mean
      #             ),
      #             colour = "grey50"
      #   ) +
      #   geom_point(data = subset(mean_sd_index, trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise)),
      #              aes(
      #                x = year,
      #                y = trend,
      #                colour = "red",
      #              ),
      #              shape = 1,
      #              size = 3
      #   ) +
      #   geom_vline(xintercept = 2000,colour="blue",alpha = 0.5) +
      #   theme_classic()
      
      # #     
      Final_Result <- mean_sd_index %>%
        filter(year > 2000,
               trend > (historic_sd$hist_mean+historic_sd$noise) |
                 trend < (historic_sd$hist_mean-historic_sd$noise)
        ) %>%
        group_by(taxon_key,neighbour_id) %>%
        summarise(emerging_yr= min(year)) %>%
        left_join(EEZ_ids) %>%
        ungroup() %>%
        select(taxon_key,eez_name,eez_neighbour,emerging_yr)
      
      
      # if(i == 1){
      #   f_df <- Final_Result
      # }else{
      #   f_df <- bind_rows(f_df,Final_Result)
      # }
    return(Final_Result)
      }
    
  
  x <- bind_rows(
    mclapply(Ids,corefx)
  )
    # return(f_df)
    
  }else{
    
    print("no share data")
    
    x <- tibble(
      taxon_key = Spp,
      eez_name = NA,
      emerging_yr = NA
    )
    
  }
  
  return(x)

}

 
#  #One spp works 
# suppressMessages(
# TransIndex(Spp = 600006,
#              year,
#              data_type = "Catch",
#              ensemble_list,
#              path,
#              Neighbours = Neighbours,
#              eez_centroid)
# Multiple spp

# spp_list <- c(600004,
#               600005,
#               600245,
#               600006
#               )
# 
# suppressMessages(
#   suppressWarnings(
#     Test <- bind_rows(
#       lapply(spp_list,
#              TransIndex,
#              year,
#              data_type = "Catch",
#              ensemble_list,
#              path,
#              Neighbours,
#              eez_centroid
#       )
#     )
#   )
# )


```

###### With relation to neighbours

```{r time_emergence_map,  eval = F, echo = T}


##_----------------------- #
# Checking on China and Indonesia
# Probably due to dispute territories

Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE) %>% 
  clean_names()

# 
# Neighbours %>% 
#   filter(eez_name == "China") %>% 
#   pull(eez_neighbour) %>% 
#   unique()

##_----------------------- #


# Get the center poligon of each EEZ for map source/target
coords <- as.data.frame(st_centroid(World_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,longitude
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

# Prepare data from results
Test_Data <- Eme_Res %>% 
  filter(
    n_ens == 10#,
    # emerging_yr >= 2020
  ) %>% 
  group_by(eez_name,eez_neighbour,emerging_yr) %>% 
  summarise(
    n_tax = length(unique(taxon_key))
  ) %>% 
  filter(
    emerging_yr <= 2050
  ) %>%
  group_by(eez_name,eez_neighbour) %>% 
  summarise(
    n_tax_emer = sum(n_tax)
  ) %>% 
  # get coords for sources
  left_join(coords,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(coords,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  # mutate(
  #   per_mid = ifelse(is.na(per_mid),0,per_mid)
  # ) %>% 
  drop_na() #%>% 
  # filter(
    # per_mid >= 20,
    # variable == "mean_spp",
  # )


# Convert to data to spatial
network_data_sf <- Test_Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  st_sf(geometry = .)%>%
  bind_cols(Test_Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  sf::st_sf(crs = 4326)

#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest() %>% 
  mutate_at(vars(X,Y), round,2)

# Plot it!

country <- c("Fiji","Solomon Isl.","Tuvalu")

ggplot() +
  geom_sf(
    # data = subset(world_map,name %in% country),
    data = World_map,
    size = 0.1, fill = "gray90", col = "gray90") +
  geom_sf(
    # data = subset(World_eez_sf, eez_name %in% country),
    data = World_eez_sf,
    size = 0.1, fill = "white", col = "gray70") +
  geom_point(data = Test_Data,
             # data = subset(Test_Data, source %in% country & target %in% source),
             aes(start_lon,
                 start_lat,
                 col = n_tax_emer
                 ),
             size = 0.1,
             col = "grey50",
             # shape = 21,
             stroke = 1.5) +
  geom_path(data = paths,
            # data = subset(paths, source %in% country),
            aes(X, Y,
                group = interaction(line_id,subline_id),
                col = n_tax_emer
            ),
            size = 0.3,
            # arrow = arrow(length = unit(0.009, "npc")),
            show.legend = NA) +
  ggtheme_map() +
  scale_colour_viridis(
    name="Number of emerging stocks\nby 2050",
    limits = c(0,40),
    breaks = seq(0,40,10),
    # option="magma",
    direction = 1
  ) +
  ggsave("./Figures/figure_emerging_2050.png",
         width = 10,
         height = 6,
         units = "in"
  )


```

### Non selected Results

```{r, olda_acumulative, eval = F}

# filter(emerging_yr >= 2020) %>% 
  ggplot() +
    geom_area(data = subset(plot_data, level == "stock"),
              aes(
                x = as.numeric(taxon_emer),
                y = com_sum,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    )  +
    geom_area(data = subset(plot_data, level == "eez"),
              aes(
                x = taxon_emer,
                y = com_sum,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    ) +
    facet_wrap(~tresh) + 
    # Comment out for option A (Change plot name!!)
  #   geom_hline(yintercept = length(unique(Eme_Res$eez_name)), color = "grey",linetype = "dashed") +
  # geom_text(aes(label="Total number of EEZs", x = 2010, y = length(unique(Eme_Res$eez_name))+10), color = "grey70",size =3) +
  #   geom_hline(yintercept = length(unique(Eme_Res$taxon_key)), color = "grey",linetype = "dashed") +
  # geom_text(aes(label="Total number of Taxa", x = 2010, y = length(unique(Eme_Res$taxon_key))+10), color = "grey70",size =3) +
    scale_y_continuous("Cumulatuve Curve",
                       breaks = seq(0,600,50),
                       limits = c(0,600)
    ) +
    scale_x_continuous("Year of emergence",
                       breaks = seq(2005,2100,10),
                       limits = c(2005,2100)
    ) +
    my_ggtheme_p() +
    scale_fill_viridis(discrete = T) +
  ggsave("./Figures/figure_accumulative_curve_ab.png",
         width = 6,
         height = 6,
         units = "in" 
  )
  
  
  ### Percentage accumulation

  ggplot() +
    geom_area(data = subset(plot_data, level == "stock"),
              aes(
                x = as.numeric(taxon_emer),
                y = per,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    )  +
    geom_area(data = subset(plot_data, level == "eez"),
              aes(
                x = taxon_emer,
                y = per,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    ) +
    scale_y_continuous("Cumulatuve Curve",
                       breaks = seq(0,100,25),
                       limits = c(0,100)
    ) +
    scale_x_continuous("Year of emergence",
                       breaks = seq(2005,2100,15),
                       limits = c(2005,2100)
    ) +
    my_ggtheme_p() +
    scale_fill_viridis(discrete = T) +
    # facet_wrap(~tresh) + 
  ggsave("./Figures/Fig4.png",
         width = 8,
         height = 8,
         units = "in"
  )
  

```



```{r histo,  eval = F, echo = T}

# First time a Species becomes emergent
Eme_Res %>% 
  filter(
    n_ens == 10#,
    # tresh == "tresh_one"
  ) %>% 
  group_by(tresh,taxon_key,emerging_yr) %>% 
  summarise(
    n_trans = length(unique(sf_eez_name))
  ) %>% 
  group_by(tresh,taxon_key) %>% 
  summarise(
    ntrans = min(emerging_yr)
  ) %>% 
  group_by(tresh,ntrans) %>% 
  summarise(
    n_taxa = length(unique(taxon_key))
  ) %>% 
  arrange(-n_taxa) %>% 
  # View()
  # group_by(tresh) %>% 
  # summarise(sum(n_taxa))
  ggplot() +
  geom_line(
    aes(
      x = ntrans,
      y = n_taxa,
      color = tresh
    )
  )


# EEZ, first time an EEZ has a emergent stock
Eme_Res %>% 
  filter(
    n_ens == 10#,
    # tresh == "tresh_one"
  ) %>% 
  group_by(tresh,sf_eez_name,emerging_yr) %>% 
  summarise(
    n_trans = length(unique(taxon_key))
  ) %>% 
  group_by(tresh,sf_eez_name) %>% 
  summarise(
    ntrans = mean(emerging_yr)
  ) %>% 
  group_by(tresh,ntrans) %>% 
  summarise(
    n_taxa = length(unique(sf_eez_name))
  ) %>% 
  arrange(-n_taxa) %>% 
  View()
  # group_by(tresh) %>%
  # summarise(sum(n_taxa))
  # ggplot() +
  # geom_line(
  #   aes(
  #     x = ntrans,
  #     y = n_taxa,
  #     color = tresh
  #   )
  # )
  

# Numer of EEZs where stocks will emerge
stock_d_hist <- Eme_Res %>% 
  distinct(taxon_key,neighbour_id,tresh, .keep_all = TRUE) %>%
  group_by(emerging_yr,taxon_key,tresh) %>%
  summarise(n_tax = length(unique(sf_eez_name))) %>%
  # summarise(n()) %>% 
  mutate(
    level = "EEZs per Spp"
  )  %>% 
  ungroup() %>% 
  select(-taxon_key)


# Per EEZs
eez_d_hist <- Eme_Res %>% 
  distinct(taxon_key,neighbour_id,tresh, .keep_all = TRUE) %>%
  group_by(emerging_yr,sf_eez_name,tresh,neighbour_id) %>%  
  # summarise(n_tax = length(unique(taxon_key))) %>% 
  summarise(n()) %>% 
  mutate(
    level = "Spp per EEZ"
  ) %>% 
  ungroup() %>% 
  select(-sf_eez_name)

stock_d_hist %>% 
  bind_rows(eez_d_hist) %>% 
  filter(tresh != "NA") %>% 
  ggplot() +
  geom_density(
    aes(
      x = emerging_yr,
      fill = level
    ),
    stat = "count",
    alpha= 0.8,
    size=0.5,
  ) +
  scale_y_continuous("Frequency",
                     # breaks = seq(0,300,50),
                     # limits = c(0,300)
  ) +
  scale_x_continuous("Year of emergence",
                     # breaks = seq(2006,2100,25),
                     # limits = c(2000,2100)
  ) +
  my_ggtheme_p() +
  scale_fill_viridis(discrete = T) +
  facet_wrap(~tresh) +
  ggsave("./Figures/hist_freq.png",
         width = 6,
         height = 6,
         units = "in"
  )

```


##### Temperature gradient

##### Fun `GetEnvData`

```{r get_env_data, eval = F, echo = T}

getEnvVar=function(yr,ModelRCP,RCP,Variable){
  
  if(ModelRCP == "IPSL"){
    ModelRCP = "IPSL-CM5A-MR"
    Filepath <- paste("/Volumes/DATA/DATA/Environmental data/Model Climate data/CMIP5/txt CMIP5/Reformatted",ModelRCP,RCP,"",sep="/")
  }
  
  
  if(ModelRCP == "MPI"){
    ModelRCP = "MPI-ESM-MR"
    Filepath <- paste("/Volumes/DATA/DATA/Environmental data/Model Climate data/CMIP5/txt CMIP5/Reformatted",ModelRCP,RCP,"",sep="/")
  }
  
  if(ModelRCP == "GFDL"){
    
    if(RCP == "rcp26"){
      ModelRCP <- "GFDL26"
    }else{
      ModelRCP <- "GFDL85"
    }
    Filepath <- paste("Z:/JULIANO_NEYMAR/PristineSeasData/Climate",ModelRCP,"",sep="/")
  }
  
  
  if(Variable == "Ice"){
    
    Bottom <- paste("IceExt_",yr,".txt",sep="")
    
  }
  
  if(Variable == "Temperature"){
    
    Bottom = paste("SST_",yr,".txt",sep="")
    
  }
  
  if(Variable == "Salinity"){
    # Bottom
    Bottom = paste("Salinity_btm_",yr,".txt",sep="")
    
  }
  
  Read_me <- paste(Filepath,Bottom,sep="")[1]
  Bottom_Data <- read.csv(Read_me,header=F)
  
  # Retrun
  
  getTemp <- Bottom_Data 
}

Years <-seq(1951,2100,1)

for(y in 1:length(Years)){
        Data <- getEnvVar(yr = Years[y],
                          Model = "GFDL",
                          Variable = "Temperature",
                          RCP = "rcp85"
        )
        
        if(y == 1){
          
          F_BData <- Data[1]
          colnames(F_BData) <- Years[1]
      
        }else{
          
          F_BData <- cbind(F_BData,Data[1])
          colnames(F_BData)[y] <- Years[y]
        }
}


F_BData <- F_BData %>% 
          rowid_to_column("index") %>% 
  gather("year","temp",-index) %>% 
   mutate(temp = ifelse(temp == -9999,NA,temp)) %>% 
  group_by(year) %>% 
  summarise(
    mean_temp = mean(temp,na.rm=T)
  ) %>% 
  write_csv(.,
            "SST_data.csv")

```


```{r temp_plot, eval = F, echo = T}

### NEED TO RUN TIME LAPSE CHUNK FIRST TO GET ACCUMULATIVE DATA

# Get sst_data
sst_data <- my_path("D",T,"Climate","SST_data.csv",read = T)

sst_hist <- sst_data %>% 
  filter(year < 2000) %>% 
  group_by() %>% 
  summarise(hist_sst =mean(mean_temp)) %>% 
  pull()

sst_change <- sst_data %>%
  filter(year > 2020) %>% 
  mutate(chng = round(mean_temp-sst_hist,2))


  
  # Plot Data
stock_d %>% 
  bind_rows(eez_d) %>% 
  filter(taxon_emer >= 2020) %>% 
  rename(year = taxon_emer) %>% 
  left_join(sst_change) %>% 
  ggplot() +
  geom_line(
    aes(
      x = chng,
      y = com_sum,
      colour = level
    )
  ) +
  geom_hline(yintercept = length(unique(Eme_Res$eez_name)), color = "grey",linetype = "dashed") +
  geom_text(aes(label="Total number of EEZs", x = 0.5, y = length(unique(Eme_Res$eez_name))+10), color = "grey70",size =3) +
    scale_y_continuous("Cumulatuve Curve",
                       breaks = seq(0,450,50),
                       limits = c(0,500)
    ) +
    scale_x_continuous("Change in SST (C)",
                       breaks = seq(0,2,0.2),
                       limits = c(0.3,2.3)
    ) +
    my_ggtheme_p() +
    scale_colour_viridis(discrete = T) +
  ggsave("./Figures/figure_temp.png",
         width = 6,
         height = 6,
         units = "in"
  )
  
```


```{r Scatter_plot,  eval = F, echo = T}




 data_stock <- Eme_Res %>% 
  filter(
    n_ens == 10,
    emerging_yr >= 2020
  ) %>% 
  group_by(emerging_yr,eez_name) %>% 
  summarise(
    tax_n = length(unique(taxon_key))
    ) %>% 
  group_by(emerging_yr) %>% 
  summarise(emerging_tax = sum(tax_n))

data_eez <- Eme_Res %>% 
  filter(
    n_ens == 10,
    emerging_yr >= 2020
  ) %>% 
  group_by(emerging_yr,taxon_key) %>% 
  summarise(
    eez_n = length(unique(eez_name))
    ) %>% 
    group_by(emerging_yr) %>% 
  summarise(emerging_eez = sum(eez_n))


data_stock %>% 
  left_join(data_eez,
            by = "emerging_yr") %>% 
  rename(year = emerging_yr) %>% 
  left_join(sst_data) %>% 
  ggplot() +
  geom_point(
    aes(
      x = mean_temp,
      y = emerging_eez,
      fill = year,
      colour = year
    )
  )
  
```
