---
title: Matching the Time of Emergence of Transboundary Fish Stocks to Lead Time for
  Policy Response Under Climate Change
author: "Juliano Palacios Abrantes"
date: "09/03/2020"
output:
  word_document: default
  html_document: default
subtitle: Initital analysis
editor_options: 
  chunk_output_type: console
---


```{r setup, eval = T, echo=F, warning=F,message=F, results='hide'}

#### READ ME !!! ####
# Run this chunk before knit so you make sure you have all pkgs installed in R

ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE,repos = "http://cran.us.r-project.org")
  sapply(pkg, require, character.only = TRUE)
}


#### Library ####
packages <- c(
  "tidyverse",
  "here", # for dbem_import `here()`
  "data.table", #dbem_import `fread()`
  "readxl", # for reading excell files
  "janitor", # for clearing names
  "geosphere", # estimate distances between points `distm()`
  "ggrepel",
  "zoo",
  "parallel", # for mclapply,
  "sf", # for mapping
  "st", # for mapping
  "rgdal", #Spatial analysis
  "tools", #Spatial analysis 
  "zeallot", # for Juanito's map
  "gmt" # for estimating distances between points
)

ipak(packages)


# Set paths depending on machine Beast (jepa88), "carmelia" or Hall1000
if(Sys.info()[7] == "jepa88"){
  data_path <- "Z:/DATA/DBEM/"
}
if(Sys.info()[7] == "carmelia"){
  data_path <- paste(here(),"/Temporal_Data/",sep = "")
  DBEM_path <- paste(data_path,"DBEM/",sep="")
  result_path <- paste(here(),"/Temporal_Data/Results/",sep="")
}
if(Sys.info()[7] == "hall1000"){
  data_path <- "/Volumes/DATA/JULIANO_NEYMAR/TransEmergence/Data/"
  DBEM_path <- "/Volumes/DATA/DATA/DBEM/"
  result_path <- "/Volumes/DATA/JULIANO_NEYMAR/TransEmergence/Results/"
}



ggtheme_map <- function(base_size = 9, Region = "NA") {
  
  theme(text             = element_text(#family = "Helvetica",
    color = "gray30", size = base_size),
    plot.title       = element_text(size = rel(1.25), hjust = 0, face = "bold"),
    panel.background = element_blank(),
    panel.border     = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "transparent"),
    strip.background =element_rect(fill = "transparent"),
    strip.text.x = element_text(size = 18, colour = "black",face= "bold.italic", angle = 0),
    axis.line        = element_blank(), # element_line(colour = "grey30", size = .5))
    axis.ticks       = element_blank(),
    axis.text        = element_blank(),
    axis.title       = element_blank(),
    legend.key       = element_rect(colour = NA, fill = NA, size = 4),
    legend.position = "bottom",
    legend.key.width =unit(5,"line")
  )
}

```


# Methods

### Fun `dbem_import`

This function reads the DBEM data for each year and ensamble (ESM model) from 102 20 111


```{r dbem_import, eval = F, echo = T}

dbem_import <- function(taxon_key, #Except taxon_key 
                        year, #Expects sequence of years 
                        ensamble, #Expects a number of the ensamble
                        data_type, #Expects either "Abd" or "Catch"
                        path = "NA"){
  

  years <- year_df %>% pull(year)
  
  D_Path <- paste(path,"mpa0F1ENS",ensamble,"/",taxon_key,"/",taxon_key,data_type,years,".txt",sep="")

  
  #### Importing data ####
  cur <- lapply(D_Path, FUN=fread, na.strings="NA")
  
  if(length(cur)>0){
    cur <- cur[sapply(cur, function(d) nrow(d) >= 1)] 
    colnames <- c("index", "value")
    cur <- lapply(cur, setNames, colnames)
    df <- bind_rows(cur, .id = "column_label")
    if(nrow(df)>0){
      frame_key <- tibble(column_label = seq(1,length(unlist(years)),1), 
                          "year"=years) %>% 
        mutate(column_label=as.character(column_label))
      df <- left_join(df, frame_key, by="column_label") %>% select(-column_label)
      df <- df %>% mutate(data_type=data_type,
                          taxon_key = taxon_key,
                          ensamble = ensamble
      )
    }
  } else {
    df <- tibble()
  }
    return(df)
} #Function end


# x <- dbem_import(
#   taxon_key <- 600004,
#   Year <- year_df,
#   data_type <- "Catch",
#   ensamble = 102,
#   # ensamble_list =ensamble,
#   path <- DBEM_path
# )


# attach(x)
# head(x)
# unique(year)
# unique(ensamble_list)
# detach(x)

```


## Determine Coords centroids and Neighbouring ids


```{r, get_eez_centroids, eval = F}

# Load SAU shapefile name and paths

# The path
path_world <- paste(data_path,"Spatial/SAU_Shapefile/",sep="")

# The File
fnam_world <- "SAUEEZ_July2015.shp"

# Load it!
World_eez_sf <- st_read(dsn = path_world,
                    layer =file_path_sans_ext(fnam_world)) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1)

# Get the center poligon of each EEZ for map source/target with st_centroid
coords <- as.data.frame(st_centroid(World_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,
                             ifelse( eez_name == "Brazil",-36.937,longitude
                             )
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

write_csv(coords,
          "eez_centroids.csv")


# Get id of neighbouring pairs
Neighbours_spp <- Transboundary_spp %>% 
  group_by(eez_name,eez_neighbour) %>% 
  summarise(n=n()) %>% 
  ungroup() %>% 
  select(-n) %>% 
  rownames_to_column("neighbour_id")
    
#  set ids 
df1 <- Neighbours_spp
df2 <- Neighbours_spp
colnames(df2) <- c("neighbour_id", "eez_neighbour", "eez_name")

df_full <- bind_rows(df1, df2) %>% 
  group_by(eez_neighbour,eez_name) %>% 
  summarise(neighbour_id = min(neighbour_id))

# write_csv(df_full, "Neighbours_eez_id.csv")
    
```

## Estimating Proportion Change

#### Fun `EstPropChange`

```{r EstPropChange, eval = F, echo = F}

EstPropChange <- function(taxon_key,
                          year,
                          data_type,
                          ensamble_list, # expects a list of ensambles to averrage by
                          path,
                          neighbours){
  
  
  # Loads species data for all ensambles
  spp_dist <- bind_rows(
    lapply(
      ensamble_list,
      dbem_import,
      taxon_key = taxon_key,
      year = year,
      data_type = data_type,
      path = path
    )
  )
  
  
  # head(spp_dist)
  
  # Result 1. Number of Countries that share the species
  
  suppressWarnings(
    trans_EEZ <- Transboundary_spp %>% 
      filter(taxon_key %in% spp_dist$taxon_key) %>% 
      left_join(Neighbours,
                by = c("eez_name","eez_neighbour")
      )
  )
  
  
  # List of indexes per EEZ
  index_id <- trans_EEZ %>% 
    group_by(eez_name,index) %>% 
    summarise(n=n()) %>% 
    select(-n)
  
  
  # --------------- #
  # Warning messages:
  # 1: Column `eez_name` joining factor and character vector, coercing into character vector 
  # 2: Column `eez_neighbour` joining factor and character vector, coercing into character vector 
  # --------------- #
  
  
  #____________ Selecting only the transboundary nature of the species _________ #
  trans_spp <- spp_dist %>%
    filter(index %in% trans_EEZ$index) %>% 
    left_join(index_id,
              by = "index")
  
  #____________ ESTIMATING DISTRIBUTION INDEX (TRESHOLD 3)_________ #
  # The number of species' cells present within each country's EEZ
  
  #Step 1.  Get EEZ id and Neighbour
  Neighbours_List <- Neighbours %>% 
    group_by(eez_name,eez_neighbour) %>% 
    summarise(n=n()) %>% 
    ungroup() %>% 
    select(-n) %>% 
    semi_join(trans_EEZ,
              by = c("eez_name","eez_neighbour")
    )
  
  # Step 2. Determines the amount of grids present in each country
  spp_grid <- trans_spp %>% 
    group_by(taxon_key,
             eez_name,
             year,
             ensamble) %>% 
    summarise(n_spp_eez = length(unique(index))) %>% 
    left_join(Neighbours_List,
              by = "eez_name")
  
  # Step 3. Sum total grids per Neighbours
  
  # Split dataframes to merge latter
  Territory_T <- spp_grid %>% 
    ungroup() %>% 
    select(
      taxon_key,
      Name=eez_name,
      n_spp_eez,
      year,
      ensamble
    )
  
  Neighbour_T <- spp_grid %>% 
    ungroup() %>% 
    select(
      taxon_key,
      n_spp_eez,
      Name=eez_neighbour,
      eez_name,
      year,
      ensamble
    )
  
  per_change_d <- full_join(Territory_T,
                            Neighbour_T, 
                            by = c("Name","taxon_key","year","ensamble")
  ) %>%
    rowwise() %>%
    mutate(Spp_Total = sum(n_spp_eez.x,n_spp_eez.y,na.rm=T)) %>% # Total gridcelles per Neighbours
    distinct() %>% # Removes false duplicates from `full_join()`
    rename(eez_name = Name,
           eez_neighbour =eez_name,
           n_spp_Country = n_spp_eez.x,
           n_spp_Neighbour = n_spp_eez.y) %>% 
    mutate(area_index = n_spp_Country/Spp_Total) %>% 
    # select(taxon_key,year,ensamble_list,eez_name,eez_neighbour,area_index) %>% 
    mutate(
      time_step = ifelse(year < 2000,"historical",
                         ifelse(year >= 2045 & year <= 2064, "mid",
                                ifelse(year >= 2080, "n_end","NA")
                         )
      )
    ) %>%
    filter(time_step != "NA") %>% 
    # Time mean and sd
    ungroup() %>% 
    group_by(taxon_key,ensamble,eez_name,eez_neighbour,time_step) %>% 
    summarise_at(vars("area_index"),
                 c(temporal_mean=mean,
                   temporal_sd=sd)
    ) %>% 
    # Ensamble mean and sd
    group_by(taxon_key,eez_name,eez_neighbour,time_step) %>%
    summarise_at(vars("temporal_mean"),
                 c(ensamble_mean=mean,
                   ensamble_sd=sd),
                 na.rm=T
    )
  
  # --------------- #
  # End function
  # --------------- #
  
  if(nrow(per_change_d) > 0){
  
  # Save Result
  name <- paste("proportion_",taxon_key,".csv",sep="")
  path_name <- paste(result_path,"Proportion/",name, sep="")
  
  write_csv(per_change_d,
            path_name)
  
  return(print(paste("analysis done",taxon_key)))
  
  }else{
    print(paste("no result for",taxon_key))
  }
  
  # Or return a df
  # return(per_change_d)
}

```

#### Proportion routine

```{r Proportion_routine, eval = F, echo = F}

####_______________________ ####
# Estimating proportion change
####_______________________ ####

t_start <- Sys.time()

mclapply(
  spp_list,
  EstPropChange,
  year <- year_df,
  data_type <- "Catch",
  ensamble_list = ensamble_list,
  path = DBEM_path,
  neighbours = Neighbours
)

t_end <- Sys.time()-t_start;t_end

# Hall 1000 ran it in 5.33 hours

```


## Estimating emerging year

#### Fun `TransIndex` 

```{r TransIndex, eval = F, echo = T}

TransIndex <- function(Spp,year, data_type = "Catch",ensamble_list,path,Neighbours,eez_centroid){
  
  # ----------------- #
  # Get Species Centrodis
  #  ---------------- #
  
  # Get model data from spps
  Spp_Dist <- bind_rows(
    lapply(
      ensamble_list,
      dbem_import,
      taxon_key = Spp,
      year = year,
      data_type = data_type,
      path = path
    )
  )
  
  #### Control for Spp id so I can fix problems
  
if(file.exists("~/Desktop/spp_df.csv") == FALSE){
  spp_df <- tibble() %>% 
    write_csv(.,
            "~/Desktop/spp_df.csv")
}

  suppressMessages(
    spp_df <- read_csv("~/Desktop/spp_df.csv")
  )
  spp_df <- tibble(Spp) %>% 
    bind_rows(spp_df) %>% 
    write_csv(.,
              "~/Desktop/spp_df.csv")
  
  
  #____________ Selecting only the transboundary nature of the species _________ #
  Trans_Spp <- Spp_Dist %>%
    left_join(index_code,
              by= "index") %>% 
    filter(!is.na(value)) %>% 
    semi_join(Transboundary_spp, # filter only transboundary cases
              by = c("taxon_key","eez_name")
    )
  
  # Step
  nr <- nrow(Trans_Spp)
  if(nr > 0){
    

    # Filter eez by those transboundary
  unique_eez <- unique(Trans_Spp$eez_name)
  
  Neighbours_combo <- Neighbours %>% 
    filter(eez_name %in% unique_eez,
           eez_neighbour %in% unique_eez)
    
    
    # Get the centroid of each country
    EEZ_centroid <- eez_centroid %>% 
      filter(eez_name %in% Trans_Spp$eez_name) %>% 
      mutate(taxon_key = Spp)
    
    
    Ids <- unique(Neighbours_combo$neighbour_id)
    
  corefx <- function(Ids){  
    
      EEZ_ids <- Neighbours_combo %>% 
        filter(neighbour_id == Ids)
      
      Sub_Trans_Spp <- Trans_Spp %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      Sub_EEZ_centroid <- EEZ_centroid %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      # Centroid is defined as the tile with the higest species value
      Centroids <- Sub_Trans_Spp %>% 
        left_join(EEZ_ids, by = "eez_name") %>% 
        group_by(taxon_key,year,ensamble,neighbour_id) %>%  # for whole distribution
        top_n(1,value) %>% 
        distinct(value,year, .keep_all = TRUE) %>%  # removes duplicates when tile is in between EEZs
        left_join(Sub_EEZ_centroid, by = "taxon_key") %>%
        select(eez_name =eez_name.y, everything() ,-eez_name.x)
      
      # Estimate distances between spp centroid and EEZ centroid
      Distance_Data <- Centroids %>%
        rename(
          catch_lon = lon,
          catch_lat = lat,
          eez_lon = longitude,
          eez_lat= latitude
        ) %>% 
        # Estimate the distance between centriods
        mutate(
          distance = geodist(eez_lon, eez_lat, catch_lon, catch_lat, units="km")
        ) %>% 
        select(taxon_key,eez_name,neighbour_id,ensamble,year,distance)
      
      # Historical mean and sd of distance
      historical <- Distance_Data %>%
        filter(year <= 2000) %>%
        ungroup() %>%
        group_by(taxon_key,ensamble,eez_name,neighbour_id) %>%
        summarise_at(vars("distance"),
                     c(hd_temp_mean=mean,
                       hd_temp_sd=sd)
        )
      
      
      # Future results
      future <- Distance_Data %>% 
        filter(year > 2000)
      
      # Transboundary Index
      Trans_index <- Distance_Data %>% 
        left_join(historical,
                  by = c("taxon_key","eez_name","ensamble","neighbour_id")
        ) %>%
        # Re arrenging table for mutate
        gather("variable","value",distance:hd_temp_sd) %>%
        ungroup()
      
      
      Partial <- Trans_index %>% 
        mutate(
          names = ifelse(eez_name ==Sub_EEZ_centroid$eez_name[1],paste("Country_A",variable,sep="_"),paste("Country_B",variable,sep="_"))
        ) %>%
        select(-eez_name,-variable) %>%
        spread(names,value) %>% 
        # mutate index
        mutate(
          trans_index = (Country_A_distance/Country_A_hd_temp_sd - Country_B_distance/Country_B_hd_temp_sd)^2
        ) %>% 
        group_by(taxon_key,ensamble,neighbour_id) %>% 
        mutate(RMean = rollmean(x = trans_index, 
                                10, 
                                align = "right", 
                                fill = trans_index)
        ) %>% 
        filter(year > 1960) %>% 
        select(taxon_key,neighbour_id,year,ensamble,trans_index,RMean)
      
      # Average of 10 years mean of ensamble members results
      mean_sd_index <- Partial %>% 
        group_by(taxon_key,year,neighbour_id) %>% 
        summarise_at(vars("RMean"),
                     c(trend=mean,
                       ensamble_sd=sd)
        )
      
      # Estimate noice from ensamble members
      historic_sd <- mean_sd_index %>% 
        filter(year < 2000) %>% 
        group_by(taxon_key) %>% 
        summarise_at(vars("trend"),
                     c(hist_mean=mean,
                       noise=sd)
        )
      
      
      # Plot the result, bruh
      # ggplot() +
      #   geom_line(data = mean_sd_index,
      #             aes(
      #               x = year,
      #               y = trend
      #             )
      #   ) +
      #   geom_ribbon(data = mean_sd_index,
      #               aes(x=year,
      #                   ymin=historic_sd$hist_mean-historic_sd$noise,
      #                   ymax=historic_sd$hist_mean+historic_sd$noise),
      #               alpha = 0.5,
      #               fill = "grey50"
      #   ) +
      #   geom_line(data = mean_sd_index,
      #             aes(
      #               x = year,
      #               y = historic_sd$hist_mean
      #             ),
      #             colour = "grey50"
      #   ) +
      #   geom_point(data = subset(mean_sd_index, trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise)),
      #              aes(
      #                x = year,
      #                y = trend,
      #                colour = "red",
      #              ),
      #              shape = 1,
      #              size = 3
      #   ) +
      #   geom_vline(xintercept = 2000,colour="blue",alpha = 0.5) +
      #   theme_classic()
      
      # #     
      Final_Result <- mean_sd_index %>%
        filter(year > 2000,
               trend > (historic_sd$hist_mean+historic_sd$noise) |
                 trend < (historic_sd$hist_mean-historic_sd$noise)
        ) %>%
        group_by(taxon_key,neighbour_id) %>%
        summarise(emerging_yr= min(year)) %>%
        left_join(EEZ_ids) %>%
        ungroup() %>%
        select(taxon_key,eez_name,eez_neighbour,emerging_yr)
      
      
      # if(i == 1){
      #   f_df <- Final_Result
      # }else{
      #   f_df <- bind_rows(f_df,Final_Result)
      # }
    return(Final_Result)
      }
    
  
  x <- bind_rows(
    mclapply(Ids,corefx)
  )
    # return(f_df)
    
  }else{
    
    print("no share data")
    
    x <- tibble(
      taxon_key = Spp,
      eez_name = NA,
      emerging_yr = NA
    )
    
  }
  
  return(x)

}

 
#  #One spp works 
# suppressMessages(
# TransIndex(Spp = 600006,
#              year,
#              data_type = "Catch",
#              ensamble_list,
#              path,
#              Neighbours = Neighbours,
#              eez_centroid)
# Multiple spp

# spp_list <- c(600004,
#               600005,
#               600245,
#               600006
#               )
# 
# suppressMessages(
#   suppressWarnings(
#     Test <- bind_rows(
#       lapply(spp_list,
#              TransIndex,
#              year,
#              data_type = "Catch",
#              ensamble_list,
#              path,
#              Neighbours,
#              eez_centroid
#       )
#     )
#   )
# )


```

#### Emerging Control Panel

```{r Emerging_control_panel, eval = F}

# Data needed for estimating Proportion change

# SAU relations between INDEX and Country's EEZs
EEZIDs_List <- read_excel(paste(data_path,"Spatial/V_Lam/Updated_EEZList_17June2016.xlsx",sep="")) %>% 
  clean_names()
EEZ_CellID <- read_excel(paste(data_path,"Spatial/V_Lam/EEZ_CellID.xlsx",sep="")) %>% 
  clean_names()
colnames(EEZ_CellID) <- c("eezid","index")

Lon_Lat_DBEM <- read.csv(paste(data_path,"Spatial/Lon_Lat_DBEM.txt",sep=""), header=FALSE)
colnames(Lon_Lat_DBEM) <- c("index","lon","lat")

index_code <- EEZIDs_List %>% 
  left_join(EEZ_CellID) %>% 
  rename(eez_name = name) %>% 
  left_join(Lon_Lat_DBEM,
            by = "index")

year_df <- tibble(year =  c(seq(1951,2000,1), seq(2001,2099,1)),
                  time_period = c(rep("historic", 50), rep("future", 99))
                  )

data_type <- "catch"
ensamble_list <- seq(102,103,1)
world_grid <- tibble(index = seq(1,259200,1))
path = DBEM_path

eez_centroid <- read.csv(paste(data_path,"Spatial/eez_centroids.csv", sep = ""), header=TRUE)

Neighbours <- read.csv(paste(data_path,"Spatial/Neighbours_eez_id.csv",sep="")) %>% clean_names()

Transboundary_spp <- read.csv(paste(data_path,"Species/Transboundary_spp.csv",sep="")) %>% 
  clean_names()

spp_list <- unique(Transboundary_spp$taxon_key)

```


#### Emerging Routine
```{r Emerging_routine, eval = F, echo = F}

####_______________________ ####
# Estimating year of eergence
####_______________________ ####


spp_list <- c(600004,
              600005,
              600245,
              600006
              )

t_start <- Sys.time()

suppressMessages(
  suppressWarnings(
    Test <- bind_rows(
      mclapply(spp_list,
             TransIndex,
             year,
             data_type = "Catch",
             ensamble_list,
             path,
             Neighbours,
             eez_centroid
      )
    )
  )
)


t_end <- Sys.time()-t_start;t_end

# Version 1 (embeded loop) <- 3.01
# Version 2 (embeded lapply) <- 2.71
# Version 3 (embeded mclapply) <- 1.597311 mins
# Version 4 (embeded mclapply) + mclapply in spp <- 1.597311 mins


```


# Results

## Percentage Change

This results only shows the average percentage change in proportion of all speecies within an EEZ without relationship with neighbours

### Functions and Data needed

#### Fun `SummaryProp`

This function estimates the total change in MCP proportion of each species for each EEZ. It looses the connection with neighbours as you only know for x species houw much is the proportion changing.

```{r fun_SummaryProp, eval = T, echo =F}

SummaryProp <- function(taxon_key,links="NA"){
  
  # Reads taxon data
  proportion_data <- fread(paste(result_path,"Proportion/","proportion_",taxon_key,".csv", sep=""))
  
  if(links == "y"){
    # summarizes by country
    country_summary <- proportion_data %>% 
      group_by(taxon_key,eez_name,eez_neighbour,time_step) %>% 
      summarise(
        mean_spp = mean(ensamble_mean,na.rm=T) # average spp change from all countries sharing
      )
    
  }else{
    # summarizes by country
    country_summary <- proportion_data %>% 
      group_by(taxon_key,eez_name,time_step) %>% 
      summarise(
        mean_spp = mean(ensamble_mean,na.rm=T) # average spp change from all countries sharing
      )
    }
  
  return(country_summary)
}

```


#### Fun `EEZProp`

The next step is to summarize all species per eez

```{r fun_EEZProp, eval = T, echo = F}

EEZProp <- function(taxon_list,links="NA"){

 spp <- bind_rows(
   lapply(taxon_list,SummaryProp,links)
   )
 
 if(links == "y"){
   
   eez_summary <- spp %>% 
     group_by(eez_name,eez_neighbour,time_step) %>% 
     summarise(
       n_spp = n(),
       min_spp = min(mean_spp,na.rm=T),
       max_spp = max(mean_spp,na.rm=T),
       sd_spp = sd(mean_spp,na.rm=T), # for some weird reason it wont work if the order is fliped
       mean_spp = mean(mean_spp,na.rm=T)
     ) %>% 
     select(eez_name:max_spp,mean_spp,sd_spp)
   
 }else{
 
   eez_summary <- spp %>% 
   group_by(eez_name,time_step) %>% 
   summarise(
     n_spp = n(),
     min_spp = min(mean_spp,na.rm=T),
     max_spp = max(mean_spp,na.rm=T),
     sd_spp = sd(mean_spp,na.rm=T), # for some weird reason it wont work if the order is fliped
     mean_spp = mean(mean_spp,na.rm=T)
   ) %>% 
   select(eez_name:max_spp,mean_spp,sd_spp)
 
 
 }
 
 return(eez_summary)

}

```


#### Fun `PropChange`

Finally, we estimate the average proportion change of all species within each eez


```{r fun_PropChange, eval = T, echo =F}

PropChange <- function(taxon_list,links="NA"){

 eez <- EEZProp(taxon_list,links)
 
 proportion_change <- eez %>% 
   gather("variable","value",n_spp:sd_spp) %>% 
   spread(time_step,value) %>% 
   mutate_at(vars(
     "per_mid" = mid,
     "per_end" = n_end),
            funs(round((((.-historical)/.))*100,2))
   )
 
 return(proportion_change)

}

```


### Run Results Analysis

```{r fun_PropChange, eval = T, echo =F}

# Get taxon list
taxon_list <- list.files(paste(result_path,"/Proportion/",sep=""))

# clean names for function
taxon_list <- gsub(".*_","",taxon_list) 
taxon_list <- gsub("\\..*","",taxon_list)

# Run results
results <- PropChange(taxon_list, links="y") %>% 
  mutate(per_mid =ifelse(per_mid >= 25, 25,
                           ifelse(per_mid <= -25,-25,per_mid)
                           )
         )

# View(results)

### Load Data

# Load SAU shapefile name and paths

# The path
path_world <- paste(data_path,"Spatial/SAU_Shapefile/",sep="")

# The File
fnam_world <- "SAUEEZ_July2015.shp"

# Load it!
World_eez_sf <- st_read(dsn = path_world,
                    layer =file_path_sans_ext(fnam_world)) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1)



# Call world map from natural earth
world_map <- rnaturalearth::ne_countries(scale = 'small', returnclass = c("sf"))

coords <- read.csv(coords)


```

### Fig.Percentage Change Map

```{r fig_map_per, eval = F, echo =F}

World_sf %>% 
  left_join(results,
            by = "eez_name") %>% 
  filter(variable %in% c("mean_spp")#,
         # eez_name %in% c("Peru","Chile","Ecuador","Argentina")
         ) %>% 
  ggplot() +
  geom_sf(
    aes(
      fill = per_mid
    )
  ) + 
  geom_sf(data=country10_sf) +
  scale_fill_gradient2("Average Change in\nStock-Share Ratio (%)\nBy Mid Century") +
  ggtheme_map() +
  ggsave("figure_one.png",
         width = 10,
         height = 6,
         units = "in"
  )

```


### Fig. Netowrk

```{r fig_map_Juan, eval = F, echo =F}

# Figure made thanks to Juanito!
# http://jsmayorga.com/post/mapping-the-global-network-of-transnational-fisheries/


# Prepare data from results
Data <- results %>% 
  # get coords for sources
  left_join(coords,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(coords,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  mutate(
    per_mid = ifelse(is.na(per_mid),0,per_mid)
  ) %>% 
  drop_na() %>% 
  filter(per_mid > 0,
         variable == "mean_spp"#,
         # source %in% c("Brazil","Argentina","Chile","Peru","Uruguay")
  )

# Convert to data to spatial
network_data_sf <- Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  st_sf(geometry = .)%>%
  bind_cols(Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  sf::st_sf(crs = 4326)

#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest() %>% 
  mutate_at(vars(X,Y), round,2)

# Plot it!

x <- ggplot() +
  geom_sf(data = world_map, size = 0.1, fill = "gray90", col = "gray90") +
  geom_sf(data = World_eez_sf, size = 0.1, fill = "white", col = "gray70") +
  geom_point(data = Data,
             aes(start_lon,
                 start_lat,
                 col = per_mid),
             size = 0.05,
             col = "black",
             shape = 20,
             stroke = 1.5) +
  geom_path(data = paths,
            aes(X, Y,
                group = interaction(line_id,subline_id),
                col = per_mid
            ),
            size = 0.3,
            arrow = arrow(length = unit(0.009, "npc")),
            show.legend = NA) +
  # geom_sf_text(data =World_eez_sf, aes(label =eez_name),
  #              size = 2) +
  # geom_text_repel(data = paths,
  #                  aes(
  #                    x = X,
  #                    y = Y,
  #                    label =source),
  #                  force = 1
  # )+
  ggtheme_map() +
  scale_colour_gradientn("Gain of Stock-Share Ratio (%)",
                         colours = wesanderson::wes_palette("Zissou1", 100, type = "continuous"),
                         limits = c(0,25),
                         breaks = seq(0,25,5)
  )+ 
  ggsave("figure_connections.png",
         width = 10,
         height = 6,
         units = "in"
  )

```



## Troubleshooting

### Weird connections from Australia

```{r fig_map_Juan, eval = F, echo =F}

##_----------------------- #
# Checking on China and Indonesia
# Probably due to dispute territories

Neighbours <- read_excel(paste(data_path,"Spatial/EEZ_Neighbour_List.xlsx",sep="")) %>% 
  clean_names()

# 
# Neighbours %>% 
#   filter(eez_name == "China") %>% 
#   pull(eez_neighbour) %>% 
#   unique()

##_----------------------- #


# Get the center poligon of each EEZ for map source/target
coords <- as.data.frame(st_centroid(World_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,longitude
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

# Prepare data from results
Test_Data <- results %>% 
  # get coords for sources
  left_join(coords,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(coords,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  mutate(
    per_mid = ifelse(is.na(per_mid),0,per_mid)
  ) %>% 
  drop_na() %>% 
  filter(
    # per_mid >= 20,
    variable == "mean_spp",
  )


# Convert to data to spatial
network_data_sf <- Test_Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  st_sf(geometry = .)%>%
  bind_cols(Test_Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  sf::st_sf(crs = 4326)

#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest() %>% 
  mutate_at(vars(X,Y), round,2)

# Plot it!

country <- c("Fiji","Solomon Isl.","Tuvalu")

ggplot() +
  geom_sf(
    # data = subset(world_map,name %in% country),
    data = world_map,
    size = 0.1, fill = "gray90", col = "gray90") +
  geom_sf(
    # data = subset(World_eez_sf, eez_name %in% country),
    data = World_eez_sf,
    size = 0.1, fill = "white", col = "gray70") +
  geom_point(data = Test_Data,
             # data = subset(Test_Data, source %in% country & target %in% source),
             aes(start_lon,
                 start_lat,
                 col = per_mid),
             size = 0.1,
             col = "black",
             # shape = 21,
             stroke = 1.5) +
  geom_path(data = paths,
            # data = subset(paths, source %in% country),
            aes(X, Y,
                group = interaction(line_id,subline_id),
                col = per_mid
            ),
            size = 0.3,
            arrow = arrow(length = unit(0.009, "npc")),
            show.legend = NA) +
  # geom_sf_text(data = subset(World_eez_sf, eez_name %in% country),
  #              aes(label =eez_name),
  #              size = 2) +
  # geom_text(data = subset(Test_Data, source %in% country),
  #              aes(start_lon,
  #                start_lat,
  #                label = paste(source,"to",target)
  #              ),
  #              size = 2) +
  # geom_text_repel(data = Test_Data,
  #   aes(start_lon,
# start_lat,
# label = paste(source,"to",target)
# )
# )+
ggtheme_map() +
  scale_colour_gradientn("Gain of Stock-Share Ratio (%)",
                         colours = wesanderson::wes_palette("Zissou1", 100, type = "continuous"),
                         limits = c(0,25),
                         breaks = seq(0,25,5)
  )

```