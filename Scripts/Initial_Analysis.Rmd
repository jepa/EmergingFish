---
title: Matching the Time of Emergence of Transboundary Fish Stocks to Lead Time for
  Policy Response Under Climate Change
author: "Juliano Palacios Abrantes"
date: "09/03/2020"
output:
  word_document: 
    keep_md: yes
  html_document: default
subtitle: Initital analysis
editor_options: 
  chunk_output_type: console
---


```{r setup, eval = T, echo = F, warning = F, message = F, results = 'hide'}

library(MyFunctions)

#### Project's Library
packages <- c(
  "dbemImport",
  "tidyverse",
  "here", # for dbem_import `here()`
  "data.table", #dbem_import `fread()`
  "readxl", # for reading excell files
  "janitor", # for clearing names
  "geosphere", # estimate distances between points `distm()`
  "ggrepel",
  "zoo", # for average mean
  "parallel", # for mclapply,
  "sf", # for mapping
  "st", # for mapping
  "rgdal", #Spatial analysis
  "tools", #Spatial analysis 
  "zeallot", # for Juanito's map
  "gmt", # for estimating distances between points
  "viridis"
)

my_lib(packages)

```


# Methods

See methods section of the paper (e.g. Manusript.Rmd)

## Creating Data

Here we re-arrange existing data for the analysis. We have three steps:

1- Set the SAU relations between index and EEZs and include lat long data for each index

2.- Deteremine the centroid of each EEZ and asigned an id to each neighbouring interaction (e.g. Chile and Peru or Canada West Coast and US West Coast) 

3.- Set Neigbouring IDs based on the interactions between neighbouring EEZs for all of those sharing transboundary species

```{r pre_data_creation, eval = F, echo = F}

## ---------------##
#### 1. SAU relations between INDEX and Country's EEZs
# Re-ran with new names data
## ---------------##

# EEZIDs_List <- my_path("G", extra_path = "Spatial/V_Lam", name="Updated_EEZList_17June2016.xlsx", read = TRUE) %>%
  # clean_names()

EEZ_CellID <- my_path("G", extra_path = "Spatial/V_Lam", name="EEZ_CellID.xlsx", read = TRUE) %>%
  clean_names()
colnames(EEZ_CellID) <- c("eezid","index")

# SAU name relatioal table (Fish For Visa)
sau_clean_names <- my_path("G", extra_path = "Spatial/SAU/", name="SAU_matching_names.csv", read = TRUE)

Lon_Lat_DBEM <- my_path("G", extra_path = "Spatial", name="Lon_Lat_DBEM.txt", read = TRUE, header = FALSE)
colnames(Lon_Lat_DBEM) <- c("index","lon","lat")


# Index_Code <- EEZIDs_List %>% 
#   left_join(EEZ_CellID) %>% 
#   rename(eez_name = name) %>% 
#   left_join(Lon_Lat_DBEM,
#             by = "index")


Index_Code <-  sau_clean_names %>% 
  select(eezid = sf_eezid) %>% 
  left_join(EEZ_CellID,
            by = "eezid") %>% 
  left_join(Lon_Lat_DBEM,
            by =  "index")

# Save Index data for future 
# write_csv(index_code,
          # paste(my_path("G",extra_path = "Spatial/DBEM"),"sau_index_code.csv",sep="")
          # )

## ---------------##
#### 2. entroids 
## ---------------##

# Load SAU shapefile name and paths

# The path
Path_SAU <- my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile")

# The File
File_Name <- "SAUEEZ_July2015.shp"

# Load it!
SAU_eez_sf <- st_read(dsn = Path_SAU,
                        layer =file_path_sans_ext(File_Name)
                      ) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1)

# Get the center poligon of each EEZ for map source/target with st_centroid
coords <- as.data.frame(st_centroid(SAU_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,
                             ifelse( eez_name == "Brazil",-36.937,longitude
                             )
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

# Double check coords
# Note that Australia and Ggreenland have points in the middle of the country because of the EEZ shape

coords_map <- ggplot() +
  geom_sf(data = SAU_eez_sf, aes(), fill = NA) +
  geom_point(data = eez_centroid,
             aes(
               x = longitude,
               y = latitude
             )
  )

ggsave("coords_map.png",
       plot = coords_map,
       width = 10,
       height = 8,
       units = "in"
       )
  

# Save dataframe so we don't need to run this ewvery time
# write_csv(coords,
#           "eez_centroids.csv")


## ---------------##
#### 3. Set Neigbouring IDs
## ---------------##

# Read transboundary species database from Palacios-Abrantes et al 2020 (FishForVisa)
Transboundary_spp <- my_path("D", extra_path = "Species/", name="Transboundary_spp.csv", read = TRUE)

# Get id of neighbouring pairs
Neighbours_spp <- Transboundary_spp %>% 
  group_by(eez_name,eez_neighbour) %>% 
  summarise(n=n()) %>% 
  ungroup() %>% 
  select(-n) %>% 
  rownames_to_column("neighbour_id")

# Split dataframes to merge neighbouring ids
df1 <- Neighbours_spp
df2 <- Neighbours_spp
colnames(df2) <- c("neighbour_id", "eez_neighbour", "eez_name")

# Merge neighbouring ids
df_full <- bind_rows(df1, df2) %>% 
  group_by(eez_neighbour,eez_name) %>% 
  summarise(neighbour_id = min(neighbour_id))

# Save dataframe so we don't need to run this every time
# write_csv(df_full, 
#           "Neighbours_eez_id.csv")
    
```

## Estimating Proportion Change

This part of the analysis estimates the Stock Share Ratio and its change under cliamte change under two time frames; early (2030) and mid (2050). Note that 2020 is the average of 2021 to 2040 and mid is the average of 2041 to 2060.


### Fun `EstPropChange`

```{r EstPropChange, eval = T, echo = F}

EstPropChange <- function(taxon_key,
                          year,
                          hist_y = 2005,
                          data_type = "Catch",
                          ensemble_list, # expects a list of ensembles to averrage by
                          path,
                          neighbours){
  
  
  # Loads species data for all ensembles
  Spp_Dist <- bind_rows(
    lapply(
      ensemble_list,
      read_dbem_ens,
      taxon_key = taxon_key,
      year = year,
      data_type = data_type,
      model = "GFDL",
      rcp = "85",
      # path = "/Volumes/DATA/DATA",
      my_path = F
    )
  )
  

  # Filter Species distribution to that of the neighbouring EEZs
  # ------------ #
  # Warning message:
  # Column `eez_name` joining factor and character vector, coercing into character vector 
# ------------ #
  
  suppressWarnings(
    Trans_EEZ <- Transboundary_spp %>% 
      filter(taxon_key %in% Spp_Dist$taxon_key) %>% 
      left_join(index_code,
                by = c("eez_name")
      )
    )
  
  # Get neighbouring id
  Neighbours_List <- Neighbours %>% 
    semi_join(Trans_EEZ,
              by = c("eez_name","eez_neighbour")
    )
  
  # Selecting only the transboundary nature of the species
  Trans_Spp <- Spp_Dist %>%
    filter(index %in% Trans_EEZ$index) %>% 
    left_join(index_code,
              by = "index") %>% 
    filter(eez_name %in% Neighbours_List$eez_name)
  
  # -------------------- #
  # Estimate area index
  # The number of species' cells present within each country's EEZ
  # -------------------- #
  
  #Determines the amount of grids present in each country
  Spp_Grid <- Trans_Spp %>% 
    group_by(taxon_key,
             eez_name,
             year,
             ensemble) %>% 
    summarise(n_spp_eez = length(unique(index))) %>% 
    left_join(Neighbours_List,
              by = "eez_name")
  
  # Split dataframes to merge latter
  Territory_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      taxon_key,
      Name=eez_name,
      n_spp_eez,
      year,
      ensemble
    )
  
  Neighbour_T <- Spp_Grid %>% 
    ungroup() %>% 
    select(
      taxon_key,
      n_spp_eez,
      Name=eez_neighbour,
      eez_name,
      year,
      ensemble
    )
  
  # Estimate Area index and % change
  Per_Ghange_D <- full_join(Territory_T,
                            Neighbour_T, 
                            by = c("Name","taxon_key","year","ensemble")
  ) %>%
    rowwise() %>%
    mutate(Spp_Total = sum(n_spp_eez.x,n_spp_eez.y,na.rm=T)) %>% # Total gridcelles per Neighbours
    distinct() %>% # Removes false duplicates from `full_join()`
    rename(eez_name = Name,
           eez_neighbour =eez_name,
           n_spp_Country = n_spp_eez.x,
           n_spp_Neighbour = n_spp_eez.y) %>% 
    mutate(area_index = n_spp_Country/Spp_Total) %>% 
    # Determine the three time frames for comparrison
    mutate(
      time_step = ifelse(year < hist_y,"historical",
                         ifelse(year >= 2021 & year <= 2040, "early",
                                ifelse(year >= 2041 & year <= 2060, "mid","NA")
                         )
      )
    ) %>%
    filter(time_step != "NA") %>% 
    # Time mean and sd
    ungroup() %>% 
    group_by(taxon_key,ensemble,eez_name,eez_neighbour,time_step) %>% 
    summarise_at(vars("area_index"),
                 c(temporal_mean=mean,
                   temporal_sd=sd)
    ) %>% 
    # ensemble mean and sd
    group_by(taxon_key,eez_name,eez_neighbour,time_step) %>%
    summarise(
      ensemble_mean = mean(temporal_mean, na.rm = T),
      ensemble_sd = sd(temporal_mean, na.rm = T),
      ensemble_n = n()
    )
  
  # --------------- #
  # End function
  # --------------- #
  
  if(nrow(Per_Ghange_D) > 0){
  
  # Save Result
  name <- paste("proportion_",taxon_key,".csv",sep="")
  path_name <- paste(my_path("R",extra_path = "Proportion_2005"),name,sep= "")
  
  write_csv(Per_Ghange_D,
            path_name)
  
  return(print(paste("analysis done",taxon_key)))
  # return(Per_Ghange_D)
  
  }else{
    print(paste("no result for",taxon_key))
  }
  
  # Or return a df
  # return(Per_Ghange_D)
}

# EstPropChange(taxon_key = 600004,
#               year = year_df$year,
#               hist_y = 2000,
#               data_type = "Catch",
#               ensemble_list = 102,
#               path = path,
#               neighbours = neighbours)
# 


```

### Proportion Control Panel

```{r Proportion_control_panel, eval = T, echo = F}

## ----------------- ##
# Data needed for estimating year of emergence
## ----------------- ##

# SAU relations between INDEX and Country's EEZs (see chunk 3)
index_code <- my_path("G", extra_path = "Spatial/SAU/", name="sau_index_code.csv", read = TRUE)

# Neighbour list and their respective id (see chunk 3)
Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE)

# Transboundary species and their sharing EEZs (see Palacios-Abrantes et al; FishForVisa)
Transboundary_spp <- my_path("D", extra_path = "Species/", name="Transboundary_spp.csv", read = TRUE) %>% 
  clean_names() %>% 
  select(-v1) 

## ----------------- ##
# Global variables
## ----------------- ##

# Year timeframe
year_df <- tibble(year =  c(seq(1951,2005,1), seq(2006,2099,1)),
                  time_period = c(rep("historic", 55), rep("future", 94))
                  )

# List of ensemble members
# ensemble_list <- seq(102,103,1) # for testing
ensemble_list <- seq(102,111,1)

#  List os species
spp_list <- unique(Transboundary_spp$taxon_key)

modeled_spp <- list.files(my_path("R", extra_path = "Proportion_n"))

modeled_spp <- gsub("proportion_","",modeled_spp)
modeled_spp <- gsub(".csv","",modeled_spp)

spp_list <- spp_list[!spp_list %in% modeled_spp]


```

### Proportion routine

```{r Proportion_routine, eval = T, echo = F}

####_______________________ ####
# Estimating proportion change
####_______________________ ####
gc()
t_start <- Sys.time()

mclapply(
  spp_list,
  EstPropChange,
  year = year_df$year,
  data_type = "Catch",
  ensemble_list = ensemble_list,
  path = DBEM_path,
  neighbours = Neighbours
)

t_end <- Sys.time()-t_start;t_end

# Hall 1000 ran it in 5.33 hours past
# Hall 1000 ran it in  hours (July 2020)

```

## Estimating emerging year

This rutine estimates the time (e.g. year) in which the changes in stock share ratio is more likely to happen based on historical variations (e.g. model noise) and future trends (e.g signal). This result uses teh average of the 10 ensemble members

### Fun `GetCentroids` 

This function estimates the distance between the centroid of each neighbouring EEZ and the distribution of the species along both EEZs. We define species centroid as the tile with the highest value of maimum catch potential from all of the species distribution in each year.

```{r GetCentroids, eval = T, echo = F}

GetCentroids <- function(taxon_key,
                         year, 
                         data_type = "Catch",
                         ensemble, 
                         path,
                         Neighbours,
                         eez_centroid,
                         p = 0.95 # percentile of data for central distribution
                         ){
  
  # ----------------- #
  # Get model data from spps for one ensemble
  #  ---------------- #
 if(ensemble == 102){
   print(taxon_key)
 }
  
  Spp_Dist <- read_dbem_ens(
    taxon_key = taxon_key,
    year = year,
    data_type = data_type,
    ensemble = ensemble,
    path = my_path("G","DBEM")
  )

  # ----------------- #
  # Extra step 
  # ----------------- #
  
  #### Creates a data to control computational time (lol!)
  #   if(file.exists(paste(my_path("R"),"spp_df.csv",sep="")) == FALSE){
  #   spp_df <- tibble() %>% 
  #     write_csv(.,
  #               paste(my_path("R"),"spp_df.csv",sep=""))
  # }
  # 
  # suppressMessages(
  #   spp_df <- my_path("R",name="spp_df.csv",read = TRUE)
  # )
  # spp_df <- tibble(taxon_key,
  #                  ensemble) %>% 
  #   bind_rows(spp_df) %>% 
  #   write_csv(.,
  #             paste(my_path("R"),"spp_df.csv",sep=""))

  # ----------------- #
  # Estimate distance between centroids
  # ----------------- #
  
  # Filter only the transboundary nature of the species 
  Trans_Spp <- Spp_Dist %>%
    left_join(index_code,
              by= "index") %>% 
    filter(!is.na(value)) %>% 
    semi_join(Transboundary_spp, # filter only transboundary cases
              by = c("taxon_key","eez_name")
    )
  
  # ----------------- #
  # Extra step 
  # ----------------- #
  # Controls for cases with no-data
  nr <- nrow(Trans_Spp)
  if(nr > 0){
    
    # Filter eez by those transboundary
    unique_eez <- unique(Trans_Spp$eez_name)
    
    Neighbours_combo <- Neighbours %>% 
      filter(eez_name %in% unique_eez,
             eez_neighbour %in% unique_eez)
    
    # Get the centroid of each country
    EEZ_centroid <- eez_centroid %>% 
      filter(eez_name %in% Trans_Spp$eez_name) %>% 
      mutate(taxon_key = taxon_key)
    
    # ----------------- #
    # Centroid function
    # ----------------- #
    
    # This function estimates the distance of each neighbouring EEZ
    # It uses Ids wich is a pre-determine identifier of neighbouring
    # EEZs. Fo example Peru and Chile have Id = 167, and viceversa
    
    CentroidsFx <- function(Ids){  
      
      # Filter data by Ids
      EEZ_ids <- Neighbours_combo %>% 
        filter(neighbour_id == Ids)
      
      Sub_Trans_Spp <- Trans_Spp %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      Sub_EEZ_centroid <- EEZ_centroid %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      # Function to get percentiles
      # https://www.tidyverse.org/blog/2020/03/dplyr-1-0-0-summarise/
      quibble <- function(x, q = p) {
        tibble(x = quantile(x, q), q = q)
      }

      # Get the percentile treshold per year, ensemble and neighbour id
      percentile <- Sub_Trans_Spp %>% 
        left_join(EEZ_ids, by = "eez_name") %>% 
        group_by(taxon_key,year,ensemble,neighbour_id) %>%  # for whole distribution
        do(quibble(.$value, p))
      
       Centroids <- Sub_Trans_Spp %>% 
         left_join(EEZ_ids, by = "eez_name") %>% 
         left_join(percentile,
                   by = c("taxon_key","year","ensemble","neighbour_id")
                   ) %>% 
         mutate(to_filter = ifelse(value < x,"out","keep")) %>% 
         filter(to_filter == "keep") %>% 
         group_by(taxon_key,year,ensemble,neighbour_id) %>%  # for whole distribution
         summarise_at(vars(lon,lat),mean) %>% 
         left_join(Sub_EEZ_centroid, by = "taxon_key") %>%
         # select(eez_name =eez_name.y, everything() ,-eez_name.x) %>% 
         # Estimate distances between spp centroid and EEZ centroid
         mutate(
           distance = geodist(longitude, # eez longitude
                              latitude,  # eez latitude
                              lon,  # species longitude
                              lat, # species latitude
                              units="km")
         ) %>% 
         select(taxon_key,eez_name,neighbour_id,ensemble,year,distance)
         
      return(Centroids)
      
    }
    # Determine the ids
    Ids <- unique(Neighbours_combo$neighbour_id)
    
    # Run sub-function
    Centroids_Data <- bind_rows(
      lapply(Ids,CentroidsFx)
    )
    
  }else{
    # In case there's no data
    Centroids_Data <- tibble()
    
  }
  
  return(Centroids_Data)
  
}

# Test function

# GetCentroids(taxon_key = 600076,
#              year = year_df$year[1:5],
#              data_type = "Catch",
#              ensemble = 102,
#              Neighbours = Neighbours,
#              eez_centroid = eez_centroid
#              )

# head(Test_centroids)
# unique(Test_centroids$ensemble)
# unique(Test_centroids$neigh)
# 
# ggplot(Test_centroids) +
#   geom_line(
#     aes(
#       x = year,
#       y = distance,
#       color = eez_name
#     )
#   )


```

### Fun `TransIndex`

This functions takes on `GetCentroids` function and estimates the TransIndex (*TI*) for each pair of neighbouring countries. Presents a 10 years average of the results

$$TI =(\frac{D_{A,y}}{sd(D_{A,h})} - \frac{D_{B,y}}{sd(D_{B,h)}})^2$$

The year of emergece is defined as the first year where the trend is larger than the 95% CI of the historic variation.

Note: If no historic data available then emerging year is the first year of data in an EEZ

```{r TransIndex, eval = T, echo = T}

TransIndex <- function(Centroids, # Expecting the results from the GetCentroids function
                       Id, # A numeric value representing a neighbouring interaction (ONE!)
                       Hist_y = 2005,
                       Plot = F){ # The LAST year of Historical data
  
  
  # Filter data by neighbouring ID
  Centroids_id <- Centroids %>% 
    filter(neighbour_id %in% Id)
  
  EEZ_ids <- Neighbours %>% 
    filter(neighbour_id %in% Id)

  # Historical mean and sd of distance
  historical <- Centroids_id %>%
    filter(year <= Hist_y) %>% 
    ungroup() %>%
    group_by(taxon_key,ensemble,eez_name,neighbour_id) %>%
    summarise_at(vars("distance"),
                 c(hd_temp_mean=mean,
                   hd_temp_sd=sd,
                   n_yrs =~n())
                 )
  
    # Future results
  future <- Centroids_id %>% 
    filter(year > Hist_y)
  
   # Get unique eezs
  Unique_EEZs <- unique(EEZ_ids$eez_name)
  
  # Transboundary Index
  Trans_index <- Centroids_id %>% 
    left_join(historical,
              by = c("taxon_key","eez_name","ensemble","neighbour_id")
    ) %>%
    # Re arrenging table for mutate
    gather("variable","value",distance:hd_temp_sd) %>%
    ungroup() %>% 
    mutate(value = ifelse(is.na(value),0,value)) %>% 
    mutate(
      names = ifelse(eez_name ==Unique_EEZs[1],paste("Country_A",variable,sep="_"),paste("Country_B",variable,sep="_")
    )
    ) %>%
    select(-eez_name,-variable) %>%
    spread(names,value) %>% 
    # mutate index
    mutate(
      trans_index = (Country_A_distance/Country_A_hd_temp_sd - Country_B_distance/Country_B_hd_temp_sd)^2
    # )
    ) %>% 
    # Ten years average of results
    group_by(taxon_key,ensemble,neighbour_id) %>% 
    mutate(RMean = rollmean(x = trans_index, 
                            10, 
                            align = "right", 
                            fill = trans_index)
    ) %>% 
    # filter(year > 1960) %>%
    select(taxon_key,neighbour_id,year,ensemble,trans_index,RMean)
  
  # Average of 10 years mean of ensemble members results
  mean_sd_index <- Trans_index %>% 
    group_by(taxon_key,year,neighbour_id) %>% 
    summarise_at(vars("RMean"),
                 c(trend=mean,
                   ensemble_sd=sd,
                   n_ens = ~n()
    )
    )
    
    # Valid ensembles
  # Only perform analysis on ensembles containing all years between 1951 and 2040
    n_years <- mean_sd_index %>% 
      group_by(n_ens) %>% 
      summarise(
        n_year = n()
      ) %>% 
      filter(
        n_year == 149
      )
    
    mean_sd_index <- mean_sd_index %>% 
      filter(n_ens %in% n_years$n_ens)
  
  # Estimate noice from ensemble members
  historic_sd <- Trans_index %>% 
    filter(year <= Hist_y) %>% 
    group_by(taxon_key,neighbour_id,ensemble) %>% #Average historic data per ensemble
    summarise_at(vars("trans_index"),
                 c(trend= mean)
                 ) %>% 
    group_by(taxon_key,neighbour_id) %>% #Capture ensemble variation
    summarise_at(vars("trend"),
                 c(hist_mean=mean,
                   noise=sd,
                   n_ens = ~n())
                 )
  
  
  # For testing
  if(Plot == T & length(historic_sd$hist_mean) > 1){
  # Plot the result, bruh
  
  # Step to determine if data exists
  Plot_Test <- nrow(subset(mean_sd_index, trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise)))>0
  
  ggplot() +
    geom_line(data = mean_sd_index,
              aes(
                x = year,
                y = trend
              )
    ) +
    geom_ribbon(data = mean_sd_index,
                aes(x=year,
                    ymin=historic_sd$hist_mean-historic_sd$noise,
                    ymax=historic_sd$hist_mean+historic_sd$noise),
                alpha = 0.5,
                fill = "grey50"
    ) +
    geom_ribbon(data = mean_sd_index,
                aes(x=year,
                    ymin=historic_sd$hist_mean-(historic_sd$noise*2),
                    ymax=historic_sd$hist_mean+(historic_sd$noise)*2)
                ,
                alpha = 0.5,
                fill = "grey30"
    ) +
    geom_line(data = mean_sd_index,
              aes(
                x = year,
                y = historic_sd$hist_mean
              ),
              colour = "grey50"
    ) +
    # Conditional, will only plot circles if the data exists
    {if(Plot_Test)geom_point(data = subset(mean_sd_index, trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise)),
               aes(
                 x = year,
                 y = trend,
                 colour = "red",
               ),
               shape = 1,
               size = 3
    )
      } +
    geom_vline(xintercept = Hist_y,colour="blue",alpha = 0.5) +
    scale_x_continuous(breaks = seq(1950,2100,5)) +
    theme_classic() +
  
    tk <- unique(mean_sd_index$taxon_key)
  
    ggsave(paste(tk,Id,"plot_example.jpg",sep="_"),
       plot = last_plot(),
       width = 10,
       height = 8,
       units = "in",
       path = my_path("R")
       )
  
  }
  
  # If no historic data then emergin year is the first year of data
  if(nrow(historic_sd) == 0){
    
    Final_Result <- mean_sd_index %>%
      group_by(taxon_key,neighbour_id,n_ens) %>%
      summarise(emerging_yr= min(year)) %>%
      left_join(EEZ_ids,
                by = "neighbour_id") %>%
      ungroup() %>%
      select(taxon_key,eez_name,eez_neighbour,n_ens,emerging_yr) %>% 
      mutate(Tresh= NA)
  
  return(Final_Result)
    
  }else{
  
  Final_Result <- mean_sd_index %>%
    filter(year > Hist_y) %>% 
    mutate(
           Tresh_one = ifelse(trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise),"One",NA),
           Tresh_two = ifelse(trend > (historic_sd$hist_mean+(2*historic_sd$noise)) | trend < (historic_sd$hist_mean-(2*historic_sd$noise)),"Two",NA)
    ) %>%
    gather("Tresh","YesNo",Tresh_one,Tresh_two) %>% 
    filter(!is.na(YesNo)) %>% 
    group_by(taxon_key,neighbour_id,n_ens,Tresh) %>%
    summarise(emerging_yr= min(year)) %>%
    left_join(EEZ_ids,
              by = "neighbour_id") %>%
    ungroup() %>%
    select(taxon_key,eez_name,eez_neighbour,n_ens,emerging_yr,Tresh)
  
  return(Final_Result)
  }
}
  



```

### Fun `GetTransIndex`

This is the last function of the emerging year evaluation. It was made so we could run the analysis per each species. The function function simply runs the functions `GetCentroids` by ensabmble member and then `TransIndex` by pairing EEZ. Thus, with this function we run the whole set by species * paired EEZ * ten ensemble members. 

```{r GetTransIndex, eval = T, echo = T}
  
GetTransIndex <- function(taxon_key,
                          year,
                          Hist_y,
                          data_type = "Catch",
                          path,
                          ensemble_list,
                          Neighbours,
                          eez_centroid,
                          Plot = F){
  t_start <- Sys.time()
  print("Starting Step One")
    # First step
    # Call Get centroids fucntion for centroids data per ensemble
    Step_one <- bind_rows(
      lapply(ensemble_list,
             GetCentroids,
             taxon_key = taxon_key,
             year = year_df$year,
             data_type = data_type,
             Neighbours = Neighbours,
             eez_centroid = eez_centroid
             )
    )
    
    # Set the different neighbouring pairs
    Ids <- unique(Step_one$neighbour_id)
    
    print("Starting Step Two")
    
    # Second Step
    # Get the transboudary index based on all centroids
    Step_two <- bind_rows(
      lapply(Ids,
             TransIndex,
             Hist_y = Hist_y,
             Centroid = Step_one)
    )
    
    name <- paste(my_path("R",extra_path = "/Emergence_2005/"),taxon_key,"_emergence.txt",sep="")
    
    write_csv(Step_two,
              name)
    
    time_dif <- Sys.time()-t_start
     
    message <- paste("Analysis done for", taxon_key, "in",time_dif, "minutes")
    return(message)
  }
  
  
  # GetTransIndex(
  #   taxon_key = 600076,
  #   ensemble_list = ensemble_list,
  #   year = year_df$year,
  #   Hist_y = 2000,
  #   data_type = "Catch",
  #   Neighbours = Neighbours,
  #   eez_centroid = eez_centroid
  # )


  # spp_list <- c(600004, 600245)
  # 
  #  test <- bind_rows(
  #   lapply(spp_list,
  #          GetTransIndex,
  #          year = year,
  #          data_type = "Catch",
  #          path = path,
  #          Neighbours = Neighbours,
  #          eez_centroid = eez_centroid,
  #          ensemble_list = ensemble_list
  #   )
  # )
  # 
    
```

### Emerging Control Panel

```{r Emerging_control_panel, eval = T, echo = T}

## ----------------- ##
# Data needed for estimating year of emergence
# Note: Use repo = F when running on the Beast or Hall1000
## ----------------- ##

# SAU relations between INDEX and Country's EEZs (see chunk 3)
index_code <- my_path("G", extra_path = "Spatial/SAU/", name="SAU_matching_names.csv", read = TRUE)

# EEZ list and their centroid of distribution (see chunk 3)
eez_centroid <- my_path("D", extra_path = "Spatial/", name="eez_centroids.csv", read = TRUE)

# Neighbour list and their respective id (see chunk 3)
Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE)

# Transboundary species and their sharing EEZs (see Palacios-Abrantes et al; FishForVisa)
Transboundary_spp <- my_path("D", extra_path = "Species/", name="Transboundary_spp.csv", read = TRUE) %>% 
  clean_names()

## ----------------- ##
# Global variables
## ----------------- ##

# Year timeframe
year_df <- tibble(year =  seq(1951,2099,1))

# Last year of "historic" data
Historic_year = 2005

# Data path
# path = DBEM_path

# List of ensemble members
# ensemble_list <- seq(102,103,1) # for testing
ensemble_list <- seq(102,111,1)

#  List os species
spp_list <- unique(Transboundary_spp$taxon_key)

# Already modeled species
spp_done <- list.files(my_path("R", extra_path = "Emergence"))

spp_done <- gsub("\\_.*","",spp_done)

spp_reman <- spp_list[!spp_list %in% spp_done]

rand_plot <- sample(spp_reman,5)


```

### Emerging Routine

```{r Emerging_routine, eval = F, echo = F}

####_______________________ ####
# Estimating year of eergence
####_______________________ ####
n_cores <- 24
t_start <- Sys.time()

gc()

    Emerging_result <- bind_rows(
      mclapply(spp_list,
               GetTransIndex,
               year = year_df$year,
               Hist_y = Historic_year,
               data_type = "Abd",
               ensemble_list = ensemble_list,
               Neighbours = Neighbours,
               eez_centroid = eez_centroid,
               Plot = F
      )
    )

```


```{r Emerging_routine_DoPar, eval = F, echo = F}

library(doParallel)
library(doSNOW)

cl <- makeCluster(12)
registerDoSNOW(cl)


# To show processing times
repetitions <- length(spp_reman)
pb <- txtProgressBar(max = repetitions, style = 3)

progress <- function(n) setTxtProgressBar(pb, n)
opts <- list(progress = progress)


foreach(i=1:repetitions,
        .combine = rbind,
        .packages = c("MyFunctions",packages),
        .options.snow = opts,
        .verbose = T) %dopar% 
  GetTransIndex(
    taxon_key =spp_reman[i],
    ensemble_list = ensemble_list,
    year = year_df$year,
    Hist_y = 2000,
    data_type = "Catch",
    Neighbours = Neighbours,
    eez_centroid = eez_centroid
  )

close(pb)
stopCluster(cl)

```

# Results

## Percentage Change

This results only shows the average percentage change in proportion of all speecies within an EEZ without relationship with neighbours

### Functions and Data needed

#### Fun `SummaryProp`

This function estimates the total change in MCP proportion of each species for each EEZ. It looses the connection with neighbours as you only know for x species houw much is the proportion changing.

```{r fun_SummaryProp, eval = F, echo =F}

SummaryProp <- function(taxon_key,links="NA"){
  
  # Reads taxon data
  proportion_data <- fread(paste(my_path("R",extra_path = "Proportion_2005/"),"proportion_",taxon_key,".csv", sep=""))
  
  if(links == "y"){
    # summarizes by country and neighbour
    country_summary <- proportion_data %>% 
      group_by(taxon_key,eez_name,eez_neighbour,time_step) %>% 
      summarise(
        mean_spp = mean(ensemble_mean, na.rm = T) # average spp change from all countries sharing
      ) %>% 
      filter(!is.na(mean_spp))
    
  }else{
    # summarizes by country
    country_summary <- proportion_data %>% 
      group_by(taxon_key,eez_name,time_step) %>% 
      summarise(
        mean_spp = mean(ensemble_mean,na.rm=T) # average spp change from all countries sharing
      ) %>% 
      filter(!is.na(mean_spp))
    }
  
  return(country_summary)
}

```


#### Fun `EEZProp`

The next step is to summarize all species per eez so our results shows average change of all species within an EEZ towards a neighbour

```{r fun_EEZProp, eval = F, echo = F}

EEZProp <- function(taxon_list,links="NA"){

 spp <- bind_rows(
   lapply(taxon_list,SummaryProp,links)
   )
 
 if(links == "y"){
   
   eez_summary <- spp %>% 
     group_by(eez_name,eez_neighbour,time_step) %>% 
     summarise(
       n_spp = n(),
       min_eez = min(mean_spp, na.rm=T),
       max_eez = max(mean_spp, na.rm=T),
       sd_eez = sd(mean_spp, na.rm=T), # for some weird reason it wont work if the order is fliped
       mean_eez = mean(mean_spp,na.rm=T)
     ) %>% 
     select(eez_name:max_eez,mean_eez,sd_eez)
   
 }else{
 
   eez_summary <- spp %>% 
   group_by(eez_name,time_step) %>% 
   summarise(
       n_spp = n(),
       min_eez = min(mean_spp, na.rm=T),
       max_eez = max(mean_spp, na.rm=T),
       sd_eez = sd(mean_spp, na.rm=T), # for some weird reason it wont work if the order is fliped
       mean_eez = mean(mean_spp,na.rm=T)
     ) %>% 
     select(eez_name:max_eez,mean_eez,sd_eez)
 
 
 }
 
 return(eez_summary)

}

```

#### Fun `PropChange`

Finally, we estimate the average proportion change of all species within each eez

```{r fun_PropChange, eval = F, echo =F}

PropChange <- function(taxon_list,links="NA"){

 eez <- EEZProp(taxon_list,links)
 
 proportion_change <- eez %>% 
   gather("variable","value",n_spp:sd_eez) %>% 
   spread(time_step,value) %>% 
   mutate_at(vars(
     "per_early" = early,
     "per_mid" = mid
     ),
            funs(round((((.-historical)/historical))*100,2))
   )
 
 return(proportion_change)

}

```

### Run Results Analysis

####  Prooportion Analysis

```{r PropChange, eval = F, echo =F}

# Get taxon list
Taxon_List <- list.files(paste(my_path("R"),"Proportion_2005",sep=""))

# clean names for function
Taxon_List <- gsub(".*_","",Taxon_List) 
Taxon_List <- gsub("\\..*","",Taxon_List)
  
# Run results
results <- PropChange(Taxon_List, links="y") %>% 
  filter(!is.na(eez_neighbour)) %>% 
  mutate(per_mid_plot =ifelse(per_mid >= 50, 50,
                           ifelse(per_mid <= -50,-50,per_mid)
                           ),
         per_early_plot =ifelse(per_early >= 50, 50,
                           ifelse(per_early <= -50,-50,per_early)
                           )
         )

# For dat availabillity
 # write_csv(results,
          # "proportion_change_2005.csv")

# View(results)

### Load Data

# Load SAU shapefile name and paths

# The path
path_world <- my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile")

# The File
fnam_world <- "SAUEEZ_July2015.shp"

# Load it!
World_eez_sf <- st_read(dsn = path_world,
                    layer =file_path_sans_ext(fnam_world)) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1)

# Call world map from natural earth
World_map <- rnaturalearth::ne_countries(scale = 'small', returnclass = c("sf"))

eez_centroid <- my_path("D",extra_path = "Spatial",name = "eez_centroids.csv",read = T)

```

##### Fig.Percentage Change Map

```{r fig_map_per, eval = F, echo =F}

World_sf %>% 
  left_join(results,
            by = "eez_name") %>% 
  filter(variable %in% c("mean_spp")#,
         # eez_name %in% c("Peru","Chile","Ecuador","Argentina")
         ) %>% 
  ggplot() +
  geom_sf(
    aes(
      fill = per_mid
    )
  ) + 
  geom_sf(data=country10_sf) +
  scale_fill_gradient2("Average Change in\nStock-Share Ratio (%)\nBy Mid Century") +
  ggtheme_map() +
  ggsave("per_mid.png",
         width = 10,
         height = 6,
         units = "in"
  )

```

##### Fig. Netowrk

```{r fig_map_Juan, eval = F, echo =F}
# Figure made thanks to Juanito!
# http://jsmayorga.com/post/mapping-the-global-network-of-transnational-fisheries/

# Prepare data from results
Data <- results %>% 
  # get coords for sources
  left_join(eez_centroid,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(eez_centroid,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  mutate(
    per_early = ifelse(is.na(per_early_plot),0,per_early_plot),
    per_mid = ifelse(is.na(per_mid_plot),0,per_mid_plot)
  ) %>% 
  drop_na() %>%
  filter(
    variable == "mean_eez"#,
    # source %in% c("Brazil","Argentina","Chile","Peru","Uruguay")
  )

# Convert to data to spatial
network_data_sf <- Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  st_sf(geometry = .)%>%
  bind_cols(Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  sf::st_sf(crs = 4326)

#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest() %>% 
  mutate_at(vars(X,Y), round,2) %>% 
  gather("time_step","per_chng",per_mid_plot:per_early_plot)
  
# Plot it!

Data <- Data %>% 
  gather("time_step","per_chng",per_mid_plot:per_early_plot)


gc()# clean ram

# time <- "per_mid_plot"
time <- "per_early_plot"

x <- ggplot() +
  geom_sf(data = subset(World_map, sovereignt != "Antarctica"), size = 0.1, fill = "gray90", col = "gray90") +
  geom_sf(data = World_eez_sf, size = 0.1, fill = "white", col = "gray70") +
  geom_point(data = subset(Data, time_step == time & per_chng < 0),
             aes(start_lon,
                 start_lat,
                 col = per_chng),
             size = 0.05,
             col = "gray30",
             shape = 20,
             stroke = 1.5) +
  geom_path(data = subset(paths, time_step == time & per_chng > 0),
            aes(X, Y,
                group = interaction(line_id,subline_id),
                col = per_chng
            ),
            size = 0.3,
            arrow = arrow(length = unit(0.009, "npc"),
                          ends = "first"),
            show.legend = NA) +
  my_ggtheme_m() +
  scale_colour_viridis(
    name="Average Gain of\nStock-Share Ratio (%)",
    limits = c(0,max(Data$per_chng)),
    breaks = seq(0,max(Data$per_chng),5),
    # option="magma",
    direction = -1
  ) +
  ggsave("./Figures/figure_connections_early_n50.png",
         width = 10,
         height = 6,
         units = "in"
  )

```

##### Histogram of change

```{r hist_change}

 results %>% 
  gather("time_step","change",per_early,per_mid) %>% 
  filter(variable == "mean_eez" & 
           !is.na(change)
         ) %>%
ggplot() +
  geom_density(
               aes(
                 x = ifelse(change >= 100,100,change),
                 # x = change,
                 fill = ifelse(time_step == "per_early","q",time_step)
                 # fill = time_step,
                 
               ),
               # stat = "count",
               # alpha= 0.8,
               size=0.1,
               # position = "stack"
  ) +
  scale_y_continuous("Density",
                     # breaks = seq(0,90,10),
                     # limits = c(0,100)
  ) +
  scale_x_continuous("Percentage Change",
                     breaks = seq(-75,500,25)
  ) +
  my_ggtheme_p() +
  theme(legend.position = "right") +
  scale_fill_viridis(discrete = T, 
                     option = "plasma",
                     alpha = 0.5,
                     name = "Time Step", labels = c("Middle", "Early")
                     ) +
  coord_flip() +
  ggsave("./Figures/hist_change.png",
         width = 6,
         height = 6,
         units = "in"
  )

```

####  Year of Eergence Analysis

```{r Emergence-analysis, eval = F, echo =F}

# Get taxon list
Taxon_List <- list.files(my_path("R",extra_path = "Emergence_2005"))

# clean names for function
Taxon_List <- gsub("_.*","",Taxon_List) 

# Neighbour list and their respective id (see chunk 3)
Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE)

Paths <- paste(my_path("R",extra_path = "Emergence_2005"),Taxon_List,"_emergence.txt",sep="")

# Load all sp in one table
Eme_Res <- bind_rows(lapply(Paths, fread)) %>% 
  filter(
    n_ens == 10
  ) %>% 
  left_join(Neighbours,
            by = c("eez_name","eez_neighbour")
            )
# warnings() for empty data species

# View(Eme_Res)

### Load Data

# Load SAU shapefile name and paths

# The path
path_world <- my_path("G", extra_path = "Spatial/SAU/SAU_Shapefile")

# The File
fnam_world <- "SAUEEZ_July2015.shp"

# Load it!
World_eez_sf <- st_read(dsn = path_world,
                    layer =file_path_sans_ext(fnam_world)) %>% 
  rename(eez_name = Name) %>% 
  st_transform(crs = 4326) %>% # 4326
  # st_transform(crs = "+proj=eck4") %>% 
  st_simplify(preserveTopology = TRUE, dTolerance = 0.1)

# Call world map from natural earth
World_map <- rnaturalearth::ne_countries(scale = 'small', returnclass = c("sf"))

eez_centroid <- read_csv(paste(data_path,"Spatial/eez_centroids.csv", sep = ""))


```

##### Histogram of Data

```{r histo,  eval = T, echo = T}

# First time a Species becomes emergent
Eme_Res %>% 
  filter(
    n_ens == 10#,
    # Tresh == "Tresh_one"
  ) %>% 
  group_by(Tresh,taxon_key,emerging_yr) %>% 
  summarise(
    n_trans = length(unique(eez_name))
  ) %>% 
  group_by(Tresh,taxon_key) %>% 
  summarise(
    ntrans = min(emerging_yr)
  ) %>% 
  group_by(Tresh,ntrans) %>% 
  summarise(
    n_taxa = length(unique(taxon_key))
  ) %>% 
  arrange(-n_taxa) %>% 
  # View()
  # group_by(Tresh) %>% 
  # summarise(sum(n_taxa))
  ggplot() +
  geom_line(
    aes(
      x = ntrans,
      y = n_taxa,
      color = Tresh
    )
  )


# EEZ, first time an EEZ has a emergent stock
Eme_Res %>% 
  filter(
    n_ens == 10#,
    # Tresh == "Tresh_one"
  ) %>% 
  group_by(Tresh,eez_name,emerging_yr) %>% 
  summarise(
    n_trans = length(unique(taxon_key))
  ) %>% 
  group_by(Tresh,eez_name) %>% 
  summarise(
    ntrans = min(emerging_yr)
  ) %>% 
  group_by(Tresh,ntrans) %>% 
  summarise(
    n_taxa = length(unique(eez_name))
  ) %>% 
  arrange(-n_taxa) %>% 
  View()
  # group_by(Tresh) %>%
  # summarise(sum(n_taxa))
  # ggplot() +
  # geom_line(
  #   aes(
  #     x = ntrans,
  #     y = n_taxa,
  #     color = Tresh
  #   )
  # )
  


# Numer of EEZs where stocks will emerge
stock_d_hist <- Eme_Res %>% 
  distinct(taxon_key,neighbour_id,Tresh, .keep_all = TRUE) %>%
  group_by(emerging_yr,taxon_key,Tresh) %>%
  summarise(n_tax = length(unique(eez_name))) %>%
  # summarise(n()) %>% 
  mutate(
    level = "EEZs per Spp"
  )  %>% 
  ungroup() %>% 
  select(-taxon_key)


# Per EEZs
eez_d_hist <- Eme_Res %>% 
  distinct(taxon_key,neighbour_id,Tresh, .keep_all = TRUE) %>%
  group_by(emerging_yr,eez_name,Tresh,neighbour_id) %>%  
  # summarise(n_tax = length(unique(taxon_key))) %>% 
  summarise(n()) %>% 
  mutate(
    level = "Spp per EEZ"
  ) %>% 
  ungroup() %>% 
  select(-eez_name)

stock_d_hist %>% 
  bind_rows(eez_d_hist) %>% 
  filter(Tresh != "NA") %>% 
  ggplot() +
  geom_density(
    aes(
      x = emerging_yr,
      fill = level
    ),
    stat = "count",
    alpha= 0.8,
    size=0.5,
  ) +
  scale_y_continuous("Frequency",
                     # breaks = seq(0,300,50),
                     # limits = c(0,300)
  ) +
  scale_x_continuous("Year of emergence",
                     # breaks = seq(2006,2100,25),
                     # limits = c(2000,2100)
  ) +
  my_ggtheme_p() +
  scale_fill_viridis(discrete = T) +
  facet_wrap(~Tresh) +
  ggsave("./Figures/hist_freq.png",
         width = 6,
         height = 6,
         units = "in"
  )

```

##### Accumulative plots

```{r Time_lapse_plot,  eval = T, echo = T}

# Per Stock
stock_d <-  Eme_Res %>% 
  left_join(Neighbours) %>% 
    # distinct(taxon_key,neighbour_id, .keep_all = TRUE) %>% 
    group_by(taxon_key,Tresh) %>% 
    summarise(
      taxon_emer = min(emerging_yr)
    ) %>% 
    group_by(taxon_emer,Tresh) %>% 
  summarise(
    n_tax = n()
  ) %>% 
  group_by(Tresh) %>% 
  mutate(
    com_sum = cumsum(n_tax),
    level = "Stock"
  )

  #  EEZ data
eez_d <-  Eme_Res %>% 
  left_join(Neighbours) %>% 
  filter(n_ens == 10) %>% 
    # distinct(eez_name,neighbour_id, .keep_all = TRUE) %>% 
    group_by(eez_name,Tresh) %>% 
    summarise(
      taxon_emer = min(emerging_yr)
    ) %>% 
    group_by(taxon_emer,Tresh) %>% 
  summarise(
    n_tax = n()
  ) %>% 
  group_by(Tresh) %>% 
  mutate(
    com_sum = cumsum(n_tax),
    level = "EEZ"
  )
  
# Plot Data
plot_data <- stock_d %>% 
  bind_rows(eez_d) %>% 
  filter(Tresh != "NA") %>% 
  mutate(
    total = ifelse(level == "Stock",length(unique(Eme_Res$taxon_key)),length(unique(Eme_Res$eez_name))),
    per = com_sum/total*100
  ) ;plot_data

  # filter(emerging_yr >= 2020) %>% 
  ggplot() +
    geom_area(data = subset(plot_data, level == "Stock"),
              aes(
                x = as.numeric(taxon_emer),
                y = com_sum,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    )  +
    geom_area(data = subset(plot_data, level == "EEZ"),
              aes(
                x = taxon_emer,
                y = com_sum,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    ) +
    facet_wrap(~Tresh) + 
    # Comment out for option A (Change plot name!!)
  #   geom_hline(yintercept = length(unique(Eme_Res$eez_name)), color = "grey",linetype = "dashed") +
  # geom_text(aes(label="Total number of EEZs", x = 2010, y = length(unique(Eme_Res$eez_name))+10), color = "grey70",size =3) +
  #   geom_hline(yintercept = length(unique(Eme_Res$taxon_key)), color = "grey",linetype = "dashed") +
  # geom_text(aes(label="Total number of Taxa", x = 2010, y = length(unique(Eme_Res$taxon_key))+10), color = "grey70",size =3) +
    scale_y_continuous("Cumulatuve Curve",
                       breaks = seq(0,600,50),
                       limits = c(0,600)
    ) +
    scale_x_continuous("Year of emergence",
                       breaks = seq(2005,2100,10),
                       limits = c(2005,2100)
    ) +
    my_ggtheme_p() +
    scale_fill_viridis(discrete = T) +
  ggsave("./Figures/figure_accumulative_curve_ab.png",
         width = 6,
         height = 6,
         units = "in"
  )
  
  
  ### Percentage accumulation
  
  # filter(emerging_yr >= 2020) %>% 
  ggplot() +
    geom_area(data = subset(plot_data, level == "Stock"),
              aes(
                x = as.numeric(taxon_emer),
                y = per,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    )  +
    geom_area(data = subset(plot_data, level == "EEZ"),
              aes(
                x = taxon_emer,
                y = per,
                fill = level
              ),
              alpha= 0.8,
              size=0.5,
              colour="black"
    ) +
    scale_y_continuous("Cumulatuve Curve",
                       breaks = seq(0,100,25),
                       limits = c(0,100)
    ) +
    scale_x_continuous("Year of emergence",
                       breaks = seq(2005,2100,10),
                       limits = c(2005,2100)
    ) +
    my_ggtheme_p() +
    scale_fill_viridis(discrete = T) +
    facet_wrap(~Tresh) + 
  ggsave("./Figures/figure_accumulative_curve_per.png",
         width = 6,
         height = 6,
         units = "in"
  )
  
```

##### Scatter plots

```{r Scatter_plot,  eval = T, echo = T}

 data_stock <- Eme_Res %>% 
  filter(
    n_ens == 10,
    emerging_yr >= 2020
  ) %>% 
  group_by(emerging_yr,eez_name) %>% 
  summarise(
    tax_n = length(unique(taxon_key))
    ) %>% 
  group_by(emerging_yr) %>% 
  summarise(emerging_tax = sum(tax_n))

data_eez <- Eme_Res %>% 
  filter(
    n_ens == 10,
    emerging_yr >= 2020
  ) %>% 
  group_by(emerging_yr,taxon_key) %>% 
  summarise(
    eez_n = length(unique(eez_name))
    ) %>% 
    group_by(emerging_yr) %>% 
  summarise(emerging_eez = sum(eez_n))


data_stock %>% 
  left_join(data_eez,
            by = "emerging_yr") %>% 
  ggplot() +
  geom_point(
    aes(
      x = emerging_eez,
      y = emerging_tax,
      fill = emerging_yr,
      colour = emerging_yr
    )
  )
  
```


##### Temperature gradient

##### Fun `GetEnvData`

```{r get_env_data, eval = T, echo = T}

getEnvVar=function(yr,ModelRCP,RCP,Variable){
  
  if(ModelRCP == "IPSL"){
    ModelRCP = "IPSL-CM5A-MR"
    Filepath <- paste("/Volumes/DATA/DATA/Environmental data/Model Climate data/CMIP5/txt CMIP5/Reformatted",ModelRCP,RCP,"",sep="/")
  }
  
  
  if(ModelRCP == "MPI"){
    ModelRCP = "MPI-ESM-MR"
    Filepath <- paste("/Volumes/DATA/DATA/Environmental data/Model Climate data/CMIP5/txt CMIP5/Reformatted",ModelRCP,RCP,"",sep="/")
  }
  
  if(ModelRCP == "GFDL"){
    
    if(RCP == "rcp26"){
      ModelRCP <- "GFDL26"
    }else{
      ModelRCP <- "GFDL85"
    }
    Filepath <- paste("Z:/JULIANO_NEYMAR/PristineSeasData/Climate",ModelRCP,"",sep="/")
  }
  
  
  if(Variable == "Ice"){
    
    Bottom <- paste("IceExt_",yr,".txt",sep="")
    
  }
  
  if(Variable == "Temperature"){
    
    Bottom = paste("SST_",yr,".txt",sep="")
    
  }
  
  if(Variable == "Salinity"){
    # Bottom
    Bottom = paste("Salinity_btm_",yr,".txt",sep="")
    
  }
  
  Read_me <- paste(Filepath,Bottom,sep="")[1]
  Bottom_Data <- read.csv(Read_me,header=F)
  
  # Retrun
  
  getTemp <- Bottom_Data 
}

Years <-seq(1951,2100,1)

for(y in 1:length(Years)){
        Data <- getEnvVar(yr = Years[y],
                          Model = "GFDL",
                          Variable = "Temperature",
                          RCP = "rcp85"
        )
        
        if(y == 1){
          
          F_BData <- Data[1]
          colnames(F_BData) <- Years[1]
      
        }else{
          
          F_BData <- cbind(F_BData,Data[1])
          colnames(F_BData)[y] <- Years[y]
        }
}


F_BData <- F_BData %>% 
          rowid_to_column("index") %>% 
  gather("year","temp",-index) %>% 
   mutate(temp = ifelse(temp == -9999,NA,temp)) %>% 
  group_by(year) %>% 
  summarise(
    mean_temp = mean(temp,na.rm=T)
  ) %>% 
  write_csv(.,
            "SST_data.csv")

```


```{r temp_plot, eval = T, echo = T}

### NEED TO RUN TIME LAPSE CHUNK FIRST TO GET ACCUMULATIVE DATA

# Get sst_data
sst_data <- my_path("D",T,"Climate","SST_data.csv",read = T)

sst_hist <- sst_data %>% 
  filter(year < 2000) %>% 
  group_by() %>% 
  summarise(hist_sst =mean(mean_temp)) %>% 
  pull()

sst_change <- sst_data %>%
  filter(year > 2020) %>% 
  mutate(chng = round(mean_temp-sst_hist,2))


  
  # Plot Data
stock_d %>% 
  bind_rows(eez_d) %>% 
  filter(taxon_emer >= 2020) %>% 
  rename(year = taxon_emer) %>% 
  left_join(sst_change) %>% 
  ggplot() +
  geom_line(
    aes(
      x = chng,
      y = com_sum,
      colour = level
    )
  ) +
  geom_hline(yintercept = length(unique(Eme_Res$eez_name)), color = "grey",linetype = "dashed") +
  geom_text(aes(label="Total number of EEZs", x = 0.5, y = length(unique(Eme_Res$eez_name))+10), color = "grey70",size =3) +
    scale_y_continuous("Cumulatuve Curve",
                       breaks = seq(0,450,50),
                       limits = c(0,500)
    ) +
    scale_x_continuous("Change in SST (C)",
                       breaks = seq(0,2,0.2),
                       limits = c(0.3,2.3)
    ) +
    my_ggtheme_p() +
    scale_colour_viridis(discrete = T) +
  ggsave("./Figures/figure_temp.png",
         width = 6,
         height = 6,
         units = "in"
  )
  
```


```{r Scatter_plot,  eval = T, echo = T}




 data_stock <- Eme_Res %>% 
  filter(
    n_ens == 10,
    emerging_yr >= 2020
  ) %>% 
  group_by(emerging_yr,eez_name) %>% 
  summarise(
    tax_n = length(unique(taxon_key))
    ) %>% 
  group_by(emerging_yr) %>% 
  summarise(emerging_tax = sum(tax_n))

data_eez <- Eme_Res %>% 
  filter(
    n_ens == 10,
    emerging_yr >= 2020
  ) %>% 
  group_by(emerging_yr,taxon_key) %>% 
  summarise(
    eez_n = length(unique(eez_name))
    ) %>% 
    group_by(emerging_yr) %>% 
  summarise(emerging_eez = sum(eez_n))


data_stock %>% 
  left_join(data_eez,
            by = "emerging_yr") %>% 
  rename(year = emerging_yr) %>% 
  left_join(sst_data) %>% 
  ggplot() +
  geom_point(
    aes(
      x = mean_temp,
      y = emerging_eez,
      fill = year,
      colour = year
    )
  )
  
```

##### Mapping the time of emergence

###### Just mean time

```{r emergence_map, eval = T}

# Per EEZs
eez_d_hist <- Eme_Res %>% 
  group_by(eez_name,Tresh) %>% 
  # summarise(n_tax = length(unique(taxon_key))) %>% 
  summarise(
    mean_yr = mean(emerging_yr,na.rm=T),
    sd_yr = sd(emerging_yr,na.rm=T)) %>% 
  gather("metric","value",mean_yr:sd_yr)


### Random plot

ggplot(eez_d_hist) +
  geom_density(
    aes(
      x = value,
      fill = Tresh
    ),
    bins = 10,
    alpha = 0.8
  ) +
  facet_wrap(~metric,
             scales = "free") +
  scale_fill_viridis(discrete = T) +
  my_ggtheme_p() +
  ggsave("./Figures/hist_mean.png",
         width = 6,
         height = 6,
         units = "in"
  )


map <- World_eez_sf %>% 
  left_join(eez_d_hist,
            by = "eez_name") %>% 
  filter(Tresh == "Tresh_two",
         metric == "mean_yr") %>%
  ggplot() +
  geom_sf(
    aes(
      fill = value
    )
  ) +
  geom_sf(data =World_map, aes(), size = 0.1, fill = "gray90", col = "gray90") +
  scale_fill_viridis() +
  my_ggtheme_m() +
  # facet_wrap(~Tresh,
             # ncol = 1) +
  ggsave("./Figures/emer_map_T2a.png",
         width = 12,
         height = 10,
         units = "in"
  )


```


###### With relation to neighbours

```{r time_emergence_map,  eval = T, echo = T}


##_----------------------- #
# Checking on China and Indonesia
# Probably due to dispute territories

Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE) %>% 
  clean_names()

# 
# Neighbours %>% 
#   filter(eez_name == "China") %>% 
#   pull(eez_neighbour) %>% 
#   unique()

##_----------------------- #


# Get the center poligon of each EEZ for map source/target
coords <- as.data.frame(st_centroid(World_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,longitude
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

# Prepare data from results
Test_Data <- Eme_Res %>% 
  filter(
    n_ens == 10#,
    # emerging_yr >= 2020
  ) %>% 
  group_by(eez_name,eez_neighbour,emerging_yr) %>% 
  summarise(
    n_tax = length(unique(taxon_key))
  ) %>% 
  filter(
    emerging_yr <= 2050
  ) %>%
  group_by(eez_name,eez_neighbour) %>% 
  summarise(
    n_tax_emer = sum(n_tax)
  ) %>% 
  # get coords for sources
  left_join(coords,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(coords,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  # mutate(
  #   per_mid = ifelse(is.na(per_mid),0,per_mid)
  # ) %>% 
  drop_na() #%>% 
  # filter(
    # per_mid >= 20,
    # variable == "mean_spp",
  # )


# Convert to data to spatial
network_data_sf <- Test_Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  st_sf(geometry = .)%>%
  bind_cols(Test_Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  sf::st_sf(crs = 4326)

#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest() %>% 
  mutate_at(vars(X,Y), round,2)

# Plot it!

country <- c("Fiji","Solomon Isl.","Tuvalu")

ggplot() +
  geom_sf(
    # data = subset(world_map,name %in% country),
    data = World_map,
    size = 0.1, fill = "gray90", col = "gray90") +
  geom_sf(
    # data = subset(World_eez_sf, eez_name %in% country),
    data = World_eez_sf,
    size = 0.1, fill = "white", col = "gray70") +
  geom_point(data = Test_Data,
             # data = subset(Test_Data, source %in% country & target %in% source),
             aes(start_lon,
                 start_lat,
                 col = n_tax_emer
                 ),
             size = 0.1,
             col = "grey50",
             # shape = 21,
             stroke = 1.5) +
  geom_path(data = paths,
            # data = subset(paths, source %in% country),
            aes(X, Y,
                group = interaction(line_id,subline_id),
                col = n_tax_emer
            ),
            size = 0.3,
            # arrow = arrow(length = unit(0.009, "npc")),
            show.legend = NA) +
  ggtheme_map() +
  scale_colour_viridis(
    name="Number of emerging stocks\nby 2050",
    limits = c(0,40),
    breaks = seq(0,40,10),
    # option="magma",
    direction = 1
  ) +
  ggsave("./Figures/figure_emerging_2050.png",
         width = 10,
         height = 6,
         units = "in"
  )


```


## Troubleshooting

### Weird connections from Australia

```{r fig_map_Juan, eval = F, echo =F}

##_----------------------- #
# Checking on China and Indonesia
# Probably due to dispute territories

Neighbours <- my_path("D", extra_path = "Spatial/", name="Neighbours_eez_id.csv", read = TRUE) %>% 
  clean_names()

# 
# Neighbours %>% 
#   filter(eez_name == "China") %>% 
#   pull(eez_neighbour) %>% 
#   unique()

##_----------------------- #


# Get the center poligon of each EEZ for map source/target
coords <- as.data.frame(st_centroid(World_eez_sf)) %>% 
  ungroup() %>% 
  select(eez_name,geometry) %>% 
  separate(col = geometry, into = c("longitude", "latitude"), sep = "\\,") %>% 
  # Manually fix issues
  mutate(
    longitude = ifelse(
      eez_name == "Fiji", 178.065033,
      ifelse(eez_name == "Tuvalu",177.6493,
             ifelse( eez_name == "New Zealand",174.8860,
                     ifelse( eez_name == "USA (Alaska, Subarctic)",-145.8860,longitude
                     )
             )
      )
    )
  )

# Remove "c()"
coords$longitude <- gsub("\\(","",coords$longitude)
coords$longitude <- gsub("c","",coords$longitude)
coords$latitude <- gsub(")","",coords$latitude)

coords <- coords %>% 
  mutate_at(vars(longitude,latitude),as.numeric)

# Prepare data from results
Test_Data <- results %>% 
  # get coords for sources
  left_join(coords,
            by = "eez_name") %>%
  rename(source = eez_name,
         start_lon = longitude,
         start_lat = latitude,
         eez_name=eez_neighbour) %>% 
  # get coords for targets
  left_join(coords,
            by = "eez_name") %>% 
  rename(target = eez_name,
         end_lon = longitude,
         end_lat = latitude) %>% 
  ungroup() %>% 
  # Plot miscs
  mutate(
    per_mid = ifelse(is.na(per_mid),0,per_mid)
  ) %>% 
  drop_na() %>% 
  filter(
    # per_mid >= 20,
    variable == "mean_spp",
  )


# Convert to data to spatial
network_data_sf <- Test_Data %>%
  select(start_lon, start_lat, end_lon, end_lat) %>% 
  purrr::transpose() %>% 
  purrr::map(~ matrix(flatten_dbl(.), nrow = 2, byrow = TRUE)) %>% 
  purrr::map(st_linestring) %>%
  st_sfc(crs = 4326) %>%
  st_sf(geometry = .)%>%
  bind_cols(Test_Data) %>%
  select(everything(), geometry) %>% 
  # Set circles ('cus the world is not flat!)
  st_segmentize(units::set_units(100, km)) %>% 
  mutate(geometry = (geometry + c(180,90)) %% c(360) - c(180,90)) %>% 
  st_wrap_dateline(options = c("WRAPDATELINE=YES",  "DATELINEOFFSET=180"), quiet = TRUE) %>% 
  sf::st_sf(crs = 4326)

#  unpack the coordinates of each feature 
coord_data <- as.data.frame( st_coordinates(st_cast(network_data_sf,"MULTILINESTRING")$geometry))

c(network_data_sf$line_id, network_data_sf$coords) %<-% (
  coord_data %>% 
    rename(subline_id = L1) %>%   
    nest(-L2)
)

# Create data path for line connections
paths <- network_data_sf %>% 
  sf::st_set_geometry(NULL) %>% 
  unnest() %>% 
  mutate_at(vars(X,Y), round,2)

# Plot it!

country <- c("Fiji","Solomon Isl.","Tuvalu")

ggplot() +
  geom_sf(
    # data = subset(world_map,name %in% country),
    data = world_map,
    size = 0.1, fill = "gray90", col = "gray90") +
  geom_sf(
    # data = subset(World_eez_sf, eez_name %in% country),
    data = World_eez_sf,
    size = 0.1, fill = "white", col = "gray70") +
  geom_point(data = Test_Data,
             # data = subset(Test_Data, source %in% country & target %in% source),
             aes(start_lon,
                 start_lat,
                 col = per_mid),
             size = 0.1,
             col = "black",
             # shape = 21,
             stroke = 1.5) +
  geom_path(data = paths,
            # data = subset(paths, source %in% country),
            aes(X, Y,
                group = interaction(line_id,subline_id),
                col = per_mid
            ),
            size = 0.3,
            arrow = arrow(length = unit(0.009, "npc")),
            show.legend = NA) +
  # geom_sf_text(data = subset(World_eez_sf, eez_name %in% country),
  #              aes(label =eez_name),
  #              size = 2) +
  # geom_text(data = subset(Test_Data, source %in% country),
  #              aes(start_lon,
  #                start_lat,
  #                label = paste(source,"to",target)
  #              ),
  #              size = 2) +
  # geom_text_repel(data = Test_Data,
  #   aes(start_lon,
# start_lat,
# label = paste(source,"to",target)
# )
# )+
ggtheme_map() +
  scale_colour_gradientn("Gain of Stock-Share Ratio (%)",
                         colours = wesanderson::wes_palette("Zissou1", 100, type = "continuous"),
                         limits = c(0,25),
                         breaks = seq(0,25,5)
  )

```


# Old Code


```{r TransIndex, eval = F, echo = F}

TransIndex <- function(Spp,year, data_type = "Catch",ensemble_list,path,Neighbours,eez_centroid){
  
  # ----------------- #
  # Get Species Centrodis
  #  ---------------- #
  
  # Get model data from spps
  Spp_Dist <- bind_rows(
    lapply(
      ensemble_list,
      dbem_import,
      taxon_key = Spp,
      year = year,
      data_type = data_type,
      path = path
    )
  )
  
  
  #### Control for Spp id so I can fix problems
  
if(file.exists("~/Desktop/spp_df.csv") == FALSE){
  spp_df <- tibble() %>% 
    write_csv(.,
            "~/Desktop/spp_df.csv")
}

  suppressMessages(
    spp_df <- read_csv("~/Desktop/spp_df.csv")
  )
  spp_df <- tibble(Spp) %>% 
    bind_rows(spp_df) %>% 
    write_csv(.,
              "~/Desktop/spp_df.csv")
  
  
  #____________ Selecting only the transboundary nature of the species _________ #
  Trans_Spp <- Spp_Dist %>%
    left_join(index_code,
              by= "index") %>% 
    filter(!is.na(value)) %>% 
    semi_join(Transboundary_spp, # filter only transboundary cases
              by = c("taxon_key","eez_name")
    )
  
  # Step
  nr <- nrow(Trans_Spp)
  if(nr > 0){
    

    # Filter eez by those transboundary
  unique_eez <- unique(Trans_Spp$eez_name)
  
  Neighbours_combo <- Neighbours %>% 
    filter(eez_name %in% unique_eez,
           eez_neighbour %in% unique_eez)
    
    
    # Get the centroid of each country
    EEZ_centroid <- eez_centroid %>% 
      filter(eez_name %in% Trans_Spp$eez_name) %>% 
      mutate(taxon_key = Spp)
    
    
    Ids <- unique(Neighbours_combo$neighbour_id)
    
  corefx <- function(Ids){  
    
      EEZ_ids <- Neighbours_combo %>% 
        filter(neighbour_id == Ids)
      
      Sub_Trans_Spp <- Trans_Spp %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      Sub_EEZ_centroid <- EEZ_centroid %>% 
        filter(eez_name %in% EEZ_ids$eez_name)
      
      # Centroid is defined as the tile with the higest species value
      Centroids <- Sub_Trans_Spp %>% 
        left_join(EEZ_ids, by = "eez_name") %>% 
        group_by(taxon_key,year,ensemble,neighbour_id) %>%  # for whole distribution
        top_n(1,value) %>% 
        distinct(value,year, .keep_all = TRUE) %>%  # removes duplicates when tile is in between EEZs
        left_join(Sub_EEZ_centroid, by = "taxon_key") %>%
        select(eez_name =eez_name.y, everything() ,-eez_name.x)
      
      # Estimate distances between spp centroid and EEZ centroid
      Distance_Data <- Centroids %>%
        rename(
          catch_lon = lon,
          catch_lat = lat,
          eez_lon = longitude,
          eez_lat= latitude
        ) %>% 
        # Estimate the distance between centriods
        mutate(
          distance = geodist(eez_lon, eez_lat, catch_lon, catch_lat, units="km")
        ) %>% 
        select(taxon_key,eez_name,neighbour_id,ensemble,year,distance)
      
      # Historical mean and sd of distance
      historical <- Distance_Data %>%
        filter(year <= 2000) %>%
        ungroup() %>%
        group_by(taxon_key,ensemble,eez_name,neighbour_id) %>%
        summarise_at(vars("distance"),
                     c(hd_temp_mean=mean,
                       hd_temp_sd=sd)
        )
      
      
      # Future results
      future <- Distance_Data %>% 
        filter(year > 2000)
      
      # Transboundary Index
      Trans_index <- Distance_Data %>% 
        left_join(historical,
                  by = c("taxon_key","eez_name","ensemble","neighbour_id")
        ) %>%
        # Re arrenging table for mutate
        gather("variable","value",distance:hd_temp_sd) %>%
        ungroup()
      
      
      Partial <- Trans_index %>% 
        mutate(
          names = ifelse(eez_name ==Sub_EEZ_centroid$eez_name[1],paste("Country_A",variable,sep="_"),paste("Country_B",variable,sep="_"))
        ) %>%
        select(-eez_name,-variable) %>%
        spread(names,value) %>% 
        # mutate index
        mutate(
          trans_index = (Country_A_distance/Country_A_hd_temp_sd - Country_B_distance/Country_B_hd_temp_sd)^2
        ) %>% 
        group_by(taxon_key,ensemble,neighbour_id) %>% 
        mutate(RMean = rollmean(x = trans_index, 
                                10, 
                                align = "right", 
                                fill = trans_index)
        ) %>% 
        filter(year > 1960) %>% 
        select(taxon_key,neighbour_id,year,ensemble,trans_index,RMean)
      
      # Average of 10 years mean of ensemble members results
      mean_sd_index <- Partial %>% 
        group_by(taxon_key,year,neighbour_id) %>% 
        summarise_at(vars("RMean"),
                     c(trend=mean,
                       ensemble_sd=sd)
        )
      
      # Estimate noice from ensemble members
      historic_sd <- mean_sd_index %>% 
        filter(year < 2000) %>% 
        group_by(taxon_key) %>% 
        summarise_at(vars("trend"),
                     c(hist_mean=mean,
                       noise=sd)
        )
      
      
      # Plot the result, bruh
      # ggplot() +
      #   geom_line(data = mean_sd_index,
      #             aes(
      #               x = year,
      #               y = trend
      #             )
      #   ) +
      #   geom_ribbon(data = mean_sd_index,
      #               aes(x=year,
      #                   ymin=historic_sd$hist_mean-historic_sd$noise,
      #                   ymax=historic_sd$hist_mean+historic_sd$noise),
      #               alpha = 0.5,
      #               fill = "grey50"
      #   ) +
      #   geom_line(data = mean_sd_index,
      #             aes(
      #               x = year,
      #               y = historic_sd$hist_mean
      #             ),
      #             colour = "grey50"
      #   ) +
      #   geom_point(data = subset(mean_sd_index, trend > (historic_sd$hist_mean+historic_sd$noise) | trend < (historic_sd$hist_mean-historic_sd$noise)),
      #              aes(
      #                x = year,
      #                y = trend,
      #                colour = "red",
      #              ),
      #              shape = 1,
      #              size = 3
      #   ) +
      #   geom_vline(xintercept = 2000,colour="blue",alpha = 0.5) +
      #   theme_classic()
      
      # #     
      Final_Result <- mean_sd_index %>%
        filter(year > 2000,
               trend > (historic_sd$hist_mean+historic_sd$noise) |
                 trend < (historic_sd$hist_mean-historic_sd$noise)
        ) %>%
        group_by(taxon_key,neighbour_id) %>%
        summarise(emerging_yr= min(year)) %>%
        left_join(EEZ_ids) %>%
        ungroup() %>%
        select(taxon_key,eez_name,eez_neighbour,emerging_yr)
      
      
      # if(i == 1){
      #   f_df <- Final_Result
      # }else{
      #   f_df <- bind_rows(f_df,Final_Result)
      # }
    return(Final_Result)
      }
    
  
  x <- bind_rows(
    mclapply(Ids,corefx)
  )
    # return(f_df)
    
  }else{
    
    print("no share data")
    
    x <- tibble(
      taxon_key = Spp,
      eez_name = NA,
      emerging_yr = NA
    )
    
  }
  
  return(x)

}

 
#  #One spp works 
# suppressMessages(
# TransIndex(Spp = 600006,
#              year,
#              data_type = "Catch",
#              ensemble_list,
#              path,
#              Neighbours = Neighbours,
#              eez_centroid)
# Multiple spp

# spp_list <- c(600004,
#               600005,
#               600245,
#               600006
#               )
# 
# suppressMessages(
#   suppressWarnings(
#     Test <- bind_rows(
#       lapply(spp_list,
#              TransIndex,
#              year,
#              data_type = "Catch",
#              ensemble_list,
#              path,
#              Neighbours,
#              eez_centroid
#       )
#     )
#   )
# )


```
